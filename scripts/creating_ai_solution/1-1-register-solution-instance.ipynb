{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP-1**. AI Solution 및 Instance 등록을 위한 준비 작업\n",
    "&#x1F600; **등록 할 AI Contents 의 experimental_plan.yaml 를 alo/config/ 에 준비해 둡니다.**\n",
    "\n",
    "&#x1F600; **가상 환경을 만들어 두고, ipykernel 을 제작해 둡니다.**     \n",
    "\n",
    "1. ALO 의 main.py 파일이 존재하는 위치에서 아래 명령어들을 순차 실행합니다.\n",
    "> conda create -n {ENV-NAME} python=3.10 \\\n",
    "> conda init bash \\\n",
    "> conda activate {ENV-NAME} \\\n",
    "> python main.py \\\n",
    "> pip install ipykernel \\\n",
    "> pip install requests \\\n",
    "> python -m ipykernel install --user --name {ENV-NAME} --display-name {IPYKERNEL-NAME}\n",
    "\n",
    "2. 본 jupyter notebook 에서, 위에서 생성한 ipykernel 을 선택 합니다. \\\n",
    "   가령 tcr이라는 이름의 가상환경을 만들었다면, 아래와 같이 선택합니다.\n",
    "\n",
    "<div style=\"margin: 40px\">\n",
    "<img src=\"./image/ipykernel.png\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "\n",
    "&#x1F600; **아래 STEP들을 하나씩 실행시키면서, <u>< 사용자 입력 ></u>이라고 주석 표기된 내용을 적절히 변경해주세요.**     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP-2**. AI Solution 이름 선택     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-2-1**. AI Conductor 시스템 URI 셋팅\n",
    "&#x1F600; 로그인 요청 및 시스템 담당으로부터 사용 가능한 시스템 URI를 확인합니다. \n",
    "- 고객지수플랫폼 Development \n",
    "> URI: \"https://aic-kic.aidxlge.com/\"\n",
    "- 담당서버 테스트 환경       \n",
    "> URI = \"http://10.158.2.243:9999/\" \n",
    "- 사외 테스트 환경 (LDAP 로그인 불가)\n",
    "> URI = \"https://web.aic-dev.lgebigdata.com/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 시스템 URI 및 로그인 정보, ECR TAG, ICON FILE 명 등 사용자 입력부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#----------------------------------------#\n",
    "#              사용자 입력                #\n",
    "#----------------------------------------#\n",
    "user_input ={\n",
    "    # 로그인 정보: EP 정보로 입력해주세요\n",
    "    'LOGIN_ID': \"magna-dev\", #'ws.jang', # \"cism-dev\"\n",
    "    'LOGIN_PW': 'magna-dev@com', # \"cism-dev\n",
    "    \n",
    "    # workspace 이름 \n",
    "    'WORKSPACE_NAME': \"magna-ws\", # \"cism-ws\"\n",
    "    \n",
    "    # 시스템 URI\n",
    "    'URI': \"https://web.aic-dev.lgebigdata.com/\", #\"http://10.158.2.243:9999/\", #\"https://web.aic-dev.lgebigdata.com/\", #\"https://web.aic-dev.lgebigdata.com/\", #\"https://aic-kic.aidxlge.com/\", #\"http://10.158.2.243:9999/\", \n",
    "    \n",
    "    # ECR에 올라갈 컨테이너 URI TAG\n",
    "    'ECR_TAG': 'latest', \n",
    "\n",
    "    # scripts/creating_ai_solution/image/ 밑에 UI에 표시될 아이콘 이미지 파일 (ex. icon.png) 를 업로드 해주세요. \n",
    "    # 이후 해당 아이콘 파일 명을 아래에 기록 해주세요.\n",
    "    'ICON_FILE': 'icon.png'\n",
    "}\n",
    "#----------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 시스템 로그인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: ipywidgets in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipywidgets) (8.20.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipywidgets) (5.14.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: decorator in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/wonjun.sung/miniforge3/envs/alo2.1.3/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# 시각화 용 모듈 install \n",
    "!pip install tabulate ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI_SCOPE:  magna-ws\n",
      "\u001b[92m\n",
      ">> Success getting cookie from AI Conductor:\n",
      " {'access-token': 'E5Tk0I-YgJASCMemgVGBpbkRjiVhbDhFxzkaTYDIZks'}\u001b[0m\n",
      "\u001b[92m\n",
      ">> Success Login: {'result': 'OK'}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Generate RegisterUtils instance & login\n",
    "from register_utils import RegisterUtils\n",
    "registerer = RegisterUtils(user_input)\n",
    "\n",
    "# AI Conductor Login\n",
    "registerer.login('static') # FIXME LDAP로그인 시 인자 안주면됨 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AI Solution 이름 설정 (사용자 입력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"font-size: 20px;\"> < Create the name of AI Solution! > </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[Success] Allowed name: << test_0111_2 >>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# AI Solution 이름 설정 (기존에 존재하는 중복 이름 허용X)\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# soltuion 이름 입력 받기 \n",
    "display(HTML('<p style=\"font-size: 20px;\"> < Create the name of AI Solution! > </p>'))\n",
    "user_solution_name = input(\"- Enter the name you want to create: \")\n",
    "\n",
    "# 기존에 존재하는 solution name과 겹치지 않는지 체크 \n",
    "registerer.check_solution_name(user_solution_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEE-2-2**. AI Solution Name 을 AI Conductor 에 등록합니다. \n",
    "&#x1F600; 이름이 등록되면 본 jupyter 노트북 과정이 끝날 때까지 변경이 어려 울 수 있습니다. \\\n",
    "변경이 필요할 경우 <b> STEP-2-1 </b> 부터 다시 실행하여 주시기 바랍니다. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 기존에 workspace에 존재하는 solution 이름을 조회하여, 사용자가 입력하는 이름이 유효한지 (고유한지) 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'workspaces': [{'id': '1b61dae3-e8f7-4b5f-9629-da0aedbb4a08', 'name': 'cism-ws', 'namespace': 'aic-ns-cism-ws', 'kubeflow_user': 'aic-user-cism-ws@aic.com', 's3_bucket_name': {'public': 's3-an2-hyunsoo-dev-aia', 'private': 's3-an2-hyunsoo-dev-cism'}, 'ecr_base_path': {'public': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solutions/public/', 'private': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solutions/cism/'}, 'execution_specs': [{'name': 'high', 'label': 'cism-ws-high', 'vcpu': 8, 'ram_gb': 32, 'gpu': 0}, {'name': 'standard', 'label': 'cism-ws-standard', 'vcpu': 2, 'ram_gb': 8, 'gpu': 0}], 'is_deleted': 0, 'created_at': '2024-01-04T06:17:39', 'updated_at': '2024-01-04T06:17:39'}, {'id': 'a0da0a72-3ce4-43e4-b510-b875896dcb35', 'name': 'magna-ws', 'namespace': 'aic-ns-magna-ws', 'kubeflow_user': 'aic-user-magna-ws@aic.com', 's3_bucket_name': {'public': 's3-an2-hyunsoo-dev-aia', 'private': 's3-an2-hyunsoo-dev-magna'}, 'ecr_base_path': {'public': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solutions/public/', 'private': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solutions/magna/'}, 'execution_specs': [{'name': 'standard', 'label': 'magna-ws-standard', 'vcpu': 2, 'ram_gb': 8, 'gpu': 0}, {'name': 'high', 'label': 'magna-ws-high', 'vcpu': 8, 'ram_gb': 32, 'gpu': 0}], 'is_deleted': 0, 'created_at': '2024-01-04T06:17:39', 'updated_at': '2024-01-04T06:17:39'}]}\n",
      "\u001b[92m\n",
      "[INFO] S3_BUCUKET_URI:\u001b[0m\n",
      "\u001b[96m- public: s3-an2-hyunsoo-dev-aia\u001b[0m\n",
      "\u001b[96m- private: s3-an2-hyunsoo-dev-magna\u001b[0m\n",
      "\u001b[92m\n",
      "[INFO] ECR_URI:\u001b[0m\n",
      "\u001b[96m- public: 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solutions/public/\u001b[0m\n",
      "\u001b[96m- private: 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solutions/magna/\u001b[0m\n",
      "\u001b[92m\n",
      "[INFO] AWS ECR URI received: \n",
      " 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solutions/magna/\u001b[0m\n",
      "\u001b[92m\n",
      "[INFO] AWS S3 BUCKET NAME received: \n",
      " s3-an2-hyunsoo-dev-magna\u001b[0m\n",
      "\u001b[92m\n",
      " << solution_metadata.yaml >> generated. - current version: v1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 학습 용 solution_metadata.yaml 셋팅 \n",
    "###################\n",
    "pipeline = 'train'\n",
    "###################\n",
    "# check workspace (ECR, S3정보 셋팅까지 진행)\n",
    "registerer.check_workspace() \n",
    "# 받아온 workspace 정보 기반으로 solution_metadata.yaml 셋팅 \n",
    "registerer.set_yaml(pipeline = pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEE-2-3**. 솔루션 사용자가 변경 가능한 User parameters를 등록합니다.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO \n",
    "- preprocess asset의 custom 같은 arg는 어찌 할 지 ? \n",
    ">- mode: custom \\\n",
    ">custom: {category_columns: [Pclass, SibSp], \\\n",
    ">            handle_missing: {fill_mean: [Age,Fare]}, \\\n",
    ">            numeric_scaler: {standard: [Fare], minmax: [Age]} \\\n",
    ">            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- step:  input\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cf11e2dfc043349a9d3fa59f5badfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='concat_dataframes', style=CheckboxStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- step:  sampling\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d6b3934b6b4c7ea36b4a7dcd9f295f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='ignore_label_class', style=CheckboxStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- step:  train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe80a0495edc4e6687eee8fbb3ad1c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='data_split_method', style=CheckboxStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO 아무 user parameter도 선택안했을 시에도 잘 작동하는지 테스트 필요 \n",
    "# FIXME x_columns 같이 사용자가 몇개입력할지 모르는 건 string 으로 해야한다는걸 가이드 잘 할필요 있음 \n",
    "from register_utils import RegisterUtils\n",
    "import ipywidgets as widgets\n",
    "\n",
    "candidate_params = registerer.set_candidate_parameters()\n",
    "\n",
    "args_checkboxes_dict = {} \n",
    "for step_args in candidate_params:\n",
    "    print('\\n- step: ', step_args['step'])\n",
    "    checkboxes = [widgets.Checkbox(value=False, description=arg, style={'description_width': 'initial'}) for arg in step_args['args'][0].keys()]\n",
    "    args_checkboxes_dict[step_args['step']] = checkboxes\n",
    "    output = widgets.VBox(children=checkboxes)\n",
    "    display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME boolean은 single selection이라 생각하고 유저 가이드도 필요할듯\n",
    "# FIXME x_columns 같은 string과 multi-selection의 경계가 애매 ? > x_columns는 몇개가 될지 모르니 selection이 아니네 \n",
    "# args type input \n",
    "type_dropdown_dict = {}\n",
    "\n",
    "type_list = ['float', 'int', 'string', 'single_selection', 'multi_selection']\n",
    "for step, checkboxes in args_checkboxes_dict.items(): # cbs: checkboxs\n",
    "    selected_args = [c.description for c in checkboxes if c.value == True] # checked list  \n",
    "    if len(selected_args) == 0: \n",
    "        continue \n",
    "    print('\\n- step: ', step)\n",
    "    for arg in selected_args:         \n",
    "        dropdown = widgets.Dropdown(options=type_list, description=arg, value=None, style={'description_width': 'initial'})\n",
    "        type_dropdown_dict[arg] = dropdown\n",
    "        display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65278669e6cb4a72b52e6d7e3cd5caec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Accordion(), Accordion(), Accordion()), selected_index=0, titles=('input', 'sampling', 'train'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FIXME checkbox 중복 선택한 경우 처리하는 로직 필요할듯 ? \n",
    "# FIXME range는 포함관계 (이하,이상,미만,초과) 어떻게 되는지 ?\n",
    "# FIXME range 같은 건 사용자가 , 로 분리해서 써야된다고 잘 가이드 필요 \n",
    "# FIXME x_columns 처럼 default None 인거 어떻게 처리? (일단 None으로 했음)\n",
    "def get_arg_format(arg_type: str):\n",
    "    if arg_type in ['int', 'float', 'string']:\n",
    "        return ['name', 'description', 'type', 'default', 'range']\n",
    "    elif arg_type in ['single_selection', 'multi_selection']: \n",
    "        return ['name', 'description', 'type', 'selectable', 'default']\n",
    "    else: \n",
    "        raise ValueError(f\"Unsupported type of user paramter: << {arg_type} >>\") \n",
    "    \n",
    "def get_text_widgets(arg_format, arg_name, arg_type):\n",
    "    text_widgets = [] \n",
    "    for desc in arg_format: \n",
    "        if desc == 'name': \n",
    "            text_widgets.append(widgets.Text(description=desc, value=arg_name))\n",
    "        elif desc == 'type': \n",
    "            text_widgets.append(widgets.Text(description=desc, value=arg_type))\n",
    "        else: \n",
    "            text_widgets.append(widgets.Text(description=desc))\n",
    "    return text_widgets\n",
    "\n",
    "accordion_list = []\n",
    "for step, checkboxes in args_checkboxes_dict.items(): \n",
    "    selected_args = [c.description for c in checkboxes if c.value == True] # checked list  \n",
    "    text_widgets_list = [] \n",
    "    for arg in selected_args: \n",
    "        selected_type = type_dropdown_dict[arg].value\n",
    "        assert selected_type is not None \n",
    "        arg_format = get_arg_format(selected_type)\n",
    "        text_widgets_list.append(get_text_widgets(arg_format=arg_format, arg_name=arg, arg_type=selected_type))\n",
    "        \n",
    "    accordion = widgets.Accordion(children=[widgets.VBox(children=text_widgets) for text_widgets in text_widgets_list])\n",
    "    for idx, arg in enumerate(selected_args):\n",
    "        accordion.set_title(idx, arg)\n",
    "    accordion_list.append((step, accordion)) # [[step, accordion]]\n",
    "    \n",
    "tab_nest = widgets.Tab()\n",
    "tab_nest.children = [step_accordion[1] for step_accordion in accordion_list]\n",
    "for idx, step_accordion in enumerate(accordion_list): \n",
    "    tab_nest.set_title(idx, step_accordion[0])\n",
    "display(tab_nest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from register_utils import convert_args_type \n",
    "# solution_metadata.yaml에 user parameters 셋팅 \n",
    "user_parameters = [] \n",
    "for step, accordion in accordion_list: \n",
    "    args_list = []\n",
    "    if len(accordion.children) != 0:\n",
    "        for vbox in accordion.children: # vbox 하나가 arg 하나에 대응됨  \n",
    "            args = {tbox.description: tbox.value for tbox in vbox.children}\n",
    "            args_list.append(convert_args_type(args))\n",
    "    user_parameters.append({'step': step, 'args': args_list})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-3**. Train 용 Sample data, train artifacts, model, icon 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m\n",
      "[INFO] AWS region: ap-northeast-2\u001b[0m\n",
      "\u001b[92m\n",
      "[INFO] AWS S3 access check: OK\u001b[0m\n",
      "\u001b[96m\n",
      "[INFO] Start uploading data into S3 from local folder:\n",
      " /home/wonjun.sung/wrangler_test/alo/input/train/\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_03_45_49_06Y8004090400000XP2405031012V5545_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_01_31_06Y8004090400000XP2405031012V5545_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_10_43_57_LR23180A0029_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_26_25_LTCO75645678010008_ETC2(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_39_14_LR23180A0031_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230122_03_32_36__ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_10_08_16_06Y8004090400000XP2405031012V5545_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230118_07_20_53_06Y8004090400000XP2405031012V5545_ETC2(3)_OTHERS(0).csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230118_07_20_54_06Y8004090400000XP2405031012V5545_ETC2(3)_OTHERS(0).csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230103_08_23_47__ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_03_46_55_06Y8004090400000XP2405031012V5545_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_27_59_LR23180A0030_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_09_12_LTCO75645678010008_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20231006_16_03_33_LR23235A0013_ETC1(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_03_45_05_06Y8004090400000XP2405031012V5545_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230120_05_40_05_06Y8004090400000XP2405031012V5545_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230202_10_27_43_06Y8004090400000XP2429692212V5545_ETC2(5)_NG.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_01_04_06Y8004090400000XP2405031012V5545_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230103_07_50_08__ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_09_49_05_06Y8004090400000XP2405031012V5545_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230201_16_18_21_06Y8004090400000XP2429692212V5545_ETC2(5)_NG.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230124_05_15_28__ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_29_37_LR23180A0030_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230122_03_32_23__ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_26_48_LTCO75645678010008_ETC2(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230118_07_21_57_06Y8004090400000XP2405031012V5545_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_05_52_06Y8004090400000XP2405031012V5545_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230124_02_15_23__ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_31_05_LR23180A0030_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_10_44_08_LR23180A0029_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_47_20_LR23180A0032_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_30_11_LR23180A0030_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_10_07_51_06Y8004090400000XP2405031012V5545_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_06_50_06Y8004090400000XP2405031012V5545_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_40_00_LR23180A0031_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_02_35_29_06Y8004090400000XP2405031012V5545_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230120_05_40_14_06Y8004090400000XP2405031012V5545_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_28_05_LTCO75645678010008_ETC1(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_02_37_05_06Y8004090400000XP2405031012V5545_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_09_40_LTCO75645678010008_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_46_30_LR23180A0032_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_03_45_25_06Y8004090400000XP2405031012V5545_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20231005_13_55_37_LR23235A0040_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230124_05_13_19__ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_28_15_LTCO75645678010008_ETC1(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_31_16_LR23180A0030_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_03_44_45_06Y8004090400000XP2405031012V5545_ETC1(1)_OTHERS(0).csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230122_03_33_38__ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230124_03_09_04__ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230202_10_26_27_06Y8004090400000XP2429692212V5545_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_02_37_24_06Y8004090400000XP2405031012V5545_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230103_08_24_13__ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_25_48_LTCO75645678010008_ETC2(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_02_27_26_LTCO75645678010008_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_09_59_07_06Y8004090400000XP2405031012V5545_ETC2(4)_OTHERS(0).csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20231005_13_55_47_LR23235A0040_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230103_07_46_37__ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_23_28_LTCO75645678010008_ETC1(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_10_08_59_06Y8004090400000XP2405031012V5545_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230122_03_32_53__ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230124_03_09_18__ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230118_07_20_27_06Y8004090400000XP2405031012V5545_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_10_03_LTCO75645678010008_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230202_10_26_55_06Y8004090400000XP2429692212V5545_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230118_07_21_52_06Y8004090400000XP2405031012V5545_ETC2(4)_OTHERS(0).csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_02_27_35_LTCO75645678010008_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_09_56_LTCO75645678010008_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_10_08_02_06Y8004090400000XP2405031012V5545_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230103_08_23_23__ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230103_08_25_55__ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_10_00_03_06Y8004090400000XP2405031012V5545_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230120_05_41_37_06Y8004090400000XP2405031012V5545_ETC2(4)_OK - Copy.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_36_14_LR23180A0031_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_46_08_LR23180A0032_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_03_46_42_06Y8004090400000XP2405031012V5545_ETC2(4)_NG.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230202_10_26_41_06Y8004090400000XP2429692212V5545_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230103_07_40_47__ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_10_09_11_06Y8004090400000XP2405031012V5545_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_10_43_11_LR23180A0029_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_09_59_11_06Y8004090400000XP2405031012V5545_ETC2(4)_OTHERS(0).csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_40_00_LR23180A0031_ETC2(4)_OTHERS(231).csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_21_46_LTCO75645678010008_ETC2(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_10_42_20_LR23180A0029_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_09_48_18_06Y8004090400000XP2405031012V5545_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230118_07_20_57_06Y8004090400000XP2405031012V5545_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_01_15_06Y8004090400000XP2405031012V5545_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230124_05_14_11__ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230124_05_13_31__ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_09_59_30_06Y8004090400000XP2405031012V5545_ETC2(5)_NG.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230122_03_32_15__ETC1(1)_OTHERS(0).csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20231005_13_56_00_LR23235A0040_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_21_47_LTCO75645678010008_ETC2(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_38_57_LR23180A0031_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_02_37_38_06Y8004090400000XP2405031012V5545_ETC2(5)_OTHERS(0).csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230120_05_41_37_06Y8004090400000XP2405031012V5545_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_45_11_LR23180A0032_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230103_07_40_22__ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230124_02_21_55__ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_10_42_30_LR23180A0029_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230118_07_22_47_06Y8004090400000XP2405031012V5545_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_02_37_32_06Y8004090400000XP2405031012V5545_ETC2(5)_NG.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230118_07_20_16_06Y8004090400000XP2405031012V5545_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20231005_13_56_21_LR23235A0040_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_02_27_54_LTCO75645678010008_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_24_19_LTCO75645678010008_ETC2(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_24_15_LTCO75645678010008_ETC2(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_28_24_LTCO75645678010008_ETC2(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_09_59_16_06Y8004090400000XP2405031012V5545_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230124_05_15_20__ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_09_23_LTCO75645678010008_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_06_02_06Y8004090400000XP2405031012V5545_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230103_08_22_56__ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230103_07_49_55__ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_03_47_12_06Y8004090400000XP2405031012V5545_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_24_16_LTCO75645678010008_ETC2(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230120_05_40_35_06Y8004090400000XP2405031012V5545_ETC2(3)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20231005_13_56_29_LR23235A0040_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230120_05_41_45_06Y8004090400000XP2405031012V5545_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_02_34_56_06Y8004090400000XP2405031012V5545_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_10_08_38_06Y8004090400000XP2405031012V5545_ETC2(4)_NG.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_40_08_LR23180A0031_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20231006_15_32_43_LR23235A0013_ETC1(1)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230117_04_26_59_LTCO75645678010008_ETC2(0)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230904_15_47_09_LR23180A0032_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230124_02_19_48__ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230202_10_27_31_06Y8004090400000XP2429692212V5545_ETC2(4)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230201_16_18_33_06Y8004090400000XP2429692212V5545_ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230122_03_33_46__ETC2(5)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/train/20230112_09_48_39_06Y8004090400000XP2405031012V5545_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success updating solution_metadata.yaml - << dataset_uri >> info / pipeline: train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# data 등록 \n",
    "# s3 접근확인\n",
    "registerer.s3_access_check('data')\n",
    "\n",
    "# s3 데이터 업로드\n",
    "# 이전에 이미 해당 s3 경로에 존재하던 데이터는 지워집니다.\n",
    "registerer.s3_upload_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m\n",
      "[INFO] AWS region: ap-northeast-2\u001b[0m\n",
      "\u001b[92m\n",
      "[INFO] AWS S3 access check: OK\u001b[0m\n",
      "\u001b[96m\n",
      "[INFO] Start uploading << train artifacts >> into S3 from local folder:\n",
      " /home/wonjun.sung/wrangler_test/alo/.temp_artifacts_dir/\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/artifacts/train_artifacts.tar.gz\u001b[0m\n",
      "\u001b[92m\n",
      "Success updating solution_metadata.yaml - << artifact_uri >> info. / pipeline: train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# artifacts 등록 \n",
    "# s3 접근확인\n",
    "registerer.s3_access_check('artifacts')\n",
    "\n",
    "# s3 model, artifacts 업로드 \n",
    "# 이전에 이미 해당 s3 경로에 존재하던 object는 지워집니다.\n",
    "registerer.s3_upload_artifacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccess uploading into S3 path: s3-an2-hyunsoo-dev-magna/icons/test_0111_2/icon.png\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# TODO icon 관련 개발 변경 필요 \n",
    "# UI에 표시될 아이콘 이미지를 s3에 업로드합니다. \n",
    "registerer.s3_upload_icon()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-4**. Train Docker Container 제작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ALO 작업 폴더를 현재 노트북 경로로 가져옵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[INFO] copy from \" /home/wonjun.sung/wrangler_test/alo/main.py \"  -->  \" /home/wonjun.sung/wrangler_test/alo/scripts/creating_ai_solution/alo/ \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/wonjun.sung/wrangler_test/alo/src \"  -->  \" /home/wonjun.sung/wrangler_test/alo/scripts/creating_ai_solution/alo/src \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/wonjun.sung/wrangler_test/alo/config \"  -->  \" /home/wonjun.sung/wrangler_test/alo/scripts/creating_ai_solution/alo/config \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/wonjun.sung/wrangler_test/alo/assets \"  -->  \" /home/wonjun.sung/wrangler_test/alo/scripts/creating_ai_solution/alo/assets \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/wonjun.sung/wrangler_test/alo/alolib \"  -->  \" /home/wonjun.sung/wrangler_test/alo/scripts/creating_ai_solution/alo/alolib \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/wonjun.sung/wrangler_test/alo/.git \"  -->  \" /home/wonjun.sung/wrangler_test/alo/scripts/creating_ai_solution/alo/.git \" \u001b[0m\n",
      "\u001b[92m\n",
      " Success ALO directory setting.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ALO 작업 폴더 가져오기 \n",
    "registerer.set_alo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> DOCKERFILE을 셋팅합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccess DOCKERFILE setting. \n",
      " - pipeline: train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# DOCKERFILE setting\n",
    "registerer.set_docker_contatiner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AWS ECR에 docker 등록을 위한 repository를 생성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[INFO] target AWS ECR url: \n",
      "086558720570.dkr.ecr.ap-northeast-2.amazonaws.com\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/wonjun.sung/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[INFO] AWS ECR | docker login result: \n",
      " Login Succeeded\n",
      "\u001b[0m\n",
      "\u001b[96m[INFO] Target AWS ECR repository: \n",
      "ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/train/test_0111_2\u001b[0m\n",
      "\u001b[96m\n",
      "[INFO] AWS ECR create-repository response: \n",
      "{\n",
      "    \"repository\": {\n",
      "        \"repositoryArn\": \"arn:aws:ecr:ap-northeast-2:086558720570:repository/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/train/test_0111_2\",\n",
      "        \"registryId\": \"086558720570\",\n",
      "        \"repositoryName\": \"ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/train/test_0111_2\",\n",
      "        \"repositoryUri\": \"086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/train/test_0111_2\",\n",
      "        \"createdAt\": 1704961478.047,\n",
      "        \"imageTagMutability\": \"MUTABLE\",\n",
      "        \"imageScanningConfiguration\": {\n",
      "            \"scanOnPush\": true\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## ECR 등록\n",
    "#----------------------------------------#\n",
    "#              사용자 입력                #\n",
    "#----------------------------------------#\n",
    "docker_or_buildah = 'docker' #buildah\n",
    "#----------------------------------------#\n",
    "\n",
    "if docker_or_buildah == 'docker':\n",
    "    ## docker login 실행 \n",
    "    registerer.set_aws_ecr(docker=True)\n",
    "    \n",
    "elif docker_or_buildah == 'buildah':\n",
    "    ## buildah login 실행 (docker in docker) \n",
    "    tags = [\n",
    "        \"Key=Company,Value=LGE\",\n",
    "        \"Key=Owner,Value=IC360\",\n",
    "        \"Key=HQ,Value=CDO\",\n",
    "        \"Key=Division,Value=CDO\",\n",
    "        \"Key=Infra Region,Value=KIC\",\n",
    "        \"Key=Service Mode,Value=DE\",\n",
    "        \"Key=Cost Type,Value=COMPUTING\",\n",
    "        \"Key=Project,Value=CIS\",\n",
    "        \"Key=Sub Project,Value=CISM\",\n",
    "        \"Key=System,Value=AIDX\"\n",
    "    ]\n",
    "    registerer.set_aws_ecr(docker=False, tags=tags) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Docker Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  131.8MB\n",
      "Step 1/12 : FROM public.ecr.aws/docker/library/python:3.10-slim-bullseye\n",
      " ---> f4856e227921\n",
      "Step 2/12 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> 393267c5fe52\n",
      "Step 3/12 : RUN apt-get install -y apt-utils\n",
      " ---> Using cache\n",
      " ---> 4109b4d06a15\n",
      "Step 4/12 : RUN apt-get install -y --no-install-recommends          build-essential          wget          ca-certificates          git          gcc     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 2d6b639a84fb\n",
      "Step 5/12 : ENV LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> d4f1428fb9f3\n",
      "Step 6/12 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> fef92aa61620\n",
      "Step 7/12 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 26f22b9a6ceb\n",
      "Step 8/12 : ENV SOLUTION_PIPELINE_MODE='train'\n",
      " ---> Using cache\n",
      " ---> 61c7c0412605\n",
      "Step 9/12 : ENV PATH=\"/framework:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> cf098a989f20\n",
      "Step 10/12 : COPY /alo /framework\n",
      " ---> Using cache\n",
      " ---> 54b13edd6a71\n",
      "Step 11/12 : WORKDIR /framework\n",
      " ---> Using cache\n",
      " ---> 95161f440727\n",
      "Step 12/12 : CMD [\"python\", \"main.py\"]\n",
      " ---> Using cache\n",
      " ---> acafdf1dafa9\n",
      "Successfully built acafdf1dafa9\n",
      "Successfully tagged 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/train/test_0111_2:latest\n"
     ]
    }
   ],
   "source": [
    "# docker build \n",
    "registerer.build_docker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ECR에 docker image를 push 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/train/test_0111_2]\n",
      "b403e7e0a94a: Preparing\n",
      "71631b3bc0e1: Preparing\n",
      "287cc957cc31: Preparing\n",
      "b73b6541d032: Preparing\n",
      "2f33dd8c934e: Preparing\n",
      "6b3d0b913afc: Preparing\n",
      "277bd6c0df20: Preparing\n",
      "12d601beac88: Preparing\n",
      "1b6fd3ad4ce6: Preparing\n",
      "12d601beac88: Waiting\n",
      "277bd6c0df20: Waiting\n",
      "1b6fd3ad4ce6: Waiting\n",
      "6b3d0b913afc: Waiting\n",
      "287cc957cc31: Pushed\n",
      "2f33dd8c934e: Pushed\n",
      "6b3d0b913afc: Pushed\n",
      "b73b6541d032: Pushed\n",
      "12d601beac88: Pushed\n",
      "277bd6c0df20: Pushed\n",
      "1b6fd3ad4ce6: Pushed\n",
      "b403e7e0a94a: Pushed\n",
      "71631b3bc0e1: Pushed\n",
      "latest: digest: sha256:99fedec6275624bd94e6980a10c12a86889d3c0a4686907cf424b66461e3e29a size: 2217\n",
      "Removing login credentials for https://index.docker.io/v1/\n"
     ]
    }
   ],
   "source": [
    "registerer.docker_push()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> solution_metadata.yaml에 container uri를 넣어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[INFO] Completes setting << container_uri >> in solution_metadata.yaml: \n",
      "086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/train/test_0111_2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "registerer.set_container_uri() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-5**. Training 에 사용될 User Parameters 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> solution_metadata.yaml에 사용자 파라미터 및 artifacts 저장 경로를 넣어줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "[{self.pipeline}] Success updating << user_parameters >> in the solution_metadata.yaml\u001b[0m\n",
      "\u001b[92m[INFO] Completes setting << artifact_uri >> in solution_metadata.yaml: \n",
      "s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/artifacts/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## user parameters 입력\n",
    "registerer.set_user_parameters(user_parameters)\n",
    "## artifact 저장 경로 지정\n",
    "registerer.set_artifacts_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-6**. Training 에 사용될 Cloud resource 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 컴퓨팅 자원을 선택합니다. (default: standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "[train] Success updating << resource >> in the solution_metadata.yaml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------#\n",
    "#              사용자 입력                #\n",
    "#----------------------------------------#\n",
    "\n",
    "train_resource = 'standard'\n",
    "\n",
    "#----------------------------------------#\n",
    "\n",
    "# 클라우드 컴퓨팅 리소스 선택 \n",
    "registerer.set_resource(train_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO : INFERENCE USER PARAMTERS 등록 과정 추가 필요 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-7**. Inference 용 Sample Data 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "<< solution_metadata.yaml >> updated. - appended pipeline: inference\u001b[0m\n",
      "\u001b[96m\n",
      "[INFO] AWS region: ap-northeast-2\u001b[0m\n",
      "\u001b[92m\n",
      "[INFO] AWS S3 access check: OK\u001b[0m\n",
      "\u001b[96m\n",
      "[INFO] Start uploading << data >> into S3 from local folder:\n",
      " /home/wonjun.sung/wrangler_test/alo/input/inference/\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/inference/data/test/20231006_16_57_06_LR23235A0040_ETC1(2)_OK.csv\u001b[0m\n",
      "\u001b[92m\n",
      "Success updating solution_metadata.yaml - << dataset_uri >> info. / pipeline: inference\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "pipeline = \"inference\"\n",
    "###################\n",
    "# inference pipeline을 solution_metadata.yaml에 추가하고, 현재 registerer의 pipeline type을 inference로 변경 \n",
    "registerer.append_pipeline(pipeline)\n",
    "# s3 데이터 업로드\n",
    "# 이전에 있던 데이터는 지워집니다\n",
    "registerer.s3_access_check('data')\n",
    "registerer.s3_upload_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m\n",
      "[INFO] AWS region: ap-northeast-2\u001b[0m\n",
      "\u001b[92m\n",
      "[INFO] AWS S3 access check: OK\u001b[0m\n",
      "\u001b[96m\n",
      "[INFO] Start uploading << inference artifacts >> into S3 from local folder:\n",
      " /home/wonjun.sung/wrangler_test/alo/.temp_artifacts_dir/\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/inference/artifacts/inference_artifacts.tar.gz\u001b[0m\n",
      "\u001b[92m\n",
      "Success updating solution_metadata.yaml - << artifact_uri >> info. / pipeline: inference\u001b[0m\n",
      "\u001b[96m\n",
      "[INFO] Start uploading << model >> into S3 from local folder:\n",
      " /home/wonjun.sung/wrangler_test/alo/.temp_model_dir/\u001b[0m\n",
      "\u001b[92m\n",
      "Success uploading into S3: \n",
      "s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/artifacts/model.tar.gz\u001b[0m\n",
      "\u001b[92m\n",
      "Success updating solution_metadata.yaml - << model_uri >> info. / pipeline: inference\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "registerer.s3_access_check('artifacts')\n",
    "registerer.s3_upload_artifacts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-8**. Inference 용 Docker Container 제작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> DOCKERFILE을 셋팅합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccess DOCKERFILE setting. \n",
      " - pipeline: inference\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# DOCKERFILE setting\n",
    "registerer.set_docker_contatiner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AWS ECR에 docker 등록을 위한 repository를 생성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[INFO] target AWS ECR url: \n",
      "086558720570.dkr.ecr.ap-northeast-2.amazonaws.com\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/wonjun.sung/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[INFO] AWS ECR | docker login result: \n",
      " Login Succeeded\n",
      "\u001b[0m\n",
      "\u001b[96m[INFO] Target AWS ECR repository: \n",
      "ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/inference/test_0111_2\u001b[0m\n",
      "\u001b[96m\n",
      "[INFO] AWS ECR create-repository response: \n",
      "{\n",
      "    \"repository\": {\n",
      "        \"repositoryArn\": \"arn:aws:ecr:ap-northeast-2:086558720570:repository/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/inference/test_0111_2\",\n",
      "        \"registryId\": \"086558720570\",\n",
      "        \"repositoryName\": \"ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/inference/test_0111_2\",\n",
      "        \"repositoryUri\": \"086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/inference/test_0111_2\",\n",
      "        \"createdAt\": 1704961890.869,\n",
      "        \"imageTagMutability\": \"MUTABLE\",\n",
      "        \"imageScanningConfiguration\": {\n",
      "            \"scanOnPush\": true\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## ECR 등록\n",
    "#----------------------------------------#\n",
    "#              사용자 입력                #\n",
    "#----------------------------------------#\n",
    "docker_or_buildah = 'docker'\n",
    "#----------------------------------------#\n",
    "\n",
    "if docker_or_buildah == 'docker':\n",
    "    ## docker login 실행 \n",
    "    registerer.set_aws_ecr(docker=True)\n",
    "    \n",
    "elif docker_or_buildah == 'buildah':\n",
    "    ## buildah login 실행 (docker in docker) \n",
    "    tags = [\n",
    "        \"Key=Company,Value=LGE\",\n",
    "        \"Key=Owner,Value=IC360\",\n",
    "        \"Key=HQ,Value=CDO\",\n",
    "        \"Key=Division,Value=CDO\",\n",
    "        \"Key=Infra Region,Value=KIC\",\n",
    "        \"Key=Service Mode,Value=DE\",\n",
    "        \"Key=Cost Type,Value=COMPUTING\",\n",
    "        \"Key=Project,Value=CIS\",\n",
    "        \"Key=Sub Project,Value=CISM\",\n",
    "        \"Key=System,Value=AIDX\"\n",
    "    ]\n",
    "    registerer.set_aws_ecr(docker=False, tags=tags) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Build docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  131.8MB\n",
      "Step 1/14 : FROM public.ecr.aws/docker/library/python:3.10-slim-bullseye\n",
      " ---> f4856e227921\n",
      "Step 2/14 : RUN apt-get update  --fix-missing\n",
      " ---> Using cache\n",
      " ---> 82840692da38\n",
      "Step 3/14 : RUN apt-get install -y apt-utils\n",
      " ---> Using cache\n",
      " ---> aabf0e406dde\n",
      "Step 4/14 : RUN apt-get install -y --no-install-recommends         --fix-missing          build-essential          wget          ca-certificates          git          gcc          docker.io          procps          jq     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 47301c76788c\n",
      "Step 5/14 : ENV LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 0e4b84ce3ba3\n",
      "Step 6/14 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 1a2160dcf90f\n",
      "Step 7/14 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> faac9d83db02\n",
      "Step 8/14 : ENV SOLUTION_PIPELINE_MODE='inference'\n",
      " ---> Using cache\n",
      " ---> ded9bd803d5f\n",
      "Step 9/14 : ENV PATH=\"/framework:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 8e47bb155b6d\n",
      "Step 10/14 : COPY /alo /framework/\n",
      " ---> Using cache\n",
      " ---> 4edc2c572d05\n",
      "Step 11/14 : COPY /solution_metadata.yaml /framework/\n",
      " ---> 1bad285afaa0\n",
      "Step 12/14 : RUN mkdir -p /alo/artifacts/inference_artifacts/log &&     mkdir -p /alo/edgeapp_interface/input &&     mkdir /alo/edgeapp_interface/output\n",
      " ---> Running in a1baa6a71b9b\n",
      "Removing intermediate container a1baa6a71b9b\n",
      " ---> 8fd8b15b89cf\n",
      "Step 13/14 : WORKDIR /framework/\n",
      " ---> Running in 6c9be7e5f2c8\n",
      "Removing intermediate container 6c9be7e5f2c8\n",
      " ---> 06a428a66fa0\n",
      "Step 14/14 : CMD sh -c 'python3 main.py --loop True --mode inference --system \"$(jq -r \".\" /framework/solution_metadata.yaml)\"'\n",
      " ---> Running in 3e4fd63118f7\n",
      "Removing intermediate container 3e4fd63118f7\n",
      " ---> 4263279c0ec6\n",
      "Successfully built 4263279c0ec6\n",
      "Successfully tagged 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/inference/test_0111_2:latest\n"
     ]
    }
   ],
   "source": [
    "# docker build \n",
    "registerer.build_docker()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AWS ECR에 docker 이미지를 push 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/inference/test_0111_2]\n",
      "a932931b0096: Preparing\n",
      "e0bbb77f7c95: Preparing\n",
      "f02945d54aa8: Preparing\n",
      "9fc9b89bc293: Preparing\n",
      "dd179f827777: Preparing\n",
      "322e9715f19a: Preparing\n",
      "2f33dd8c934e: Preparing\n",
      "6b3d0b913afc: Preparing\n",
      "277bd6c0df20: Preparing\n",
      "12d601beac88: Preparing\n",
      "1b6fd3ad4ce6: Preparing\n",
      "6b3d0b913afc: Waiting\n",
      "12d601beac88: Waiting\n",
      "277bd6c0df20: Waiting\n",
      "1b6fd3ad4ce6: Waiting\n",
      "322e9715f19a: Waiting\n",
      "2f33dd8c934e: Waiting\n",
      "e0bbb77f7c95: Pushed\n",
      "a932931b0096: Pushed\n",
      "dd179f827777: Pushed\n",
      "6b3d0b913afc: Pushed\n",
      "2f33dd8c934e: Pushed\n",
      "12d601beac88: Pushed\n",
      "277bd6c0df20: Pushed\n",
      "322e9715f19a: Pushed\n",
      "f02945d54aa8: Pushed\n",
      "1b6fd3ad4ce6: Pushed\n",
      "9fc9b89bc293: Pushed\n",
      "latest: digest: sha256:c224eaa8e50b7eaccf567099508da94f4c1396c71f92aa01ba0255a941b2623e size: 2632\n",
      "Removing login credentials for https://index.docker.io/v1/\n"
     ]
    }
   ],
   "source": [
    "registerer.docker_push()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> solution_metadata.yaml에 container uri를 넣어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[INFO] Completes setting << container_uri >> in solution_metadata.yaml: \n",
      "086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/inference/test_0111_2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "registerer.set_container_uri() # uri도 그냥 입력되게 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-9**. Inference 용 User Parameters 제작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> solution_metadata.yaml에 사용자 파라미터, artifacts 경로 등을 넣어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': [{'concat_dataframes': True,\n",
       "    'drop_columns': None,\n",
       "    'encoding': None,\n",
       "    'groupkey_columns': None,\n",
       "    'input_path': 'train',\n",
       "    'time_column': None,\n",
       "    'use_all_x': False,\n",
       "    'x_columns': ['Count',\n",
       "     'Converted Torque',\n",
       "     'angle_min',\n",
       "     'angle_mean',\n",
       "     'angle_median',\n",
       "     'angle_std',\n",
       "     'angle_max',\n",
       "     'torque_min',\n",
       "     'torque_mean',\n",
       "     'torque_median',\n",
       "     'torque_std',\n",
       "     'torque_max'],\n",
       "    'y_column': 'current_cls'}],\n",
       "  'step': 'input'},\n",
       " {'args': [{'ignore_label_class': 'NG',\n",
       "    'label_sampling': True,\n",
       "    'label_sampling_num': {'NG': 1, 'OK': 10},\n",
       "    'label_sampling_num_type': 'compare',\n",
       "    'negative_target_class': None,\n",
       "    'sampling_groupkey_columns': None,\n",
       "    'sampling_method': 'cluster',\n",
       "    'sampling_num': None,\n",
       "    'sampling_num_type': None,\n",
       "    'sampling_type': 'under'}],\n",
       "  'step': 'sampling'},\n",
       " {'args': [{'data_split_method': 'cross_validate',\n",
       "    'evaluation_metric': 'accuracy',\n",
       "    'model_list': ['lgb', 'rf', 'cb'],\n",
       "    'model_type': 'classification',\n",
       "    'num_hpo': 3,\n",
       "    'param_range': {'cb': {'max_depth': [5, 9], 'n_estimators': [100, 500]},\n",
       "     'gbm': {'max_depth': [5, 7], 'n_estimators': [300, 500]},\n",
       "     'lgb': {'max_depth': [5, 9], 'n_estimators': [300, 500]},\n",
       "     'ngb': {'col_sample': [0.6, 0.8], 'n_estimators': [100, 300]},\n",
       "     'rf': {'max_depth': 6, 'n_estimators': [300, 500]}},\n",
       "    'shap_ratio': 1.0}],\n",
       "  'step': 'train'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- step:  <class 'str'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9042825b416e49b1a2efc90375a00a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='concat_dataframes', style=CheckboxStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- step:  <class 'str'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064894d92a5049718d5acb85aabc80ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='model_type', style=CheckboxStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- step:  <class 'str'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7948dffdf6e04fe89144ff405c965af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='temp', style=CheckboxStyle(description_width='initial')),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "candidate_params = registerer.set_candidate_parameters()\n",
    "\n",
    "args_checkboxes_dict = {} \n",
    "for step_args in candidate_params:\n",
    "    print('\\n- step: ', type(step_args['step']))\n",
    "    if step_args['args'] == None:\n",
    "        step_args['args'] = list()\n",
    "        # FIXME temp로 되어 있어서 수정이 필요\n",
    "        step_args['args'].append({\"temp\": \"temp\"})\n",
    "    checkboxes = [widgets.Checkbox(value=False, description=arg, style={'description_width': 'initial'}) for arg in step_args['args'][0].keys()]\n",
    "    args_checkboxes_dict[step_args['step']] = checkboxes\n",
    "    output = widgets.VBox(children=checkboxes)\n",
    "    display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME boolean은 single selection이라 생각하고 유저 가이드도 필요할듯\n",
    "# FIXME x_columns 같은 string과 multi-selection의 경계가 애매 ? > x_columns는 몇개가 될지 모르니 selection이 아니네 \n",
    "# args type input \n",
    "type_dropdown_dict = {}\n",
    "\n",
    "type_list = ['float', 'int', 'string', 'single_selection', 'multi_selection']\n",
    "for step, checkboxes in args_checkboxes_dict.items(): # cbs: checkboxs\n",
    "    selected_args = [c.description for c in checkboxes if c.value == True] # checked list  \n",
    "    if len(selected_args) == 0: \n",
    "        continue \n",
    "    print('\\n- step: ', step)\n",
    "    for arg in selected_args:         \n",
    "        dropdown = widgets.Dropdown(options=type_list, description=arg, value=None, style={'description_width': 'initial'})\n",
    "        type_dropdown_dict[arg] = dropdown\n",
    "        display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3407ae683e9446668001c1f4925f454e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Accordion(), Accordion(), Accordion()), selected_index=0, titles=('input', 'inference', 'output'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accordion_list = []\n",
    "for step, checkboxes in args_checkboxes_dict.items(): \n",
    "    selected_args = [c.description for c in checkboxes if c.value == True] # checked list  \n",
    "    text_widgets_list = [] \n",
    "    for arg in selected_args: \n",
    "        selected_type = type_dropdown_dict[arg].value\n",
    "        assert selected_type is not None \n",
    "        arg_format = get_arg_format(selected_type)\n",
    "        text_widgets_list.append(get_text_widgets(arg_format=arg_format, arg_name=arg, arg_type=selected_type))\n",
    "        \n",
    "    accordion = widgets.Accordion(children=[widgets.VBox(children=text_widgets) for text_widgets in text_widgets_list])\n",
    "    for idx, arg in enumerate(selected_args):\n",
    "        accordion.set_title(idx, arg)\n",
    "    accordion_list.append((step, accordion)) # [[step, accordion]]\n",
    "    \n",
    "tab_nest = widgets.Tab()\n",
    "tab_nest.children = [step_accordion[1] for step_accordion in accordion_list]\n",
    "for idx, step_accordion in enumerate(accordion_list): \n",
    "    tab_nest.set_title(idx, step_accordion[0])\n",
    "display(tab_nest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_metadata.yaml에 user parameters 셋팅 \n",
    "user_parameters = [] \n",
    "for step, accordion in accordion_list: \n",
    "    args_list = []\n",
    "    if len(accordion.children) != 0:\n",
    "        for vbox in accordion.children: # vbox 하나가 arg 하나에 대응됨  \n",
    "            args = {tbox.description: tbox.value for tbox in vbox.children}\n",
    "            args_list.append(convert_args_type(args))\n",
    "    user_parameters.append({'step': step, 'args': args_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "[{self.pipeline}] Success updating << user_parameters >> in the solution_metadata.yaml\u001b[0m\n",
      "\u001b[92m[INFO] Completes setting << artifact_uri >> in solution_metadata.yaml: \n",
      "s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/inference/artifacts/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## user parameters 입력\n",
    "registerer.set_user_parameters(user_parameters)\n",
    "## artifact 경로 설정 \n",
    "registerer.set_artifacts_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> solution_metadata.yaml에 model 경로를 넣어줍니다. <u>(추론 시에만 필요합니다.)</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[INFO] Completes setting << model_uri >> in solution_metadata.yaml: \n",
      "s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/artifacts/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "registerer.set_model_uri() # 주의: model은 train artifacts 경로에 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-10**. Inference 용 Resource 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 컴퓨팅 자원을 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "[inference] Success updating << resource >> in the solution_metadata.yaml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------#\n",
    "#              사용자 입력                #\n",
    "#----------------------------------------#\n",
    "\n",
    "inference_resource = 'standard'\n",
    "\n",
    "#----------------------------------------#\n",
    "\n",
    "registerer.set_resource(inference_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-11**. Description 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> solution_metadata.yaml에 description을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "<< solution_metadata.yaml >> updated. \n",
      "- solution metadata description:\n",
      " {'icon': 's3://s3-an2-hyunsoo-dev-magna/icons/test_0111_2/icon.png', 'title': 'UI solution title', 'overview': 'AI Advisor Test', 'input_data': 's3-an2-hyunsoo-dev-magnaTest input s3 bucket', 'output_data': 's3-an2-hyunsoo-dev-magnaTest input s3 bucket', 'user_parameters': 'Test params', 'algorithm': 'ALO'}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# [임시] 수정필요 \n",
    "#----------------------------------------#\n",
    "#              사용자 입력                #\n",
    "#----------------------------------------#\n",
    "user_description ={\n",
    "    'title': \"UI solution title\",\n",
    "    \n",
    "    'overview': \"AI Advisor Test\",\n",
    "\n",
    "    'input_data': \"Test input s3 bucket\",\n",
    "    \n",
    "    'output_data': \"Test output s3 bucket\",\n",
    "\n",
    "    'user_parameters': \"Test params\",\n",
    "    \n",
    "    'algorithm': \"ALO\"\n",
    "}\n",
    "#----------------------------------------#\n",
    "\n",
    "registerer.set_description(user_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "wrangler_file = os.path.abspath(os.path.join('../../..')) + \"/wrangler/wrangler:1.1_amd_bolt_1.0/wrangler.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-12**. AI Solution & Instance 등록 !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AI Solution 등록을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wrangler 정보 등록 \n",
    "# [임시] 변경 예정\n",
    "registerer.set_wrangler(wrangler_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#----------------------------------------#\n",
    "#              사용자 입력                #\n",
    "#----------------------------------------#\n",
    "\n",
    "# Edge관련 정보 등록\n",
    "edgeconductor_interface = {\n",
    "            'support_labeling': False,\n",
    "            \n",
    "            'inference_result_datatype': 'table', # 'image'\n",
    "            \n",
    "            'train_datatype': 'table' # 'image'\n",
    "        }\n",
    "\n",
    "#----------------------------------------#\n",
    "\n",
    "registerer.set_edge(edgeconductor_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': 1,\n",
       " 'name': 'test_0111_2',\n",
       " 'description': {'icon': 's3://s3-an2-hyunsoo-dev-aia/icons/ic_customer_classification.svg',\n",
       "  'title': 'UI solution title',\n",
       "  'overview': 'AI Advisor Test',\n",
       "  'input_data': 's3-an2-hyunsoo-dev-magnaTest input s3 bucket',\n",
       "  'output_data': 's3-an2-hyunsoo-dev-magnaTest input s3 bucket',\n",
       "  'user_parameters': 'Test params',\n",
       "  'algorithm': 'ALO'},\n",
       " 'pipeline': [{'type': 'train',\n",
       "   'parameters': {'candidate_parameters': [{'args': [{'concat_dataframes': True,\n",
       "        'drop_columns': None,\n",
       "        'encoding': None,\n",
       "        'groupkey_columns': None,\n",
       "        'input_path': 'train',\n",
       "        'time_column': None,\n",
       "        'use_all_x': False,\n",
       "        'x_columns': ['Count',\n",
       "         'Converted Torque',\n",
       "         'angle_min',\n",
       "         'angle_mean',\n",
       "         'angle_median',\n",
       "         'angle_std',\n",
       "         'angle_max',\n",
       "         'torque_min',\n",
       "         'torque_mean',\n",
       "         'torque_median',\n",
       "         'torque_std',\n",
       "         'torque_max'],\n",
       "        'y_column': 'current_cls'}],\n",
       "      'step': 'input'},\n",
       "     {'args': [{'ignore_label_class': 'NG',\n",
       "        'label_sampling': True,\n",
       "        'label_sampling_num': {'NG': 1, 'OK': 10},\n",
       "        'label_sampling_num_type': 'compare',\n",
       "        'negative_target_class': None,\n",
       "        'sampling_groupkey_columns': None,\n",
       "        'sampling_method': 'cluster',\n",
       "        'sampling_num': None,\n",
       "        'sampling_num_type': None,\n",
       "        'sampling_type': 'under'}],\n",
       "      'step': 'sampling'},\n",
       "     {'args': [{'data_split_method': 'cross_validate',\n",
       "        'evaluation_metric': 'accuracy',\n",
       "        'model_list': ['lgb', 'rf', 'cb'],\n",
       "        'model_type': 'classification',\n",
       "        'num_hpo': 3,\n",
       "        'param_range': {'cb': {'max_depth': [5, 9],\n",
       "          'n_estimators': [100, 500]},\n",
       "         'gbm': {'max_depth': [5, 7], 'n_estimators': [300, 500]},\n",
       "         'lgb': {'max_depth': [5, 9], 'n_estimators': [300, 500]},\n",
       "         'ngb': {'col_sample': [0.6, 0.8], 'n_estimators': [100, 300]},\n",
       "         'rf': {'max_depth': 6, 'n_estimators': [300, 500]}},\n",
       "        'shap_ratio': 1.0}],\n",
       "      'step': 'train'}],\n",
       "    'user_parameters': [{'step': 'input', 'args': []},\n",
       "     {'step': 'sampling', 'args': []},\n",
       "     {'step': 'train', 'args': []}],\n",
       "    'selected_user_parameters': [{'step': 'input', 'args': {}},\n",
       "     {'step': 'sampling', 'args': {}},\n",
       "     {'step': 'train', 'args': {}}]},\n",
       "   'dataset_uri': ['s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/'],\n",
       "   'artifact_uri': 's3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/artifacts/',\n",
       "   'container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/train/test_0111_2',\n",
       "   'resource': {'default': 'standard'}},\n",
       "  {'type': 'inference',\n",
       "   'dataset_uri': ['s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/inference/data/'],\n",
       "   'artifact_uri': 's3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/inference/artifacts/',\n",
       "   'model_uri': 's3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/artifacts/',\n",
       "   'container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/inference/test_0111_2',\n",
       "   'parameters': {'candidate_parameters': [{'args': [{'concat_dataframes': True,\n",
       "        'drop_columns': None,\n",
       "        'encoding': None,\n",
       "        'groupkey_columns': None,\n",
       "        'input_path': 'test',\n",
       "        'time_column': None,\n",
       "        'use_all_x': False,\n",
       "        'x_columns': ['Count',\n",
       "         'Converted Torque',\n",
       "         'angle_min',\n",
       "         'angle_mean',\n",
       "         'angle_median',\n",
       "         'angle_std',\n",
       "         'angle_max',\n",
       "         'torque_min',\n",
       "         'torque_mean',\n",
       "         'torque_median',\n",
       "         'torque_std',\n",
       "         'torque_max'],\n",
       "        'y_column': None}],\n",
       "      'step': 'input'},\n",
       "     {'args': [{'model_type': 'classification', 'run_shapley': False}],\n",
       "      'step': 'inference'},\n",
       "     {'args': [{'temp': 'temp'}], 'step': 'output'}],\n",
       "    'user_parameters': [{'step': 'input', 'args': []},\n",
       "     {'step': 'inference', 'args': []},\n",
       "     {'step': 'output', 'args': []}],\n",
       "    'selected_user_parameters': [{'step': 'input', 'args': {}},\n",
       "     {'step': 'inference', 'args': {}},\n",
       "     {'step': 'output', 'args': {}}]},\n",
       "   'resource': {'default': 'standard'}}],\n",
       " 'wrangler_code_uri': 'from time import time\\nimport os\\nimport csv\\nimport numpy as np\\nimport pandas as pd\\nimport re\\nfrom apscheduler.schedulers.background import BackgroundScheduler\\nimport shutil\\n\\nimport argparse\\n\\nfrom redisqueue import RedisQueue\\nfrom logger import Logger\\n\\nclass Wrangler:\\n    def __init__(self):\\n        # 명령줄 인수를 파싱하는 데 사용될 Parser 초기화\\n        #self.parser = argparse.ArgumentParser(description=\"Process the data path.\")\\n        #self.parser.add_argument(\\'--data_path\\', type=str, help=\"The path to the data file.\")\\n        self.logger = Logger(__name__)\\n\\n        # data_path 변수 초기화\\n        self.data_path = \"/alo/edgeapp_interface/input\"\\n\\n        self.scheduler = BackgroundScheduler()\\n        self.register_schedule()\\n\\n        self.pattern_order = re.compile(r\"\\\\(*[0-9]+\\\\)*_(OK|NG|OTHER)\")\\n        self.pattern_number = re.compile(r\"[0-9]+\")\\n\\n        self.wrangler_request_queue = RedisQueue(\\'request_wrangler\\', host=\\'localhost\\', port=6379, db=0)\\n        self.wrangler_finish_queue = RedisQueue(\\'finish_wrangler\\', host=\\'localhost\\', port=6379, db=0)\\n        \\n        self.dummy_flag = False\\n\\n    def register_schedule(self):\\n        self.logger.debug(f\\'scheduler: {self.scheduler}\\')\\n        self.scheduler.add_job(\\n            self._run_wrangler_request_queue,\\n            id=\\'_run_wrangler_request_queue\\')\\n\\n    def unregister_schedule(self):\\n        self.logger.debug()\\n        self.scheduler.remove_job(\\'_run_wrangler_request_queue\\')\\n\\n    def wrangling(self, data_path):\\n        start = time()\\n        csv_files = os.path.basename(data_path)\\n        output_path = os.path.join(self.data_path, csv_files)\\n        \\n        if self.dummy_flag:\\n            shutil.copy2(data_path, output_path)\\n\\n        else:\\n            with open(data_path, \\'r\\') as f:\\n                lines = csv.reader(f)\\n                columns = next(lines)\\n                row_data = next(lines)\\n\\n            if row_data[-1] == \\'\\' :\\n                row_data = row_data[:-1]\\n\\n            count_num = int(row_data[4])\\n            torque_angle_data = row_data[-(count_num*2):]\\n            torque = np.array(torque_angle_data[:count_num]).astype(float)\\n            angle = np.array(torque_angle_data[count_num:]).astype(int)\\n\\n            if torque[-1] == 0 and len(torque) > 1:\\n                torque = torque[:-1]\\n            if angle[-1] == 0 and len(angle) > 1:\\n                angle = angle[:-1]\\n\\n            angle_max = max(angle)\\n            angle_min = min(angle)\\n            angle_mean = np.mean(angle)\\n            angle_median = np.median(angle)\\n            angle_std = np.std(angle)\\n\\n            torque_max = max(torque)\\n            torque_min = min(torque)\\n            torque_mean = np.mean(torque)\\n            torque_median = np.median(torque)\\n            torque_std = np.std(torque)\\n\\n            columns = columns[:-1]\\n\\n            df_initial = pd.DataFrame(np.array(row_data[:len(columns)]).reshape(1, -1), columns=columns)\\n\\n            process_order = 0\\n            match = self.pattern_order.search(data_path)\\n            if match is not None :\\n                matched_str = match.group()\\n                match_number = self.pattern_number.search(matched_str)\\n                if match_number is not None :\\n                    process_order = match_number.group()\\n            print(f\\'### wrangler process order : {process_order}\\')\\n\\n            #self.load_time += time() - start\\n            print(\\'### load data and statistics time : \\', time() - start)\\n\\n            start = time()\\n            # torque, angle raw data into columns\\n            df_torque = pd.DataFrame([torque], columns=[\\'torque_\\'+str(i) for i in range(len(torque))])\\n            df_angle = pd.DataFrame([angle], columns=[\\'angle_\\'+str(i) for i in range(len(angle))])\\n\\n            # stats. columns\\n            col_list = [\\'file_name\\', \\'path\\', \\'process_order\\', \\'angle_max\\', \\'angle_min\\', \\'angle_mean\\', \\'angle_median\\', \\'angle_std\\', \\'torque_max\\', \\'torque_min\\', \\'torque_mean\\', \\'torque_median\\', \\'torque_std\\']\\n            value_list = [csv_files, output_path, process_order, angle_max, angle_min, angle_mean, angle_median, angle_std, torque_max, torque_min, torque_mean, torque_median, torque_std]\\n            df_input = pd.DataFrame([value_list], columns=col_list)\\n\\n            # concat all the columns\\n            df_input_data = pd.concat((df_initial, df_input, df_torque, df_angle), axis=1, sort=False) #sort false 안하면 angle_1, angle_10 .. 순서로 정렬됨\\n\\n            df_input_data.to_csv(output_path, index=False)\\n            #self.create_df_time += time() - start\\n            print(\\'### data frame processing time : \\', time() - start)\\n        \\n        return csv_files\\n\\n    def _run_wrangler_request_queue(self):\\n        self.logger.debug()\\n        while(True):\\n            msg = self.wrangler_request_queue.rget(isBlocking=True) # 큐가 비어있을 때 대기\\n            if msg is not None:\\n                msg_str = msg.decode(\\'utf-8\\')\\n                print(\\'got req from EdgeAPP: \\', msg_str) \\n                print(\\'-----------------------------------------------------------\\')\\n                try:\\n                    wrangler_data = self.wrangling(msg_str)\\n                except Exception as e:\\n                    print(\"wrangler error:\", str(e))\\n                    wrangler_data = \\'error\\'\\n                \\n                self.wrangler_finish_queue.rput(wrangler_data) \\n\\n\\nif __name__ == \"__main__\":\\n    wrangler = Wrangler()\\n    wrangler.scheduler.start()\\n',\n",
       " 'wrangler_dataset_uri': '',\n",
       " 'edgeconductor_interface': {'support_labeling': False,\n",
       "  'inference_result_datatype': 'table',\n",
       "  'train_datatype': 'table'},\n",
       " 'edgeapp_interface': {'redis_server_uri': ''}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIXME icon 등록 임시 \n",
    "registerer.sm_yaml['description']['icon'] = 's3://s3-an2-hyunsoo-dev-aia/icons/ic_customer_classification.svg'\n",
    "registerer.sm_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[INFO] AI solution register response: \n",
      " {'id': '681952df-a6a9-4d15-8935-96768f4eada9', 'name': 'test_0111_2', 'scope_ws': 'magna-ws', 'version': {'id': '0a0fd6d2-39e2-47af-9fc1-cad3ac3e383f', 'version': 1, 'metadata_dict': {'version': 1, 'name': 'test_0111_2', 'description': {'icon': 's3://s3-an2-hyunsoo-dev-aia/icons/ic_customer_classification.svg', 'title': 'UI solution title', 'overview': 'AI Advisor Test', 'input_data': 's3-an2-hyunsoo-dev-magnaTest input s3 bucket', 'output_data': 's3-an2-hyunsoo-dev-magnaTest input s3 bucket', 'user_parameters': 'Test params', 'algorithm': 'ALO'}, 'pipeline': [{'type': 'train', 'parameters': {'candidate_parameters': [{'args': [{'concat_dataframes': True, 'drop_columns': None, 'encoding': None, 'groupkey_columns': None, 'input_path': 'train', 'time_column': None, 'use_all_x': False, 'x_columns': ['Count', 'Converted Torque', 'angle_min', 'angle_mean', 'angle_median', 'angle_std', 'angle_max', 'torque_min', 'torque_mean', 'torque_median', 'torque_std', 'torque_max'], 'y_column': 'current_cls'}], 'step': 'input'}, {'args': [{'ignore_label_class': 'NG', 'label_sampling': True, 'label_sampling_num': {'NG': 1, 'OK': 10}, 'label_sampling_num_type': 'compare', 'negative_target_class': None, 'sampling_groupkey_columns': None, 'sampling_method': 'cluster', 'sampling_num': None, 'sampling_num_type': None, 'sampling_type': 'under'}], 'step': 'sampling'}, {'args': [{'data_split_method': 'cross_validate', 'evaluation_metric': 'accuracy', 'model_list': ['lgb', 'rf', 'cb'], 'model_type': 'classification', 'num_hpo': 3, 'param_range': {'cb': {'max_depth': [5, 9], 'n_estimators': [100, 500]}, 'gbm': {'max_depth': [5, 7], 'n_estimators': [300, 500]}, 'lgb': {'max_depth': [5, 9], 'n_estimators': [300, 500]}, 'ngb': {'col_sample': [0.6, 0.8], 'n_estimators': [100, 300]}, 'rf': {'max_depth': 6, 'n_estimators': [300, 500]}}, 'shap_ratio': 1.0}], 'step': 'train'}], 'user_parameters': [{'step': 'input', 'args': []}, {'step': 'sampling', 'args': []}, {'step': 'train', 'args': []}], 'selected_user_parameters': [{'step': 'input', 'args': {}}, {'step': 'sampling', 'args': {}}, {'step': 'train', 'args': {}}]}, 'dataset_uri': ['s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/'], 'artifact_uri': 's3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/artifacts/', 'container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/train/test_0111_2', 'resource': {'default': 'standard'}}, {'type': 'inference', 'dataset_uri': ['s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/inference/data/'], 'artifact_uri': 's3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/inference/artifacts/', 'model_uri': 's3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/artifacts/', 'container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/inference/test_0111_2', 'parameters': {'candidate_parameters': [{'args': [{'concat_dataframes': True, 'drop_columns': None, 'encoding': None, 'groupkey_columns': None, 'input_path': 'test', 'time_column': None, 'use_all_x': False, 'x_columns': ['Count', 'Converted Torque', 'angle_min', 'angle_mean', 'angle_median', 'angle_std', 'angle_max', 'torque_min', 'torque_mean', 'torque_median', 'torque_std', 'torque_max'], 'y_column': None}], 'step': 'input'}, {'args': [{'model_type': 'classification', 'run_shapley': False}], 'step': 'inference'}, {'args': [{'temp': 'temp'}], 'step': 'output'}], 'user_parameters': [{'step': 'input', 'args': []}, {'step': 'inference', 'args': []}, {'step': 'output', 'args': []}], 'selected_user_parameters': [{'step': 'input', 'args': {}}, {'step': 'inference', 'args': {}}, {'step': 'output', 'args': {}}]}, 'resource': {'default': 'standard'}}], 'wrangler_code_uri': 'from time import time\\nimport os\\nimport csv\\nimport numpy as np\\nimport pandas as pd\\nimport re\\nfrom apscheduler.schedulers.background import BackgroundScheduler\\nimport shutil\\n\\nimport argparse\\n\\nfrom redisqueue import RedisQueue\\nfrom logger import Logger\\n\\nclass Wrangler:\\n    def __init__(self):\\n        # 명령줄 인수를 파싱하는 데 사용될 Parser 초기화\\n        #self.parser = argparse.ArgumentParser(description=\"Process the data path.\")\\n        #self.parser.add_argument(\\'--data_path\\', type=str, help=\"The path to the data file.\")\\n        self.logger = Logger(__name__)\\n\\n        # data_path 변수 초기화\\n        self.data_path = \"/alo/edgeapp_interface/input\"\\n\\n        self.scheduler = BackgroundScheduler()\\n        self.register_schedule()\\n\\n        self.pattern_order = re.compile(r\"\\\\(*[0-9]+\\\\)*_(OK|NG|OTHER)\")\\n        self.pattern_number = re.compile(r\"[0-9]+\")\\n\\n        self.wrangler_request_queue = RedisQueue(\\'request_wrangler\\', host=\\'localhost\\', port=6379, db=0)\\n        self.wrangler_finish_queue = RedisQueue(\\'finish_wrangler\\', host=\\'localhost\\', port=6379, db=0)\\n        \\n        self.dummy_flag = False\\n\\n    def register_schedule(self):\\n        self.logger.debug(f\\'scheduler: {self.scheduler}\\')\\n        self.scheduler.add_job(\\n            self._run_wrangler_request_queue,\\n            id=\\'_run_wrangler_request_queue\\')\\n\\n    def unregister_schedule(self):\\n        self.logger.debug()\\n        self.scheduler.remove_job(\\'_run_wrangler_request_queue\\')\\n\\n    def wrangling(self, data_path):\\n        start = time()\\n        csv_files = os.path.basename(data_path)\\n        output_path = os.path.join(self.data_path, csv_files)\\n        \\n        if self.dummy_flag:\\n            shutil.copy2(data_path, output_path)\\n\\n        else:\\n            with open(data_path, \\'r\\') as f:\\n                lines = csv.reader(f)\\n                columns = next(lines)\\n                row_data = next(lines)\\n\\n            if row_data[-1] == \\'\\' :\\n                row_data = row_data[:-1]\\n\\n            count_num = int(row_data[4])\\n            torque_angle_data = row_data[-(count_num*2):]\\n            torque = np.array(torque_angle_data[:count_num]).astype(float)\\n            angle = np.array(torque_angle_data[count_num:]).astype(int)\\n\\n            if torque[-1] == 0 and len(torque) > 1:\\n                torque = torque[:-1]\\n            if angle[-1] == 0 and len(angle) > 1:\\n                angle = angle[:-1]\\n\\n            angle_max = max(angle)\\n            angle_min = min(angle)\\n            angle_mean = np.mean(angle)\\n            angle_median = np.median(angle)\\n            angle_std = np.std(angle)\\n\\n            torque_max = max(torque)\\n            torque_min = min(torque)\\n            torque_mean = np.mean(torque)\\n            torque_median = np.median(torque)\\n            torque_std = np.std(torque)\\n\\n            columns = columns[:-1]\\n\\n            df_initial = pd.DataFrame(np.array(row_data[:len(columns)]).reshape(1, -1), columns=columns)\\n\\n            process_order = 0\\n            match = self.pattern_order.search(data_path)\\n            if match is not None :\\n                matched_str = match.group()\\n                match_number = self.pattern_number.search(matched_str)\\n                if match_number is not None :\\n                    process_order = match_number.group()\\n            print(f\\'### wrangler process order : {process_order}\\')\\n\\n            #self.load_time += time() - start\\n            print(\\'### load data and statistics time : \\', time() - start)\\n\\n            start = time()\\n            # torque, angle raw data into columns\\n            df_torque = pd.DataFrame([torque], columns=[\\'torque_\\'+str(i) for i in range(len(torque))])\\n            df_angle = pd.DataFrame([angle], columns=[\\'angle_\\'+str(i) for i in range(len(angle))])\\n\\n            # stats. columns\\n            col_list = [\\'file_name\\', \\'path\\', \\'process_order\\', \\'angle_max\\', \\'angle_min\\', \\'angle_mean\\', \\'angle_median\\', \\'angle_std\\', \\'torque_max\\', \\'torque_min\\', \\'torque_mean\\', \\'torque_median\\', \\'torque_std\\']\\n            value_list = [csv_files, output_path, process_order, angle_max, angle_min, angle_mean, angle_median, angle_std, torque_max, torque_min, torque_mean, torque_median, torque_std]\\n            df_input = pd.DataFrame([value_list], columns=col_list)\\n\\n            # concat all the columns\\n            df_input_data = pd.concat((df_initial, df_input, df_torque, df_angle), axis=1, sort=False) #sort false 안하면 angle_1, angle_10 .. 순서로 정렬됨\\n\\n            df_input_data.to_csv(output_path, index=False)\\n            #self.create_df_time += time() - start\\n            print(\\'### data frame processing time : \\', time() - start)\\n        \\n        return csv_files\\n\\n    def _run_wrangler_request_queue(self):\\n        self.logger.debug()\\n        while(True):\\n            msg = self.wrangler_request_queue.rget(isBlocking=True) # 큐가 비어있을 때 대기\\n            if msg is not None:\\n                msg_str = msg.decode(\\'utf-8\\')\\n                print(\\'got req from EdgeAPP: \\', msg_str) \\n                print(\\'-----------------------------------------------------------\\')\\n                try:\\n                    wrangler_data = self.wrangling(msg_str)\\n                except Exception as e:\\n                    print(\"wrangler error:\", str(e))\\n                    wrangler_data = \\'error\\'\\n                \\n                self.wrangler_finish_queue.rput(wrangler_data) \\n\\n\\nif __name__ == \"__main__\":\\n    wrangler = Wrangler()\\n    wrangler.scheduler.start()\\n', 'wrangler_dataset_uri': '', 'edgeconductor_interface': {'support_labeling': False, 'inference_result_datatype': 'table', 'train_datatype': 'table'}, 'edgeapp_interface': {'redis_server_uri': ''}}, 'created_at': '2024-01-11T08:34:20', 'updated_at': '2024-01-11T08:34:20'}, 'is_deleted': 0, 'created_at': '2024-01-11T08:34:20', 'updated_at': '2024-01-11T08:34:20'}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "registerer.register_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Solution instance 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\n",
      "[INFO] AI solution interface information: \n",
      " {'name': 'test_0111_2', 'solution_version_id': '0a0fd6d2-39e2-47af-9fc1-cad3ac3e383f', 'workspace_name': 'magna-ws'}\u001b[0m\n",
      "\u001b[96m\n",
      "[INFO] AI solution instance register response: \n",
      " {'id': 'a6e5e45a-2d4c-45a8-b2e1-ff3b2262a202', 'name': 'test_0111_2', 'workspace_id': 'a0da0a72-3ce4-43e4-b510-b875896dcb35', 'workspace_name': 'magna-ws', 'solution_version_id': '0a0fd6d2-39e2-47af-9fc1-cad3ac3e383f', 'solution_version': 1, 'metadata_dict': {'version': 1, 'name': 'test_0111_2', 'description': {'icon': 's3://s3-an2-hyunsoo-dev-aia/icons/ic_customer_classification.svg', 'title': 'UI solution title', 'overview': 'AI Advisor Test', 'input_data': 's3-an2-hyunsoo-dev-magnaTest input s3 bucket', 'output_data': 's3-an2-hyunsoo-dev-magnaTest input s3 bucket', 'user_parameters': 'Test params', 'algorithm': 'ALO'}, 'pipeline': [{'type': 'train', 'parameters': {'candidate_parameters': [{'args': [{'concat_dataframes': True, 'drop_columns': None, 'encoding': None, 'groupkey_columns': None, 'input_path': 'train', 'time_column': None, 'use_all_x': False, 'x_columns': ['Count', 'Converted Torque', 'angle_min', 'angle_mean', 'angle_median', 'angle_std', 'angle_max', 'torque_min', 'torque_mean', 'torque_median', 'torque_std', 'torque_max'], 'y_column': 'current_cls'}], 'step': 'input'}, {'args': [{'ignore_label_class': 'NG', 'label_sampling': True, 'label_sampling_num': {'NG': 1, 'OK': 10}, 'label_sampling_num_type': 'compare', 'negative_target_class': None, 'sampling_groupkey_columns': None, 'sampling_method': 'cluster', 'sampling_num': None, 'sampling_num_type': None, 'sampling_type': 'under'}], 'step': 'sampling'}, {'args': [{'data_split_method': 'cross_validate', 'evaluation_metric': 'accuracy', 'model_list': ['lgb', 'rf', 'cb'], 'model_type': 'classification', 'num_hpo': 3, 'param_range': {'cb': {'max_depth': [5, 9], 'n_estimators': [100, 500]}, 'gbm': {'max_depth': [5, 7], 'n_estimators': [300, 500]}, 'lgb': {'max_depth': [5, 9], 'n_estimators': [300, 500]}, 'ngb': {'col_sample': [0.6, 0.8], 'n_estimators': [100, 300]}, 'rf': {'max_depth': 6, 'n_estimators': [300, 500]}}, 'shap_ratio': 1.0}], 'step': 'train'}], 'user_parameters': [{'step': 'input', 'args': []}, {'step': 'sampling', 'args': []}, {'step': 'train', 'args': []}], 'selected_user_parameters': [{'step': 'input', 'args': {}}, {'step': 'sampling', 'args': {}}, {'step': 'train', 'args': {}}]}, 'dataset_uri': ['s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/'], 'artifact_uri': 's3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/artifacts/', 'container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/train/test_0111_2', 'resource': {'default': 'standard'}}, {'type': 'inference', 'dataset_uri': ['s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/inference/data/'], 'artifact_uri': 's3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/inference/artifacts/', 'model_uri': 's3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/artifacts/', 'container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/inference/test_0111_2', 'parameters': {'candidate_parameters': [{'args': [{'concat_dataframes': True, 'drop_columns': None, 'encoding': None, 'groupkey_columns': None, 'input_path': 'test', 'time_column': None, 'use_all_x': False, 'x_columns': ['Count', 'Converted Torque', 'angle_min', 'angle_mean', 'angle_median', 'angle_std', 'angle_max', 'torque_min', 'torque_mean', 'torque_median', 'torque_std', 'torque_max'], 'y_column': None}], 'step': 'input'}, {'args': [{'model_type': 'classification', 'run_shapley': False}], 'step': 'inference'}, {'args': [{'temp': 'temp'}], 'step': 'output'}], 'user_parameters': [{'step': 'input', 'args': []}, {'step': 'inference', 'args': []}, {'step': 'output', 'args': []}], 'selected_user_parameters': [{'step': 'input', 'args': {}}, {'step': 'inference', 'args': {}}, {'step': 'output', 'args': {}}]}, 'resource': {'default': 'standard'}}], 'wrangler_code_uri': 'from time import time\\nimport os\\nimport csv\\nimport numpy as np\\nimport pandas as pd\\nimport re\\nfrom apscheduler.schedulers.background import BackgroundScheduler\\nimport shutil\\n\\nimport argparse\\n\\nfrom redisqueue import RedisQueue\\nfrom logger import Logger\\n\\nclass Wrangler:\\n    def __init__(self):\\n        # 명령줄 인수를 파싱하는 데 사용될 Parser 초기화\\n        #self.parser = argparse.ArgumentParser(description=\"Process the data path.\")\\n        #self.parser.add_argument(\\'--data_path\\', type=str, help=\"The path to the data file.\")\\n        self.logger = Logger(__name__)\\n\\n        # data_path 변수 초기화\\n        self.data_path = \"/alo/edgeapp_interface/input\"\\n\\n        self.scheduler = BackgroundScheduler()\\n        self.register_schedule()\\n\\n        self.pattern_order = re.compile(r\"\\\\(*[0-9]+\\\\)*_(OK|NG|OTHER)\")\\n        self.pattern_number = re.compile(r\"[0-9]+\")\\n\\n        self.wrangler_request_queue = RedisQueue(\\'request_wrangler\\', host=\\'localhost\\', port=6379, db=0)\\n        self.wrangler_finish_queue = RedisQueue(\\'finish_wrangler\\', host=\\'localhost\\', port=6379, db=0)\\n        \\n        self.dummy_flag = False\\n\\n    def register_schedule(self):\\n        self.logger.debug(f\\'scheduler: {self.scheduler}\\')\\n        self.scheduler.add_job(\\n            self._run_wrangler_request_queue,\\n            id=\\'_run_wrangler_request_queue\\')\\n\\n    def unregister_schedule(self):\\n        self.logger.debug()\\n        self.scheduler.remove_job(\\'_run_wrangler_request_queue\\')\\n\\n    def wrangling(self, data_path):\\n        start = time()\\n        csv_files = os.path.basename(data_path)\\n        output_path = os.path.join(self.data_path, csv_files)\\n        \\n        if self.dummy_flag:\\n            shutil.copy2(data_path, output_path)\\n\\n        else:\\n            with open(data_path, \\'r\\') as f:\\n                lines = csv.reader(f)\\n                columns = next(lines)\\n                row_data = next(lines)\\n\\n            if row_data[-1] == \\'\\' :\\n                row_data = row_data[:-1]\\n\\n            count_num = int(row_data[4])\\n            torque_angle_data = row_data[-(count_num*2):]\\n            torque = np.array(torque_angle_data[:count_num]).astype(float)\\n            angle = np.array(torque_angle_data[count_num:]).astype(int)\\n\\n            if torque[-1] == 0 and len(torque) > 1:\\n                torque = torque[:-1]\\n            if angle[-1] == 0 and len(angle) > 1:\\n                angle = angle[:-1]\\n\\n            angle_max = max(angle)\\n            angle_min = min(angle)\\n            angle_mean = np.mean(angle)\\n            angle_median = np.median(angle)\\n            angle_std = np.std(angle)\\n\\n            torque_max = max(torque)\\n            torque_min = min(torque)\\n            torque_mean = np.mean(torque)\\n            torque_median = np.median(torque)\\n            torque_std = np.std(torque)\\n\\n            columns = columns[:-1]\\n\\n            df_initial = pd.DataFrame(np.array(row_data[:len(columns)]).reshape(1, -1), columns=columns)\\n\\n            process_order = 0\\n            match = self.pattern_order.search(data_path)\\n            if match is not None :\\n                matched_str = match.group()\\n                match_number = self.pattern_number.search(matched_str)\\n                if match_number is not None :\\n                    process_order = match_number.group()\\n            print(f\\'### wrangler process order : {process_order}\\')\\n\\n            #self.load_time += time() - start\\n            print(\\'### load data and statistics time : \\', time() - start)\\n\\n            start = time()\\n            # torque, angle raw data into columns\\n            df_torque = pd.DataFrame([torque], columns=[\\'torque_\\'+str(i) for i in range(len(torque))])\\n            df_angle = pd.DataFrame([angle], columns=[\\'angle_\\'+str(i) for i in range(len(angle))])\\n\\n            # stats. columns\\n            col_list = [\\'file_name\\', \\'path\\', \\'process_order\\', \\'angle_max\\', \\'angle_min\\', \\'angle_mean\\', \\'angle_median\\', \\'angle_std\\', \\'torque_max\\', \\'torque_min\\', \\'torque_mean\\', \\'torque_median\\', \\'torque_std\\']\\n            value_list = [csv_files, output_path, process_order, angle_max, angle_min, angle_mean, angle_median, angle_std, torque_max, torque_min, torque_mean, torque_median, torque_std]\\n            df_input = pd.DataFrame([value_list], columns=col_list)\\n\\n            # concat all the columns\\n            df_input_data = pd.concat((df_initial, df_input, df_torque, df_angle), axis=1, sort=False) #sort false 안하면 angle_1, angle_10 .. 순서로 정렬됨\\n\\n            df_input_data.to_csv(output_path, index=False)\\n            #self.create_df_time += time() - start\\n            print(\\'### data frame processing time : \\', time() - start)\\n        \\n        return csv_files\\n\\n    def _run_wrangler_request_queue(self):\\n        self.logger.debug()\\n        while(True):\\n            msg = self.wrangler_request_queue.rget(isBlocking=True) # 큐가 비어있을 때 대기\\n            if msg is not None:\\n                msg_str = msg.decode(\\'utf-8\\')\\n                print(\\'got req from EdgeAPP: \\', msg_str) \\n                print(\\'-----------------------------------------------------------\\')\\n                try:\\n                    wrangler_data = self.wrangling(msg_str)\\n                except Exception as e:\\n                    print(\"wrangler error:\", str(e))\\n                    wrangler_data = \\'error\\'\\n                \\n                self.wrangler_finish_queue.rput(wrangler_data) \\n\\n\\nif __name__ == \"__main__\":\\n    wrangler = Wrangler()\\n    wrangler.scheduler.start()\\n', 'wrangler_dataset_uri': '', 'edgeconductor_interface': {'support_labeling': False, 'inference_result_datatype': 'table', 'train_datatype': 'table'}, 'edgeapp_interface': {'redis_server_uri': ''}}, 'is_deleted': 0, 'created_at': '2024-01-11T08:34:22', 'updated_at': '2024-01-11T08:34:22'}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "registerer.register_solution_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <u>[임시]</u> 추후 Edge Conductor UI에서 진행 예정 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Stream 등록 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[INFO] AI solution stream register response: \n",
      " {'id': 'f39a80a9-fe4a-4a20-991e-77e8f104d2ba', 'name': 'ws-test-1214-1106', 'instance_id': '1151d48f-4e12-46c0-be5e-8743b15a9eda', 'train_dataset_uri': 's3://s3-an2-hyunsoo-dev-cism/instances/ws-test-1214-1106/ws-test-1214-1106/train/data/', 'workspace_name': 'cism-ws', 'is_deleted': 0, 'created_at': '2023-12-14 02:08:34'}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "registerer.register_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> stream run 요청 (train, inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[INFO] Run pipeline << inference >> response: \n",
      " {'id': '88ed6d11-da1c-4a70-9696-60903c8fb316', 'name': 'ws-test-1214-1106-20231214020837', 'workspace_name': 'cism-ws', 'stream_id': 'f39a80a9-fe4a-4a20-991e-77e8f104d2ba', 'train_pipeline_id': '3520a52e-9463-444a-8efd-941916972bca', 'status': 'running', 'train_dataset_uri': ['s3://s3-an2-hyunsoo-dev-cism/ai-solutions/ws-test-1214-1106/v1/train/data/'], 'train_artifact_uri': 's3://s3-an2-hyunsoo-dev-cism/instances/ws-test-1214-1106/f39a80a9-fe4a-4a20-991e-77e8f104d2ba/train/artifacts/2023/12/14/020837.084/', 'model_version': '0', 'is_deleted': 0, 'created_at': '2023-12-14 02:08:37', 'updated_at': '2023-12-14 02:08:37'}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "registerer.request_run_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> pipeline status 조회 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mStream status: Failed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "registerer.get_stream_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 학습 완료된 artifacts download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mDownloaded: model.tar.gz\u001b[0m\n",
      "\u001b[96mDownloaded: train_artifacts.tar.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "registerer.download_artifacts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> download 받은 학습 artifacts로 로컬 환경에서 추론해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ws.jang/miniforge3/envs/aic_test/bin/python\n"
     ]
    }
   ],
   "source": [
    "# 가상환경이 잘 connected 돼있는지 확인 \n",
    "!which python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 작업경로 확인 \n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3로부터 다운로드받은 train artifacts를 scripts 폴더 상위 경로의 main.py랑 같은 위치로 옮기고 추론 실행 \n",
    "import os\n",
    "os.makedirs(\"./.train_artifacts\",  exist_ok=True)\n",
    "\n",
    "!tar -xvf ./train_artifacts.tar.gz -C ./.train_artifacts/\n",
    "!cp -r .train_artifacts ../../\n",
    "!rm -rf ./.train_artifacts\n",
    "\n",
    "!python ../../main.py --mode inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
