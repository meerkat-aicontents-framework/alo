description:
  algorithm: ALO
  icon: s3://s3-an2-hyunsoo-dev-magna/icons/test_0111_2/icon.png
  input_data: s3-an2-hyunsoo-dev-magnaTest input s3 bucket
  output_data: s3-an2-hyunsoo-dev-magnaTest input s3 bucket
  overview: AI Advisor Test
  title: UI solution title
  user_parameters: Test params
edgeapp_interface:
  redis_server_uri: ''
edgeconductor_interface:
  inference_result_datatype: table
  support_labeling: false
  train_datatype: table
name: test_0111_2
pipeline:
- artifact_uri: s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/artifacts/
  container_uri: 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/train/test_0111_2
  dataset_uri:
  - s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/data/
  parameters:
    candidate_parameters:
    - args:
      - concat_dataframes: true
        drop_columns: null
        encoding: null
        groupkey_columns: null
        input_path: train
        time_column: null
        use_all_x: false
        x_columns:
        - Count
        - Converted Torque
        - angle_min
        - angle_mean
        - angle_median
        - angle_std
        - angle_max
        - torque_min
        - torque_mean
        - torque_median
        - torque_std
        - torque_max
        y_column: current_cls
      step: input
    - args:
      - ignore_label_class: NG
        label_sampling: true
        label_sampling_num:
          NG: 1
          OK: 10
        label_sampling_num_type: compare
        negative_target_class: null
        sampling_groupkey_columns: null
        sampling_method: cluster
        sampling_num: null
        sampling_num_type: null
        sampling_type: under
      step: sampling
    - args:
      - data_split_method: cross_validate
        evaluation_metric: accuracy
        model_list:
        - lgb
        - rf
        - cb
        model_type: classification
        num_hpo: 3
        param_range:
          cb:
            max_depth:
            - 5
            - 9
            n_estimators:
            - 100
            - 500
          gbm:
            max_depth:
            - 5
            - 7
            n_estimators:
            - 300
            - 500
          lgb:
            max_depth:
            - 5
            - 9
            n_estimators:
            - 300
            - 500
          ngb:
            col_sample:
            - 0.6
            - 0.8
            n_estimators:
            - 100
            - 300
          rf:
            max_depth: 6
            n_estimators:
            - 300
            - 500
        shap_ratio: 1.0
      step: train
    selected_user_parameters:
    - args: {}
      step: input
    - args: {}
      step: sampling
    - args: {}
      step: train
    user_parameters:
    - args: []
      step: input
    - args: []
      step: sampling
    - args: []
      step: train
  resource:
    default: standard
  type: train
- artifact_uri: s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/inference/artifacts/
  container_uri: 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/ai-solutions/test_0111_2/inference/test_0111_2
  dataset_uri:
  - s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/inference/data/
  model_uri: s3://s3-an2-hyunsoo-dev-magna/ai-solutions/test_0111_2/v1/train/artifacts/
  parameters:
    candidate_parameters:
    - args:
      - concat_dataframes: true
        drop_columns: null
        encoding: null
        groupkey_columns: null
        input_path: test
        time_column: null
        use_all_x: false
        x_columns:
        - Count
        - Converted Torque
        - angle_min
        - angle_mean
        - angle_median
        - angle_std
        - angle_max
        - torque_min
        - torque_mean
        - torque_median
        - torque_std
        - torque_max
        y_column: null
      step: input
    - args:
      - model_type: classification
        run_shapley: false
      step: inference
    - args:
      - temp: temp
      step: output
    selected_user_parameters:
    - args: {}
      step: input
    - args: {}
      step: inference
    - args: {}
      step: output
    user_parameters:
    - args: []
      step: input
    - args: []
      step: inference
    - args: []
      step: output
  resource:
    default: standard
  type: inference
version: 1
wrangler_code_uri: "from time import time\nimport os\nimport csv\nimport numpy as\
  \ np\nimport pandas as pd\nimport re\nfrom apscheduler.schedulers.background import\
  \ BackgroundScheduler\nimport shutil\n\nimport argparse\n\nfrom redisqueue import\
  \ RedisQueue\nfrom logger import Logger\n\nclass Wrangler:\n    def __init__(self):\n\
  \        # 명령줄 인수를 파싱하는 데 사용될 Parser 초기화\n        #self.parser = argparse.ArgumentParser(description=\"\
  Process the data path.\")\n        #self.parser.add_argument('--data_path', type=str,\
  \ help=\"The path to the data file.\")\n        self.logger = Logger(__name__)\n\
  \n        # data_path 변수 초기화\n        self.data_path = \"/alo/edgeapp_interface/input\"\
  \n\n        self.scheduler = BackgroundScheduler()\n        self.register_schedule()\n\
  \n        self.pattern_order = re.compile(r\"\\(*[0-9]+\\)*_(OK|NG|OTHER)\")\n \
  \       self.pattern_number = re.compile(r\"[0-9]+\")\n\n        self.wrangler_request_queue\
  \ = RedisQueue('request_wrangler', host='localhost', port=6379, db=0)\n        self.wrangler_finish_queue\
  \ = RedisQueue('finish_wrangler', host='localhost', port=6379, db=0)\n        \n\
  \        self.dummy_flag = False\n\n    def register_schedule(self):\n        self.logger.debug(f'scheduler:\
  \ {self.scheduler}')\n        self.scheduler.add_job(\n            self._run_wrangler_request_queue,\n\
  \            id='_run_wrangler_request_queue')\n\n    def unregister_schedule(self):\n\
  \        self.logger.debug()\n        self.scheduler.remove_job('_run_wrangler_request_queue')\n\
  \n    def wrangling(self, data_path):\n        start = time()\n        csv_files\
  \ = os.path.basename(data_path)\n        output_path = os.path.join(self.data_path,\
  \ csv_files)\n        \n        if self.dummy_flag:\n            shutil.copy2(data_path,\
  \ output_path)\n\n        else:\n            with open(data_path, 'r') as f:\n \
  \               lines = csv.reader(f)\n                columns = next(lines)\n \
  \               row_data = next(lines)\n\n            if row_data[-1] == '' :\n\
  \                row_data = row_data[:-1]\n\n            count_num = int(row_data[4])\n\
  \            torque_angle_data = row_data[-(count_num*2):]\n            torque =\
  \ np.array(torque_angle_data[:count_num]).astype(float)\n            angle = np.array(torque_angle_data[count_num:]).astype(int)\n\
  \n            if torque[-1] == 0 and len(torque) > 1:\n                torque =\
  \ torque[:-1]\n            if angle[-1] == 0 and len(angle) > 1:\n             \
  \   angle = angle[:-1]\n\n            angle_max = max(angle)\n            angle_min\
  \ = min(angle)\n            angle_mean = np.mean(angle)\n            angle_median\
  \ = np.median(angle)\n            angle_std = np.std(angle)\n\n            torque_max\
  \ = max(torque)\n            torque_min = min(torque)\n            torque_mean =\
  \ np.mean(torque)\n            torque_median = np.median(torque)\n            torque_std\
  \ = np.std(torque)\n\n            columns = columns[:-1]\n\n            df_initial\
  \ = pd.DataFrame(np.array(row_data[:len(columns)]).reshape(1, -1), columns=columns)\n\
  \n            process_order = 0\n            match = self.pattern_order.search(data_path)\n\
  \            if match is not None :\n                matched_str = match.group()\n\
  \                match_number = self.pattern_number.search(matched_str)\n      \
  \          if match_number is not None :\n                    process_order = match_number.group()\n\
  \            print(f'### wrangler process order : {process_order}')\n\n        \
  \    #self.load_time += time() - start\n            print('### load data and statistics\
  \ time : ', time() - start)\n\n            start = time()\n            # torque,\
  \ angle raw data into columns\n            df_torque = pd.DataFrame([torque], columns=['torque_'+str(i)\
  \ for i in range(len(torque))])\n            df_angle = pd.DataFrame([angle], columns=['angle_'+str(i)\
  \ for i in range(len(angle))])\n\n            # stats. columns\n            col_list\
  \ = ['file_name', 'path', 'process_order', 'angle_max', 'angle_min', 'angle_mean',\
  \ 'angle_median', 'angle_std', 'torque_max', 'torque_min', 'torque_mean', 'torque_median',\
  \ 'torque_std']\n            value_list = [csv_files, output_path, process_order,\
  \ angle_max, angle_min, angle_mean, angle_median, angle_std, torque_max, torque_min,\
  \ torque_mean, torque_median, torque_std]\n            df_input = pd.DataFrame([value_list],\
  \ columns=col_list)\n\n            # concat all the columns\n            df_input_data\
  \ = pd.concat((df_initial, df_input, df_torque, df_angle), axis=1, sort=False) #sort\
  \ false 안하면 angle_1, angle_10 .. 순서로 정렬됨\n\n            df_input_data.to_csv(output_path,\
  \ index=False)\n            #self.create_df_time += time() - start\n           \
  \ print('### data frame processing time : ', time() - start)\n        \n       \
  \ return csv_files\n\n    def _run_wrangler_request_queue(self):\n        self.logger.debug()\n\
  \        while(True):\n            msg = self.wrangler_request_queue.rget(isBlocking=True)\
  \ # 큐가 비어있을 때 대기\n            if msg is not None:\n                msg_str = msg.decode('utf-8')\n\
  \                print('got req from EdgeAPP: ', msg_str) \n                print('-----------------------------------------------------------')\n\
  \                try:\n                    wrangler_data = self.wrangling(msg_str)\n\
  \                except Exception as e:\n                    print(\"wrangler error:\"\
  , str(e))\n                    wrangler_data = 'error'\n                \n     \
  \           self.wrangler_finish_queue.rput(wrangler_data) \n\n\nif __name__ ==\
  \ \"__main__\":\n    wrangler = Wrangler()\n    wrangler.scheduler.start()\n"
wrangler_dataset_uri: ''
