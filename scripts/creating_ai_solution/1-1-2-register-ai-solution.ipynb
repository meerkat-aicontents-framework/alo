{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP-1**. AI Solution 및 Instance 등록을 위한 준비 작업\n",
    "&#x1F600; **등록 할 AI Contents 의 experimental_plan.yaml 를 alo/config/ 에 준비해 둡니다.**\n",
    "\n",
    "&#x1F600; **가상 환경을 만들어 두고, ipykernel 을 제작해 둡니다.**     \n",
    "\n",
    "1. ALO 의 main.py 파일이 존재하는 위치에서 아래 명령어들을 순차 실행합니다.\n",
    "> conda create -n {ENV-NAME} python=3.10 \\\n",
    "> conda init bash \\\n",
    "> conda activate {ENV-NAME} \\\n",
    "> python main.py \\\n",
    "> pip install ipykernel \\\n",
    "> pip install requests \\\n",
    "> python -m ipykernel install --user --name {ENV-NAME} --display-name {IPYKERNEL-NAME}\n",
    "\n",
    "2. 본 jupyter notebook 에서, 위에서 생성한 ipykernel 을 선택 합니다. \\\n",
    "   가령 tcr이라는 이름의 가상환경을 만들었다면, 아래와 같이 선택합니다.\n",
    "\n",
    "<div style=\"margin: 40px\">\n",
    "<img src=\"./image/ipykernel.png\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "\n",
    "&#x1F600; **아래 STEP들을 하나씩 실행시키면서, <u>< 사용자 입력 ></u>이라고 주석 표기된 내용을 적절히 변경해주세요.**     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP-2**. AI Solution 이름 선택     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-2-1**. AI Conductor 시스템 URI 셋팅\n",
    "&#x1F600; 로그인 요청 및 시스템 담당으로부터 사용 가능한 시스템 URI를 확인합니다. \n",
    "- 고객지수플랫폼 Development \n",
    "> URI: \"https://aic-kic.aidxlge.com/\"\n",
    "- 담당서버 테스트 환경       \n",
    "> URI = \"http://10.158.2.243:9999/\" \n",
    "- 사외 테스트 환경 (LDAP 로그인 불가)\n",
    "> URI = \"https://web.aic-dev.lgebigdata.com/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 시스템 URI 및 로그인 정보, ECR TAG, ICON FILE 명 등 사용자 입력부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------#\n",
    "#              사용자 입력                #\n",
    "#----------------------------------------#\n",
    "solution_info ={\n",
    "    # 로그인 정보: EP 정보로 입력해주세요\n",
    "    # 'login_id': \"cism-dev\", #\"magna-dev\", #'ws.jang', # \"cism-dev\"\n",
    "    # 'login_pw': \"cism-dev@com\", #'magna-dev@com', # \"cism-dev\n",
    "    'pipeline_type': [\"train\", \"inference\"], # \"single\", \"multi\"\n",
    "    'solution_update': True,\n",
    "    'name': 'tcr-test-ssh',\n",
    "    'description': {\n",
    "        \"overview\": \"Test TCR\"\n",
    "    },\n",
    "    'contents_type': {\n",
    "            'support_labeling': False,\n",
    "            'inference_result_datatype': 'table', # 'image'\n",
    "            'train_datatype': 'table' # 'image'\n",
    "    },\n",
    "    'train_gpu': True, ## cpu, gpu\n",
    "    'inference_gpu': True,\n",
    "    \"inference_arm\": True  # amd, arm  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "infra_setup = {\n",
    "    ### system info. \n",
    "    'AIC_URI': \"https://web.aic-dev.lgebigdata.com/\",  ## 실 서버 \n",
    "    \"REGION\": \"ap-northeast-2\",\n",
    "    \"WORKSPACE_NAME\": \"cism-ws\",  ## magna-ws, cism-ws\n",
    "    \"BUILD_METHOD\": \"docker\",  ## docker, buildah \n",
    "\n",
    "    'VERSION': 1.0,\n",
    "    \"LOGIN_MODE\": \"static\", ## ldap, static\n",
    "    \"ECR_TAG\": \"latest\",   ## 없어질 사항\n",
    "    \"SOLUTION_TYPE\": \"private\", ##public, private \n",
    "    \"BUILDAH_TAGS\": [ \n",
    "      \"Key=Company,Value=LGE\",\n",
    "      \"Key=Owner,Value=IC360\",\n",
    "      \"Key=HQ,Value=CDO\",\n",
    "      \"Key=Division,Value=CDO\",\n",
    "      \"Key=Infra Region,Value=KIC\",\n",
    "      \"Key=Service Mode,Value=OP\",\n",
    "      \"Key=Cost Type,Value=COMPUTING\",\n",
    "      \"Key=Project,Value=CIS\",\n",
    "      \"Key=Sub Project,Value=CISM\",\n",
    "      \"Key=System,Value=AIDX\"]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Conductor 사용을 위한 Username & Password 를 입력 \n",
    "\n",
    "> !! 접속을 실패할 경우, AI Conductor 에게 계정 생성을 요청 하시기 바랍니다.   \n",
    "> Contact Us: hyunsoo0802.lim@lge.com  (LGE AI빅데이터담당)\n",
    "\n",
    "> Login 방식이 {'LOGIN_METHOD': 'ldap'} 로 설정되어 있는 경우, LGEP 의 ID & PW 를 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your ID :  cism-dev\n",
      "Your PW :  cism-dev@com\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "username = input('Username: ')\n",
    "password = getpass.getpass('Password: ')\n",
    "\n",
    "print(\"Your ID : \", username)\n",
    "print(\"Your PW : \", password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Initiate ALO operation mode\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SYSTEM] Solutoin 등록에 필요한 setup file 들을 load 합니다. \u001b[0m\n",
      "\u001b[92m[SYSTEM] infra_setup: \u001b[0m\n",
      "{'AIC_URI': 'https://web.aic-dev.lgebigdata.com/',\n",
      " 'BUILDAH_TAGS': ['Key=Company,Value=LGE',\n",
      "                  'Key=Owner,Value=IC360',\n",
      "                  'Key=HQ,Value=CDO',\n",
      "                  'Key=Division,Value=CDO',\n",
      "                  'Key=Infra Region,Value=KIC',\n",
      "                  'Key=Service Mode,Value=OP',\n",
      "                  'Key=Cost Type,Value=COMPUTING',\n",
      "                  'Key=Project,Value=CIS',\n",
      "                  'Key=Sub Project,Value=CISM',\n",
      "                  'Key=System,Value=AIDX'],\n",
      " 'BUILD_METHOD': 'docker',\n",
      " 'ECR_TAG': 'latest',\n",
      " 'LOGIN_MODE': 'static',\n",
      " 'REGION': 'ap-northeast-2',\n",
      " 'SOLUTION_TYPE': 'private',\n",
      " 'VERSION': 1.0,\n",
      " 'WORKSPACE_NAME': 'cism-ws'}\n",
      "\n",
      "API setup 파일이 존재 하지 않으므로, Default 파일을 load 합니다. (path: ./api_setup.yaml)\n",
      "\u001b[92m[SYSTEM] solution_info.: \u001b[0m\n",
      "{'contents_type': {'inference_result_datatype': 'table',\n",
      "                   'support_labeling': False,\n",
      "                   'train_datatype': 'table'},\n",
      " 'description': {'algorithm': '',\n",
      "                 'input_data': '',\n",
      "                 'output_data': '',\n",
      "                 'overview': 'Test TCR',\n",
      "                 'title': 'tcr-test-ssh',\n",
      "                 'user_parameters': ''},\n",
      " 'inference_arm': True,\n",
      " 'inference_gpu': True,\n",
      " 'name': 'tcr-test-ssh',\n",
      " 'pipeline_type': ['train', 'inference'],\n",
      " 'solution_update': True,\n",
      " 'train_gpu': True}\n",
      "\u001b[92m[SYSTEM] S3 key 파일을 로드 합니다. (file: /nas001/users/ruci.sung/aws.key)\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Login to AI Conductor\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 계정으로 접근 가능한 workspace list: ['cism-ws']\n",
      "\u001b[92m[SYSTEM] 접근 요청하신 workspace (cism-ws) 은 해당 계정으로 접근 가능합니다.\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Solution Name Creation\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "<Response [200]>\n",
      "\u001b[92m[SUCCESS] 입력하신 Solution Name (tcr-test-ssh)은 사용 가능합니다. \u001b[0m\n",
      "\u001b[92m[SYSTEM] Solution Name List (in-use):\u001b[0m\n",
      "\u001b[96m╒════╤══════════════════════════╕\n",
      "│    │ AI solutions             │\n",
      "╞════╪══════════════════════════╡\n",
      "│  0 │ solution-hyunsoo-cism-20 │\n",
      "├────┼──────────────────────────┤\n",
      "│  1 │ pytest-solution-1        │\n",
      "├────┼──────────────────────────┤\n",
      "│  2 │ solution-hyunsoo-cism-2  │\n",
      "├────┼──────────────────────────┤\n",
      "│  3 │ solution-hyunsoo-cism-1  │\n",
      "╘════╧══════════════════════════╛\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Check ECR & S3 Resource\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SYSTEM] AWS ECR:  \u001b[0m\n",
      "086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solutions/cism/\n",
      "\u001b[92m[SYSTEM] AWS S3 buckeet:  \u001b[0m\n",
      "s3-an2-hyunsoo-dev-cism\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set AI Solution Description\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadata.yaml.\u001b[0m\n",
      "description: {'overview': 'Test TCR', 'title': 'tcr-test-ssh', 'input_data': '', 'output_data': '', 'user_parameters': '', 'algorithm': ''}\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set Wrangler\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[93m[WARNING] wrangler.py 가 해당 위치에 존재해야 합니다. (path: ./wrangler/wrangler.py)\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set Contents Type (for retrain & relabeling)\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] contents_type 을 solution_metadata 에 성공적으로 업데이트 하였습니다.\u001b[0m\n",
      "edgeconductor_interfance: {'support_labeling': False, 'inference_result_datatype': 'table', 'train_datatype': 'table'}\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Display icon list\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload icon\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] update solution_metadata.yaml:\u001b[0m\n",
      "description: -icon: s3://s3-an2-hyunsoo-dev-aia/icons/ic_artificial_intelligence.svg \n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Check to access S3\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "[INFO] AWS region: ap-northeast-2\n",
      "\u001b[92m[INFO] AWS S3 access check: OK\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Display train Resource List\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "train 에 사용될 resource 를 선택해주세요(type['high', 'standard']):\n",
      "\u001b[96m╒════╤══════════╤══════════════════╤════════╤══════════╤═══════╕\n",
      "│    │ name     │ label            │   vcpu │   ram_gb │   gpu │\n",
      "╞════╪══════════╪══════════════════╪════════╪══════════╪═══════╡\n",
      "│  0 │ high     │ cism-ws-high     │      8 │       32 │     0 │\n",
      "├────┼──────────┼──────────────────┼────────┼──────────┼───────┤\n",
      "│  1 │ standard │ cism-ws-standard │      2 │        8 │     0 │\n",
      "╘════╧══════════╧══════════════════╧════════╧══════════╧═══════╛\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set train Resource\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadat.yaml:\u001b[0m\n",
      "pipeline[0]: -resource: standard\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set train user parameters:\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SYSTEM] experimental_plan.yaml 에 ui_args_detail 이 정상 기록 되었는지 체크 합니다.\u001b[0m\n",
      "ui_arg_detail: 에 [input](x_columns) 이 기록됨을 확인. \n",
      "ui_arg_detail: 에 [input](y_column) 이 기록됨을 확인. \n",
      "ui_arg_detail: 에 [train](evaluation_metric) 이 기록됨을 확인. \n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload train data to S3\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadata.yaml:\u001b[0m\n",
      "pipeline: type: train, dataset_uri: {'dataset_uri': ['s3://s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/train/data/']} \n",
      "\u001b[96m[SYSTEM] Start uploading data into S3 from local folder:\u001b[0m\n",
      "/home/sehyun.song/Project/alo/dev-240111/input/train/\n",
      "\u001b[93m[SYSTEM] Deleted pre-existing S3 object: ai-solutions/tcr-test-ssh/v1/train/data/\u001b[0m\n",
      "\u001b[93m[SYSTEM] Deleted pre-existing S3 object: ai-solutions/tcr-test-ssh/v1/train/data/default_train/iris.csv\u001b[0m\n",
      "\u001b[92m[SUCCESS] update train_data to S3:\u001b[0m\n",
      "s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/train/data/default_train/iris.csv\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload train artifacts to S3\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadata.yaml:\u001b[0m\n",
      "pipeline: type:train, model_uri: {'artifact_uri': 's3://s3-an2-hyunsoo-dev-cism//ai-solutions/tcr-test-ssh/v1/train/artifacts/'} \n",
      "\u001b[96m[SYSTEM] Start uploading train artifacts into S3 from local folder:\u001b[0m\n",
      "/home/sehyun.song/Project/alo/dev-240111/.temp_artifacts_dir/\n",
      "\u001b[93m[INFO] Deleted pre-existing S3 object:\u001b[0m\n",
      "/ai-solutions/tcr-test-ssh/v1/train/artifacts//\n",
      "\u001b[93m[INFO] Deleted pre-existing S3 object:\u001b[0m\n",
      "/ai-solutions/tcr-test-ssh/v1/train/artifacts//model.tar.gz\n",
      "\u001b[93m[INFO] Deleted pre-existing S3 object:\u001b[0m\n",
      "/ai-solutions/tcr-test-ssh/v1/train/artifacts//train_artifacts.tar.gz\n",
      "\u001b[92m[SUSTEM] S3 object key (new): \u001b[0m\n",
      "s3-an2-hyunsoo-dev-cism//ai-solutions/tcr-test-ssh/v1/train/artifacts//train_artifacts.tar.gz\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set AWS ECR\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set alo source code\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/main.py \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/ \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/src \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/src \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/config \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/config \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/assets \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/assets \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/alolib \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/alolib \" \u001b[0m\n",
      "SSH_DEBUG:  /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/config/experimental_plan.yaml\n",
      "\u001b[92m[SUCCESS] Success ALO directory setting.\u001b[0m\n",
      "\u001b[92m[SUCESS] set DOCKERFILE for (train) pipeline\u001b[0m\n",
      "\u001b[93m[SYSTEM] Repository ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh already exists. Deleting...\u001b[0m\n",
      "\u001b[94m[SYSTEM] target AWS ECR url: \u001b[0m\n",
      "086558720570.dkr.ecr.ap-northeast-2.amazonaws.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/sehyun.song/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[SYSTEM] AWS ECR | docker login result:\u001b[0m\n",
      "Login Succeeded\n",
      "\n",
      "\u001b[96m[SYSTEM] Target AWS ECR repository:\u001b[0m\n",
      "ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh\n",
      "\u001b[96m[SYSTEM] AWS ECR create-repository response: \u001b[0m\n",
      "{'repository': {'repositoryArn': 'arn:aws:ecr:ap-northeast-2:086558720570:repository/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh', 'registryId': '086558720570', 'repositoryName': 'ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh', 'repositoryUri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh', 'createdAt': datetime.datetime(2024, 1, 19, 19, 53, 20, 334000, tzinfo=tzlocal()), 'imageTagMutability': 'MUTABLE', 'imageScanningConfiguration': {'scanOnPush': False}, 'encryptionConfiguration': {'encryptionType': 'AES256'}}, 'ResponseMetadata': {'RequestId': '9456cc62-fe1a-4502-843a-3f7f335ffd61', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '9456cc62-fe1a-4502-843a-3f7f335ffd61', 'date': 'Fri, 19 Jan 2024 10:53:20 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '589', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload Docker Container\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "Sending build context to Docker daemon  3.159MB\n",
      "Step 1/12 : FROM public.ecr.aws/docker/library/python:3.10-slim-bullseye\n",
      " ---> ee6be26d226b\n",
      "Step 2/12 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> c5214f1ac135\n",
      "Step 3/12 : RUN apt-get install -y apt-utils\n",
      " ---> Using cache\n",
      " ---> b4b5b8d367ba\n",
      "Step 4/12 : RUN apt-get install -y --no-install-recommends          build-essential          wget          ca-certificates          git          gcc     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> f61e2821ba8e\n",
      "Step 5/12 : ENV LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 729705be4177\n",
      "Step 6/12 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 47764350993e\n",
      "Step 7/12 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> ead025070b9a\n",
      "Step 8/12 : ENV SOLUTION_PIPELINE_MODE='train'\n",
      " ---> Using cache\n",
      " ---> 94201625ca27\n",
      "Step 9/12 : ENV PATH=\"/framework:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 1d6d3cf6e2d1\n",
      "Step 10/12 : COPY /alo /framework\n",
      " ---> Using cache\n",
      " ---> f4116b91b166\n",
      "Step 11/12 : WORKDIR /framework\n",
      " ---> Using cache\n",
      " ---> c906787ccf58\n",
      "Step 12/12 : CMD [\"python\", \"main.py\"]\n",
      " ---> Using cache\n",
      " ---> ec160a16ab52\n",
      "[Warning] One or more build-args [ARCHITECTURE MODE USE_GPU] were not consumed\n",
      "Successfully built ec160a16ab52\n",
      "Successfully tagged 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh:latest\n",
      "The push refers to repository [086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh]\n",
      "4c6180266c6d: Preparing\n",
      "52f6a5bb02a9: Preparing\n",
      "1ae895bce35d: Preparing\n",
      "d80559b265dd: Preparing\n",
      "9647f452a529: Preparing\n",
      "7972dfbb0bc8: Preparing\n",
      "29578fbbec63: Preparing\n",
      "cc056986b725: Preparing\n",
      "74c0af6e0227: Preparing\n",
      "29578fbbec63: Waiting\n",
      "7972dfbb0bc8: Waiting\n",
      "cc056986b725: Waiting\n",
      "74c0af6e0227: Waiting\n",
      "1ae895bce35d: Pushed\n",
      "4c6180266c6d: Pushed\n",
      "7972dfbb0bc8: Pushed\n",
      "9647f452a529: Pushed\n",
      "d80559b265dd: Pushed\n",
      "cc056986b725: Pushed\n",
      "29578fbbec63: Pushed\n",
      "74c0af6e0227: Pushed\n",
      "52f6a5bb02a9: Pushed\n",
      "latest: digest: sha256:013a0fd7ea06362634a61ba172bd22e2c2bfc269f693f779cd1e2715de76c471 size: 2215\n",
      "Removing login credentials for https://index.docker.io/v1/\n",
      "\u001b[92m[SYSTEM] Completes setting << container_uri >> in solution_metadata.yaml:\u001b[0m\n",
      "pipeline: -container_uri: 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set inference Resource\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[93mEdgeApp 에 대한 resource 설정은 현재 미지원 입니다. resource=standard 로 고정 됩니다.\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadat.yaml:\u001b[0m\n",
      "pipeline[1]: -resource: standard\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set inference user parameters:\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SYSTEM] experimental_plan.yaml 에 ui_args_detail 이 정상 기록 되었는지 체크 합니다.\u001b[0m\n",
      "ui_arg_detail: 에 [input](x_columns) 이 기록됨을 확인. \n",
      "ui_arg_detail: 에 [inference](run_shapley) 이 기록됨을 확인. \n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload inference data to S3\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadata.yaml:\u001b[0m\n",
      "pipeline: type: inference, dataset_uri: {'dataset_uri': ['s3://s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/inference/data/']} \n",
      "\u001b[96m[INFO] Start uploading data into S3 from local folder:\u001b[0m\n",
      "/home/sehyun.song/Project/alo/dev-240111/input/inference/\n",
      "\u001b[93m[SYSTEM] Deleted pre-existing S3 object: ai-solutions/tcr-test-ssh/v1/inference/data/\u001b[0m\n",
      "\u001b[93m[SYSTEM] Deleted pre-existing S3 object: ai-solutions/tcr-test-ssh/v1/inference/data/default_inference/iris.csv\u001b[0m\n",
      "\u001b[92m[SUCCESS] update train_data to S3:\u001b[0m\n",
      "s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/inference/data/default_inference/iris.csv\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload inference artifacts to S3\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadata.yaml:\u001b[0m\n",
      "pipeline: type:inference, model_uri: {'artifact_uri': 's3://s3-an2-hyunsoo-dev-cism//ai-solutions/tcr-test-ssh/v1/inference/artifacts/'} \n",
      "\u001b[96m[INFO] Start uploading inference artifacts into S3 from local folder:\u001b[0m\n",
      "/home/sehyun.song/Project/alo/dev-240111/.temp_artifacts_dir/\n",
      "\u001b[93m[INFO] Deleted pre-existing S3 object:\u001b[0m\n",
      "/ai-solutions/tcr-test-ssh/v1/inference/artifacts//\n",
      "\u001b[93m[INFO] Deleted pre-existing S3 object:\u001b[0m\n",
      "/ai-solutions/tcr-test-ssh/v1/inference/artifacts//inference_artifacts.tar.gz\n",
      "\u001b[92m[SUSTEM] S3 object key (new): \u001b[0m\n",
      "s3-an2-hyunsoo-dev-cism//ai-solutions/tcr-test-ssh/v1/inference/artifacts//inference_artifacts.tar.gz\n",
      "\u001b[96m\n",
      "[SYSTEM] Start uploading << model >> into S3 from local folder:\u001b[0m\n",
      "/home/sehyun.song/Project/alo/dev-240111/.temp_model_dir/\n",
      "\u001b[92m[SUSTEM] S3 object key (new): \u001b[0m\n",
      "s3-an2-hyunsoo-dev-cism//ai-solutions/tcr-test-ssh/v1/train/artifacts//model.tar.gz\n",
      "\u001b[92m[SUCCESS] Update solution_metadata.yaml:\u001b[0m\n",
      "pipeline: type:inference, model_uri: {'model_uri': 's3://s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/train/artifacts/'} \n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set AWS ECR\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set alo source code\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/main.py \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/ \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/src \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/src \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/config \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/config \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/assets \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/assets \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/alolib \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/alolib \" \u001b[0m\n",
      "SSH_DEBUG:  /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/config/experimental_plan.yaml\n",
      "\u001b[92m[SUCCESS] Success ALO directory setting.\u001b[0m\n",
      "\u001b[92m[SUCESS] set DOCKERFILE for (inference) pipeline\u001b[0m\n",
      "\u001b[93m[SYSTEM] Repository ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh already exists. Deleting...\u001b[0m\n",
      "\u001b[94m[SYSTEM] target AWS ECR url: \u001b[0m\n",
      "086558720570.dkr.ecr.ap-northeast-2.amazonaws.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/sehyun.song/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[SYSTEM] AWS ECR | docker login result:\u001b[0m\n",
      "Login Succeeded\n",
      "\n",
      "\u001b[96m[SYSTEM] Target AWS ECR repository:\u001b[0m\n",
      "ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh\n",
      "\u001b[96m[SYSTEM] AWS ECR create-repository response: \u001b[0m\n",
      "{'repository': {'repositoryArn': 'arn:aws:ecr:ap-northeast-2:086558720570:repository/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh', 'registryId': '086558720570', 'repositoryName': 'ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh', 'repositoryUri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh', 'createdAt': datetime.datetime(2024, 1, 19, 19, 53, 45, 548000, tzinfo=tzlocal()), 'imageTagMutability': 'MUTABLE', 'imageScanningConfiguration': {'scanOnPush': False}, 'encryptionConfiguration': {'encryptionType': 'AES256'}}, 'ResponseMetadata': {'RequestId': '7dbaf2ff-aba9-441e-afe8-5ca4fb991b61', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '7dbaf2ff-aba9-441e-afe8-5ca4fb991b61', 'date': 'Fri, 19 Jan 2024 10:53:45 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '601', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload Docker Container\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "Sending build context to Docker daemon  3.161MB\n",
      "Step 1/12 : FROM public.ecr.aws/docker/library/python:3.10-slim-bullseye\n",
      " ---> ee6be26d226b\n",
      "Step 2/12 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> c5214f1ac135\n",
      "Step 3/12 : RUN apt-get install -y apt-utils\n",
      " ---> Using cache\n",
      " ---> b4b5b8d367ba\n",
      "Step 4/12 : RUN apt-get install -y --no-install-recommends          build-essential          wget          ca-certificates          git          gcc     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> f61e2821ba8e\n",
      "Step 5/12 : ENV LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 729705be4177\n",
      "Step 6/12 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 47764350993e\n",
      "Step 7/12 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> ead025070b9a\n",
      "Step 8/12 : ENV SOLUTION_PIPELINE_MODE='inference'\n",
      " ---> Using cache\n",
      " ---> aa77d76f572d\n",
      "Step 9/12 : ENV PATH=\"/framework:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 53b6bdefdee1\n",
      "Step 10/12 : COPY /alo /framework\n",
      " ---> Using cache\n",
      " ---> 37e3737adb2c\n",
      "Step 11/12 : WORKDIR /framework\n",
      " ---> Using cache\n",
      " ---> 49ebf0629ee2\n",
      "Step 12/12 : CMD [\"python\", \"main.py\"]\n",
      " ---> Using cache\n",
      " ---> 34e40b26b7b8\n",
      "[Warning] One or more build-args [USE_GPU ARCHITECTURE MODE] were not consumed\n",
      "Successfully built 34e40b26b7b8\n",
      "Successfully tagged 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh:latest\n",
      "The push refers to repository [086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh]\n",
      "a5c4b9af6dca: Preparing\n",
      "52f6a5bb02a9: Preparing\n",
      "1ae895bce35d: Preparing\n",
      "d80559b265dd: Preparing\n",
      "9647f452a529: Preparing\n",
      "7972dfbb0bc8: Preparing\n",
      "29578fbbec63: Preparing\n",
      "cc056986b725: Preparing\n",
      "74c0af6e0227: Preparing\n",
      "29578fbbec63: Waiting\n",
      "cc056986b725: Waiting\n",
      "74c0af6e0227: Waiting\n",
      "7972dfbb0bc8: Waiting\n",
      "a5c4b9af6dca: Pushed\n",
      "1ae895bce35d: Pushed\n",
      "7972dfbb0bc8: Pushed\n",
      "9647f452a529: Pushed\n",
      "d80559b265dd: Pushed\n",
      "cc056986b725: Pushed\n",
      "29578fbbec63: Pushed\n",
      "74c0af6e0227: Pushed\n",
      "52f6a5bb02a9: Pushed\n",
      "latest: digest: sha256:b2abcf6094efece2fb9599a0d9e3f9e2fd93d4c806d580800ff14de994a73798 size: 2215\n",
      "Removing login credentials for https://index.docker.io/v1/\n",
      "\u001b[92m[SYSTEM] Completes setting << container_uri >> in solution_metadata.yaml:\u001b[0m\n",
      "pipeline: -container_uri: 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Failed to register AI solution: \n Object of type Response is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Project/alo/dev-240111/scripts/creating_ai_solution/register_utils_ssh.py:591\u001b[0m, in \u001b[0;36mSolutionRegister.register_solution\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[1;32m    588\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mscope_ws\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkspaces,\n\u001b[1;32m    589\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mmetadata_json\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msm_yaml\n\u001b[1;32m    590\u001b[0m }\n\u001b[0;32m--> 591\u001b[0m data \u001b[39m=\u001b[39mjson\u001b[39m.\u001b[39;49mdumps(data)\n\u001b[1;32m    592\u001b[0m solution_params \u001b[39m=\u001b[39m {\n\u001b[1;32m    593\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mworkspace_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkspaces\n\u001b[1;32m    594\u001b[0m \n\u001b[1;32m    595\u001b[0m }\n",
      "File \u001b[0;32m~/miniforge3/envs/tcr/lib/python3.10/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m skipkeys \u001b[39mand\u001b[39;00m ensure_ascii \u001b[39mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[39mand\u001b[39;00m allow_nan \u001b[39mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m indent \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m separators \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sort_keys \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_encoder\u001b[39m.\u001b[39;49mencode(obj)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/tcr/lib/python3.10/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n",
      "File \u001b[0;32m~/miniforge3/envs/tcr/lib/python3.10/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tcr/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39ma serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m(to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Response is not JSON serializable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/1-1-2-register-ai-solution.ipynb 셀 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.158.2.41/home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/1-1-2-register-ai-solution.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m register \u001b[39m=\u001b[39m SolutionRegister(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.158.2.41/home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/1-1-2-register-ai-solution.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     infra_setup\u001b[39m=\u001b[39minfra_setup, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.158.2.41/home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/1-1-2-register-ai-solution.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     solution_info\u001b[39m=\u001b[39msolution_info)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.158.2.41/home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/1-1-2-register-ai-solution.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m register\u001b[39m.\u001b[39mdebugging \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m## default: False\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.158.2.41/home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/1-1-2-register-ai-solution.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m register\u001b[39m.\u001b[39;49mrun(username\u001b[39m=\u001b[39;49musername, password\u001b[39m=\u001b[39;49mpassword)\n",
      "File \u001b[0;32m~/Project/alo/dev-240111/scripts/creating_ai_solution/register_utils_ssh.py:180\u001b[0m, in \u001b[0;36mSolutionRegister.run\u001b[0;34m(self, username, password)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_docker_container()\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebugging:\n\u001b[0;32m--> 180\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mregister_solution()\n",
      "File \u001b[0;32m~/Project/alo/dev-240111/scripts/creating_ai_solution/register_utils_ssh.py:603\u001b[0m, in \u001b[0;36mSolutionRegister.register_solution\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    601\u001b[0m     print_color(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[INFO] AI solution register response: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_solution_response\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcyan\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    602\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e: \n\u001b[0;32m--> 603\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to register AI solution: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Failed to register AI solution: \n Object of type Response is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from IPython.display import SVG, display, HTML\n",
    "import os \n",
    "from register_utils_ssh import SolutionRegister\n",
    "#################################\n",
    "#################################\n",
    "\n",
    "try:\n",
    "    del sys.modules['register_utils_ssh'] \n",
    "except:\n",
    "    pass\n",
    "\n",
    "register = SolutionRegister(\n",
    "    infra_setup=infra_setup, \n",
    "    solution_info=solution_info)\n",
    "\n",
    "register.debugging = False  ## default: False\n",
    "register.run(username=username, password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register.register_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inference_pipeline': [{'args': [{'description': '',\n",
      "                                   'name': 'concat_dataframes',\n",
      "                                   'type': ''},\n",
      "                                  {'description': '',\n",
      "                                   'name': 'drop_columns',\n",
      "                                   'type': ''},\n",
      "                                  {'description': '',\n",
      "                                   'name': 'encoding',\n",
      "                                   'type': ''},\n",
      "                                  {'description': '',\n",
      "                                   'name': 'groupkey_columns',\n",
      "                                   'type': ''},\n",
      "                                  {'description': '',\n",
      "                                   'name': 'input_path',\n",
      "                                   'type': ''},\n",
      "                                  {'description': '',\n",
      "                                   'name': 'time_column',\n",
      "                                   'type': ''},\n",
      "                                  {'description': '',\n",
      "                                   'name': 'use_all_x',\n",
      "                                   'type': ''},\n",
      "                                  {'description': '',\n",
      "                                   'name': 'x_columns',\n",
      "                                   'type': ''},\n",
      "                                  {'description': '',\n",
      "                                   'name': 'y_column',\n",
      "                                   'type': ''}],\n",
      "                         'step': 'input'},\n",
      "                        {'args': [{'description': '',\n",
      "                                   'name': 'custom',\n",
      "                                   'type': ''},\n",
      "                                  {'description': '',\n",
      "                                   'name': 'mode',\n",
      "                                   'type': ''}],\n",
      "                         'step': 'preprocess'},\n",
      "                        {'args': [{'description': '',\n",
      "                                   'name': 'model_type',\n",
      "                                   'type': ''},\n",
      "                                  {'description': '',\n",
      "                                   'name': 'run_shapley',\n",
      "                                   'type': ''}],\n",
      "                         'step': 'inference'}],\n",
      " 'train_pipeline': [{'args': [{'description': '',\n",
      "                               'name': 'concat_dataframes',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'drop_columns',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'encoding',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'groupkey_columns',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'input_path',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'time_column',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'use_all_x',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'x_columns',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'y_column',\n",
      "                               'type': ''}],\n",
      "                     'step': 'input'},\n",
      "                    {'args': [{'description': '', 'name': 'custom', 'type': ''},\n",
      "                              {'description': '', 'name': 'mode', 'type': ''}],\n",
      "                     'step': 'preprocess'},\n",
      "                    {'args': [{'description': '',\n",
      "                               'name': 'ignore_label_class',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'label_sampling',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'label_sampling_num',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'label_sampling_num_type',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'negative_target_class',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'sampling_groupkey_columns',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'sampling_method',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'sampling_num',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'sampling_num_type',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'sampling_type',\n",
      "                               'type': ''}],\n",
      "                     'step': 'sampling'},\n",
      "                    {'args': [{'description': '',\n",
      "                               'name': 'data_split_method',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'evaluation_metric',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'model_list',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'model_type',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'num_hpo',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'param_range',\n",
      "                               'type': ''},\n",
      "                              {'description': '',\n",
      "                               'name': 'shap_ratio',\n",
      "                               'type': ''}],\n",
      "                     'step': 'train'}]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO 진행할 사항 아래에 남겨두기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extra Job \n",
    "\n",
    "registerer.register_solution_instance()\n",
    "registerer.register_stream()\n",
    "registerer.request_run_stream()\n",
    "registerer.get_stream_status()\n",
    "registerer.download_artifacts()\n",
    "\n",
    "# 가상환경이 잘 connected 돼있는지 확인 \n",
    "!which python \n",
    "# 현재 작업경로 확인 \n",
    "!pwd\n",
    "\n",
    "# s3로부터 다운로드받은 train artifacts를 scripts 폴더 상위 경로의 main.py랑 같은 위치로 옮기고 추론 실행 \n",
    "import os\n",
    "os.makedirs(\"./.train_artifacts\",  exist_ok=True)\n",
    "\n",
    "!tar -xvf ./train_artifacts.tar.gz -C ./.train_artifacts/\n",
    "!cp -r .train_artifacts ../../\n",
    "!rm -rf ./.train_artifacts\n",
    "\n",
    "!python ../../main.py --mode inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr",
   "language": "python",
   "name": "tcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
