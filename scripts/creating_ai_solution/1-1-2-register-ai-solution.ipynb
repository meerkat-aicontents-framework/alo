{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP-1**. 준비 작업\n",
    "&#x1F600; **등록 할 AI Contents 의 experimental_plan.yaml 를 alo/config/ 에 준비해 둡니다.**\n",
    "\n",
    "&#x1F600; **가상 환경을 만들어 두고, ipykernel 을 제작해 둡니다.**     \n",
    "\n",
    "1. ALO 의 main.py 파일이 존재하는 위치에서 아래 명령어들을 순차 실행합니다.\n",
    "> conda create -n {ENV-NAME} python=3.10 \\\n",
    "> conda init bash \\\n",
    "> conda activate {ENV-NAME} \\\n",
    "> python main.py \\\n",
    "> pip install ipykernel \\\n",
    "> pip install requests \\\n",
    "> python -m ipykernel install --user --name {ENV-NAME} --display-name {IPYKERNEL-NAME}\n",
    "\n",
    "2. 본 jupyter notebook 에서, 위에서 생성한 ipykernel 을 선택 합니다. \\\n",
    "   가령 tcr이라는 이름의 가상환경을 만들었다면, 아래와 같이 선택합니다.\n",
    "\n",
    "<div style=\"margin: 40px\">\n",
    "<img src=\"./image/ipykernel.png\" width=\"400\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP-2**. Solution 정보 입력 및 Infra 정보 입력\n",
    "\n",
    "##### Solution information (dict) 작성 \n",
    "- pipeline_type: 파이프라인이 학습 및 추론 과정을 지원하는 표시     \n",
    "  - ex1: 학습 과 추론 모두 지원 --> ['train', 'inference]     \n",
    "  - ex2: 추론만 지원 --> ['inference']    \n",
    "  - ex3: 학습 만은 미지원 --> ~~['train']~~ \n",
    "\n",
    "- solution_update: 기존 솔루션을 업데이트 할지 결정\n",
    "  - True: 업데이트 진행. 기존 name 과 동일한 이름 입력 (name 이 존재하지 않으면 에러)  \n",
    "  - False: 신규 생성. 기존 name 과 다르게 입력 (name 이 존재하면 에러)\n",
    "\n",
    "- name: 솔루션 이름 \n",
    "  - 주의사항: 스페이스, 특수 문자, 한글은 미지원 \n",
    "\n",
    "- description: 솔루션이 Edge Conductor 의 UI 로 표시 될 때, 설명 가이드 작성 \n",
    "  - overview: 솔루션에 대한 전반적을 설명을 작성. (markdown 을 지원)\n",
    "  - 고려사항: overview 외에 다양한 sub-title 지원 예정.\n",
    "\n",
    "- contents_type: re-train, re-labeling 을 위한 설명 \n",
    "  - support_labeling: re-labeling 할지 결정. True 일 경우,   \n",
    "    Edge Conductor 에서 re-labeling 기능 활성화.   \n",
    "  - inference_result_datatype: EdgeApp 에 inference 결과를 표시하는 방법으로 'table', 'image' 중에 하나 선택. \n",
    "    AI Contents 제작 시, output.csv, output.jpg 를 생성해 두어야 함\n",
    "  - train_datatype: re-train 에 사용될 데이터 포멧 결정으로 'table', 'image' 중에 하나 선택. \n",
    "    AI Contents 제작 시, output.csv, output.jpg 를 생성해 두어야 함\n",
    "\n",
    "- train_gpu: True, False 중에 선택. True 일 경우, gpu 용 train docker container 제작 \n",
    "- train_gpu: True, False 중에 선택. True 일 경우, gpu 용 inference docker container 제작 \n",
    "- inference_arm: True, False 중에 선택. True 일 경우, arm 용 inference docker container 제작\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------#\n",
    "#        AI Solution Spec 작성           #\n",
    "#----------------------------------------#\n",
    "solution_info ={\n",
    "    'pipeline_type': [\"train\", \"inference\"], # \"single\", \"multi\"\n",
    "    'solution_update': True,\n",
    "    'name': 'tcr-test-ssh',\n",
    "    'description': {\n",
    "        \"overview\": \"Test TCR\"\n",
    "    },\n",
    "    'contents_type': {\n",
    "            'support_labeling': False,\n",
    "            'inference_result_datatype': 'table', # 'image'\n",
    "            'train_datatype': 'table' # 'image'\n",
    "    },\n",
    "    'train_gpu': True, ## cpu, gpu\n",
    "    'inference_gpu': True,\n",
    "    \"inference_arm\": True  # amd, arm  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AI Solution 이 동작될 Infra (dict) 설정\n",
    "- AIC_URI: AI Conductor 또는 Solution Storage 의 web server 주소. \n",
    "  - 고객지수플랫폼: \"https://aic-kic.aidxlge.com/\"\n",
    "  - 마그나 운영과제: \"https://aic-kic.aidxlge.com/\"\n",
    "  - 담당테스트 환경: \"http://10.158.2.243:9999/\"\n",
    "  - 사외테스트 환경: \"https://web.aic-dev.lgebigdata.com/\" \n",
    "\n",
    "- REGION: AWS Cloud 의 region 값 (\"ap-northeat-2\" 고정)\n",
    "- WORKSPACE_NAME: 프로젝트 명을 의미.   \n",
    "  (기술적의미: ML Ochestractor 의 물리적 태그 명으로 Cost 측정 단위)\n",
    "  - 고객지수플랫폼: \"cism-ws\"\n",
    "  - 마그나 운영과제: \"magna-ws\"\n",
    "  - 담당테스트 환경: \"cism-ws\", \"magna-ws\"\n",
    "  - 사외서비스 환경: \"cism-ws\", \"magna-ws\" \n",
    "\n",
    "- BUILD_METHOD: docker build 하는 방식 설정.    \n",
    "  docker container 형태의 jupyter notebook 에서 솔루션 제작 시,     \n",
    "  buildah (빌다) 라는 제작 방식을 사용해야 함.     \n",
    "  - 고객지수플랫폼: \"buildah\"\n",
    "  - 마그나운영과제: \"buildah\"\n",
    "  - 담당테스트 환경 (솔루션 제작은 로컬서버 jupyter 실행): \"docker\"\n",
    "  - 사외서비스 환경 (솔루션 제작은 로컬서버 jupyter 실행): \"docker\"\n",
    "\n",
    "- VERSION: AI Solution 의 metadata 인 solution_metadata 의 format 버전.   \n",
    "           AIC_URI 마다 지원버전이 다름.    \n",
    "  - 모든 플랫폼 & 서비스 환경: 1.0 으로 동일 \n",
    "\n",
    "- SOLUTION_TYPE: AI Solution 이 공유되는 계정 범위. 'private', 'public' 중에 하나 선택.   \n",
    "  - 'public' : AI-Advisor 가 설치될 때, built-in 되어 설치 할 solution 의미.   \n",
    "    (SYSTEM MANAGER 만 등록 가능)\n",
    "  - 'private': 과제 단위로 공유 될 solution. \n",
    "\n",
    "- REPOSITORY_TAGS: ECR repository 를 생성 시, 입력 할 Tags 값. 과금를 위한 표시 정보 (buildah 모드만 지원)\n",
    "  - 고객지수플랫폼, 마그나운영과제:    \n",
    "    \"REPOSITORY_TAGS\": [ \n",
    "      \"Key=Company,Value=LGE\",    \n",
    "      \"Key=Owner,Value=IC360\",    \n",
    "      \"Key=HQ,Value=CDO\",    \n",
    "      \"Key=Division,Value=CDO\",    \n",
    "      \"Key=Infra Region,Value=KIC\",    \n",
    "      \"Key=Service Mode,Value=OP\",     \n",
    "      \"Key=Cost Type,Value=COMPUTING\",     \n",
    "      \"Key=Project,Value=CIS\",     \n",
    "      \"Key=Sub Project,Value=CISM\",     \n",
    "      \"Key=System,Value=AIDX\"]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "infra_setup = {\n",
    "    ### system info. \n",
    "    'AIC_URI': \"https://web.aic-dev.lgebigdata.com/\",  ## 실 서버 \n",
    "    \"REGION\": \"ap-northeast-2\",\n",
    "    \"WORKSPACE_NAME\": \"cism-ws\",  ## magna-ws, cism-ws\n",
    "    \"BUILD_METHOD\": \"docker\",  ## docker, buildah \n",
    "\n",
    "    'VERSION': 1.0,\n",
    "    \"LOGIN_MODE\": \"static\", ## ldap, static\n",
    "    \"ECR_TAG\": \"latest\",   ## 없어질 사항\n",
    "    \"SOLUTION_TYPE\": \"private\", ##public, private \n",
    "    \"REPOSITORY_TAGS\": [ \n",
    "      \"Key=Company,Value=LGE\",\n",
    "      \"Key=Owner,Value=IC360\",\n",
    "      \"Key=HQ,Value=CDO\",\n",
    "      \"Key=Division,Value=CDO\",\n",
    "      \"Key=Infra Region,Value=KIC\",\n",
    "      \"Key=Service Mode,Value=OP\",\n",
    "      \"Key=Cost Type,Value=COMPUTING\",\n",
    "      \"Key=Project,Value=CIS\",\n",
    "      \"Key=Sub Project,Value=CISM\",\n",
    "      \"Key=System,Value=AIDX\"]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP-3**. AI Solution 등록\n",
    "\n",
    "##### 3-1. Username & Password 를 입력 \n",
    "\n",
    "> !! 접속이 실패되는 경우, AI Conductor 에게 계정 생성을 요청 하시기 바랍니다.   \n",
    "> Contact Us: hyunsoo0802.lim@lge.com  (LGE AI빅데이터담당, AI Conductor 담당자)\n",
    "\n",
    "> Login 방식이 {'LOGIN_METHOD': 'ldap'} 로 설정되어 있는 경우, LGEP 의 ID & PW 를 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your ID :  cism-dev\n",
      "Your PW :  cism-dev@com\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "username = input('Username: ')\n",
    "password = getpass.getpass('Password: ')\n",
    "\n",
    "print(\"Your ID : \", username)\n",
    "print(\"Your PW : \", password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-2. ALO 솔루션 등록 실행\n",
    "아래와 같은 과정이 순차적으로 실행 됨. 진행 중 Error 가 발생하게 되면, STEP-2 설정을 변경 함.\n",
    "> Contact US: sehyun.song@lge.com (LGE AI빅데이터 담당, ALO 담당자)\n",
    "\n",
    "AI Solution 등록 과정 Process:  \n",
    "> 1.  solution name 입력 \n",
    "> 2.  description & wrangler code 를 solution_metadata 에 삽입\n",
    "> 3.  contents_type 을 solution_metadata 에 삽입\n",
    "> 4.  description 의 solution icon 을 solution_metadata 에 삽입\n",
    "> 5.  train 용 user parameter 를 solution_metadata 에 삽입\n",
    "> 6.  s3 에 train data & artifacts 업로드 \n",
    "> 7.  train 용 ecr repository 생성 및 docker container 업로드 \n",
    "> 8.  inference 용 user parameter 를 solution_metadata 에 삽입\n",
    "> 9.  s3 에 inference data & artifacts 업로드 \n",
    "> 10. inference 용 ecr repository 생성 및 docker container 업로드 \n",
    "> 11. solution 등록 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Initiate ALO operation mode\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SYSTEM] Solutoin 등록에 필요한 setup file 들을 load 합니다. \u001b[0m\n",
      "\u001b[92m[SYSTEM] infra_setup: \u001b[0m\n",
      "{'AIC_URI': 'https://web.aic-dev.lgebigdata.com/',\n",
      " 'BUILDAH_TAGS': ['Key=Company,Value=LGE',\n",
      "                  'Key=Owner,Value=IC360',\n",
      "                  'Key=HQ,Value=CDO',\n",
      "                  'Key=Division,Value=CDO',\n",
      "                  'Key=Infra Region,Value=KIC',\n",
      "                  'Key=Service Mode,Value=OP',\n",
      "                  'Key=Cost Type,Value=COMPUTING',\n",
      "                  'Key=Project,Value=CIS',\n",
      "                  'Key=Sub Project,Value=CISM',\n",
      "                  'Key=System,Value=AIDX'],\n",
      " 'BUILD_METHOD': 'docker',\n",
      " 'ECR_TAG': 'latest',\n",
      " 'LOGIN_MODE': 'static',\n",
      " 'REGION': 'ap-northeast-2',\n",
      " 'SOLUTION_TYPE': 'private',\n",
      " 'VERSION': 1.0,\n",
      " 'WORKSPACE_NAME': 'cism-ws'}\n",
      "\n",
      "API setup 파일이 존재 하지 않으므로, Default 파일을 load 합니다. (path: ./api_setup.yaml)\n",
      "\u001b[92m[SYSTEM] solution_info.: \u001b[0m\n",
      "{'contents_type': {'inference_result_datatype': 'table',\n",
      "                   'support_labeling': False,\n",
      "                   'train_datatype': 'table'},\n",
      " 'description': {'algorithm': '',\n",
      "                 'input_data': '',\n",
      "                 'output_data': '',\n",
      "                 'overview': 'Test TCR',\n",
      "                 'title': 'tcr-test-ssh',\n",
      "                 'user_parameters': ''},\n",
      " 'inference_arm': True,\n",
      " 'inference_gpu': True,\n",
      " 'name': 'tcr-test-ssh',\n",
      " 'pipeline_type': ['train', 'inference'],\n",
      " 'solution_update': True,\n",
      " 'train_gpu': True}\n",
      "\u001b[92m[SYSTEM] S3 key 파일을 로드 합니다. (file: /nas001/users/ruci.sung/aws.key)\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Login to AI Conductor\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 계정으로 접근 가능한 workspace list: ['cism-ws']\n",
      "\u001b[92m[SYSTEM] 접근 요청하신 workspace (cism-ws) 은 해당 계정으로 접근 가능합니다.\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Solution Name Creation\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "<Response [200]>\n",
      "\u001b[92m[SUCCESS] 입력하신 Solution Name (tcr-test-ssh)은 사용 가능합니다. \u001b[0m\n",
      "\u001b[92m[SYSTEM] Solution Name List (in-use):\u001b[0m\n",
      "\u001b[96m╒════╤══════════════════════════╕\n",
      "│    │ AI solutions             │\n",
      "╞════╪══════════════════════════╡\n",
      "│  0 │ solution-hyunsoo-cism-20 │\n",
      "├────┼──────────────────────────┤\n",
      "│  1 │ pytest-solution-1        │\n",
      "├────┼──────────────────────────┤\n",
      "│  2 │ solution-hyunsoo-cism-2  │\n",
      "├────┼──────────────────────────┤\n",
      "│  3 │ solution-hyunsoo-cism-1  │\n",
      "╘════╧══════════════════════════╛\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Check ECR & S3 Resource\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SYSTEM] AWS ECR:  \u001b[0m\n",
      "086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solutions/cism/\n",
      "\u001b[92m[SYSTEM] AWS S3 buckeet:  \u001b[0m\n",
      "s3-an2-hyunsoo-dev-cism\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set AI Solution Description\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadata.yaml.\u001b[0m\n",
      "description: {'overview': 'Test TCR', 'title': 'tcr-test-ssh', 'input_data': '', 'output_data': '', 'user_parameters': '', 'algorithm': ''}\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set Wrangler\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[93m[WARNING] wrangler.py 가 해당 위치에 존재해야 합니다. (path: ./wrangler/wrangler.py)\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set Contents Type (for retrain & relabeling)\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] contents_type 을 solution_metadata 에 성공적으로 업데이트 하였습니다.\u001b[0m\n",
      "edgeconductor_interfance: {'support_labeling': False, 'inference_result_datatype': 'table', 'train_datatype': 'table'}\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Display icon list\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload icon\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] update solution_metadata.yaml:\u001b[0m\n",
      "description: -icon: s3://s3-an2-hyunsoo-dev-aia/icons/ic_artificial_intelligence.svg \n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Check to access S3\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "[INFO] AWS region: ap-northeast-2\n",
      "\u001b[92m[INFO] AWS S3 access check: OK\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Display train Resource List\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "train 에 사용될 resource 를 선택해주세요(type['high', 'standard']):\n",
      "\u001b[96m╒════╤══════════╤══════════════════╤════════╤══════════╤═══════╕\n",
      "│    │ name     │ label            │   vcpu │   ram_gb │   gpu │\n",
      "╞════╪══════════╪══════════════════╪════════╪══════════╪═══════╡\n",
      "│  0 │ high     │ cism-ws-high     │      8 │       32 │     0 │\n",
      "├────┼──────────┼──────────────────┼────────┼──────────┼───────┤\n",
      "│  1 │ standard │ cism-ws-standard │      2 │        8 │     0 │\n",
      "╘════╧══════════╧══════════════════╧════════╧══════════╧═══════╛\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set train Resource\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadat.yaml:\u001b[0m\n",
      "pipeline[0]: -resource: standard\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set train user parameters:\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SYSTEM] experimental_plan.yaml 에 ui_args_detail 이 정상 기록 되었는지 체크 합니다.\u001b[0m\n",
      "ui_arg_detail: 에 [input](x_columns) 이 기록됨을 확인. \n",
      "ui_arg_detail: 에 [input](y_column) 이 기록됨을 확인. \n",
      "ui_arg_detail: 에 [train](evaluation_metric) 이 기록됨을 확인. \n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload train data to S3\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadata.yaml:\u001b[0m\n",
      "pipeline: type: train, dataset_uri: {'dataset_uri': ['s3://s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/train/data/']} \n",
      "\u001b[96m[SYSTEM] Start uploading data into S3 from local folder:\u001b[0m\n",
      "/home/sehyun.song/Project/alo/dev-240111/input/train/\n",
      "\u001b[93m[SYSTEM] Deleted pre-existing S3 object: ai-solutions/tcr-test-ssh/v1/train/data/\u001b[0m\n",
      "\u001b[93m[SYSTEM] Deleted pre-existing S3 object: ai-solutions/tcr-test-ssh/v1/train/data/default_train/iris.csv\u001b[0m\n",
      "\u001b[92m[SUCCESS] update train_data to S3:\u001b[0m\n",
      "s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/train/data/default_train/iris.csv\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload train artifacts to S3\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadata.yaml:\u001b[0m\n",
      "pipeline: type:train, model_uri: {'artifact_uri': 's3://s3-an2-hyunsoo-dev-cism//ai-solutions/tcr-test-ssh/v1/train/artifacts/'} \n",
      "\u001b[96m[SYSTEM] Start uploading train artifacts into S3 from local folder:\u001b[0m\n",
      "/home/sehyun.song/Project/alo/dev-240111/.temp_artifacts_dir/\n",
      "\u001b[93m[INFO] Deleted pre-existing S3 object:\u001b[0m\n",
      "/ai-solutions/tcr-test-ssh/v1/train/artifacts//\n",
      "\u001b[93m[INFO] Deleted pre-existing S3 object:\u001b[0m\n",
      "/ai-solutions/tcr-test-ssh/v1/train/artifacts//model.tar.gz\n",
      "\u001b[93m[INFO] Deleted pre-existing S3 object:\u001b[0m\n",
      "/ai-solutions/tcr-test-ssh/v1/train/artifacts//train_artifacts.tar.gz\n",
      "\u001b[92m[SUSTEM] S3 object key (new): \u001b[0m\n",
      "s3-an2-hyunsoo-dev-cism//ai-solutions/tcr-test-ssh/v1/train/artifacts//train_artifacts.tar.gz\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set AWS ECR\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set alo source code\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/main.py \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/ \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/src \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/src \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/config \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/config \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/assets \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/assets \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/alolib \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/alolib \" \u001b[0m\n",
      "SSH_DEBUG:  /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/config/experimental_plan.yaml\n",
      "\u001b[92m[SUCCESS] Success ALO directory setting.\u001b[0m\n",
      "\u001b[92m[SUCESS] set DOCKERFILE for (train) pipeline\u001b[0m\n",
      "\u001b[93m[SYSTEM] Repository ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh already exists. Deleting...\u001b[0m\n",
      "\u001b[94m[SYSTEM] target AWS ECR url: \u001b[0m\n",
      "086558720570.dkr.ecr.ap-northeast-2.amazonaws.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/sehyun.song/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[SYSTEM] AWS ECR | docker login result:\u001b[0m\n",
      "Login Succeeded\n",
      "\n",
      "\u001b[96m[SYSTEM] Target AWS ECR repository:\u001b[0m\n",
      "ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh\n",
      "\u001b[96m[SYSTEM] AWS ECR create-repository response: \u001b[0m\n",
      "{'repository': {'repositoryArn': 'arn:aws:ecr:ap-northeast-2:086558720570:repository/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh', 'registryId': '086558720570', 'repositoryName': 'ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh', 'repositoryUri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh', 'createdAt': datetime.datetime(2024, 1, 20, 14, 37, 22, 99000, tzinfo=tzlocal()), 'imageTagMutability': 'MUTABLE', 'imageScanningConfiguration': {'scanOnPush': False}, 'encryptionConfiguration': {'encryptionType': 'AES256'}}, 'ResponseMetadata': {'RequestId': '51cb98e3-b32a-4c85-bde5-6230a9bd92f1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '51cb98e3-b32a-4c85-bde5-6230a9bd92f1', 'date': 'Sat, 20 Jan 2024 05:37:22 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '589', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload Docker Container\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "Sending build context to Docker daemon  3.115MB\n",
      "Step 1/12 : FROM public.ecr.aws/docker/library/python:3.10-slim-bullseye\n",
      " ---> ee6be26d226b\n",
      "Step 2/12 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> c5214f1ac135\n",
      "Step 3/12 : RUN apt-get install -y apt-utils\n",
      " ---> Using cache\n",
      " ---> b4b5b8d367ba\n",
      "Step 4/12 : RUN apt-get install -y --no-install-recommends          build-essential          wget          ca-certificates          git          gcc     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> f61e2821ba8e\n",
      "Step 5/12 : ENV LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 729705be4177\n",
      "Step 6/12 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 47764350993e\n",
      "Step 7/12 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> ead025070b9a\n",
      "Step 8/12 : ENV SOLUTION_PIPELINE_MODE='train'\n",
      " ---> Using cache\n",
      " ---> 94201625ca27\n",
      "Step 9/12 : ENV PATH=\"/framework:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 1d6d3cf6e2d1\n",
      "Step 10/12 : COPY /alo /framework\n",
      " ---> 0d6f57d6bd31\n",
      "Step 11/12 : WORKDIR /framework\n",
      " ---> Running in dc42182954f3\n",
      "Removing intermediate container dc42182954f3\n",
      " ---> 0bfb9e0b9399\n",
      "Step 12/12 : CMD [\"python\", \"main.py\"]\n",
      " ---> Running in 4b02325512fb\n",
      "Removing intermediate container 4b02325512fb\n",
      " ---> a6fde0be4670\n",
      "[Warning] One or more build-args [ARCHITECTURE MODE USE_GPU] were not consumed\n",
      "Successfully built a6fde0be4670\n",
      "Successfully tagged 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh:latest\n",
      "The push refers to repository [086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh]\n",
      "89ab929bbfe1: Preparing\n",
      "52f6a5bb02a9: Preparing\n",
      "1ae895bce35d: Preparing\n",
      "d80559b265dd: Preparing\n",
      "9647f452a529: Preparing\n",
      "7972dfbb0bc8: Preparing\n",
      "29578fbbec63: Preparing\n",
      "cc056986b725: Preparing\n",
      "74c0af6e0227: Preparing\n",
      "29578fbbec63: Waiting\n",
      "cc056986b725: Waiting\n",
      "7972dfbb0bc8: Waiting\n",
      "74c0af6e0227: Waiting\n",
      "89ab929bbfe1: Pushed\n",
      "1ae895bce35d: Pushed\n",
      "7972dfbb0bc8: Pushed\n",
      "9647f452a529: Pushed\n",
      "cc056986b725: Pushed\n",
      "d80559b265dd: Pushed\n",
      "29578fbbec63: Pushed\n",
      "74c0af6e0227: Pushed\n",
      "52f6a5bb02a9: Pushed\n",
      "latest: digest: sha256:8363c0a6fb5f4079b8deabaf6b93d7b4f55558aaf1704b5c60f5c3894564974f size: 2215\n",
      "Removing login credentials for https://index.docker.io/v1/\n",
      "\u001b[92m[SYSTEM] Completes setting << container_uri >> in solution_metadata.yaml:\u001b[0m\n",
      "pipeline: -container_uri: 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set inference Resource\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[93mEdgeApp 에 대한 resource 설정은 현재 미지원 입니다. resource=standard 로 고정 됩니다.\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadat.yaml:\u001b[0m\n",
      "pipeline[1]: -resource: standard\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set inference user parameters:\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SYSTEM] experimental_plan.yaml 에 ui_args_detail 이 정상 기록 되었는지 체크 합니다.\u001b[0m\n",
      "ui_arg_detail: 에 [input](x_columns) 이 기록됨을 확인. \n",
      "ui_arg_detail: 에 [inference](run_shapley) 이 기록됨을 확인. \n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload inference data to S3\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadata.yaml:\u001b[0m\n",
      "pipeline: type: inference, dataset_uri: {'dataset_uri': ['s3://s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/inference/data/']} \n",
      "\u001b[96m[INFO] Start uploading data into S3 from local folder:\u001b[0m\n",
      "/home/sehyun.song/Project/alo/dev-240111/input/inference/\n",
      "\u001b[93m[SYSTEM] Deleted pre-existing S3 object: ai-solutions/tcr-test-ssh/v1/inference/data/\u001b[0m\n",
      "\u001b[93m[SYSTEM] Deleted pre-existing S3 object: ai-solutions/tcr-test-ssh/v1/inference/data/default_inference/iris.csv\u001b[0m\n",
      "\u001b[92m[SUCCESS] update train_data to S3:\u001b[0m\n",
      "s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/inference/data/default_inference/iris.csv\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload inference artifacts to S3\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SUCCESS] Update solution_metadata.yaml:\u001b[0m\n",
      "pipeline: type:inference, model_uri: {'artifact_uri': 's3://s3-an2-hyunsoo-dev-cism//ai-solutions/tcr-test-ssh/v1/inference/artifacts/'} \n",
      "\u001b[96m[INFO] Start uploading inference artifacts into S3 from local folder:\u001b[0m\n",
      "/home/sehyun.song/Project/alo/dev-240111/.temp_artifacts_dir/\n",
      "\u001b[93m[INFO] Deleted pre-existing S3 object:\u001b[0m\n",
      "/ai-solutions/tcr-test-ssh/v1/inference/artifacts//\n",
      "\u001b[93m[INFO] Deleted pre-existing S3 object:\u001b[0m\n",
      "/ai-solutions/tcr-test-ssh/v1/inference/artifacts//inference_artifacts.tar.gz\n",
      "\u001b[92m[SUSTEM] S3 object key (new): \u001b[0m\n",
      "s3-an2-hyunsoo-dev-cism//ai-solutions/tcr-test-ssh/v1/inference/artifacts//inference_artifacts.tar.gz\n",
      "\u001b[96m\n",
      "[SYSTEM] Start uploading << model >> into S3 from local folder:\u001b[0m\n",
      "/home/sehyun.song/Project/alo/dev-240111/.temp_model_dir/\n",
      "\u001b[92m[SUSTEM] S3 object key (new): \u001b[0m\n",
      "s3-an2-hyunsoo-dev-cism//ai-solutions/tcr-test-ssh/v1/train/artifacts//model.tar.gz\n",
      "\u001b[92m[SUCCESS] Update solution_metadata.yaml:\u001b[0m\n",
      "pipeline: type:inference, model_uri: {'model_uri': 's3://s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/train/artifacts/'} \n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set AWS ECR\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Set alo source code\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/main.py \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/ \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/src \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/src \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/config \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/config \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/assets \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/assets \" \u001b[0m\n",
      "\u001b[94m[INFO] copy from \" /home/sehyun.song/Project/alo/dev-240111/alolib \"  -->  \" /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/alolib \" \u001b[0m\n",
      "SSH_DEBUG:  /home/sehyun.song/Project/alo/dev-240111/scripts/creating_ai_solution/alo/config/experimental_plan.yaml\n",
      "\u001b[92m[SUCCESS] Success ALO directory setting.\u001b[0m\n",
      "\u001b[92m[SUCESS] set DOCKERFILE for (inference) pipeline\u001b[0m\n",
      "\u001b[93m[SYSTEM] Repository ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh already exists. Deleting...\u001b[0m\n",
      "\u001b[94m[SYSTEM] target AWS ECR url: \u001b[0m\n",
      "086558720570.dkr.ecr.ap-northeast-2.amazonaws.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/sehyun.song/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[SYSTEM] AWS ECR | docker login result:\u001b[0m\n",
      "Login Succeeded\n",
      "\n",
      "\u001b[96m[SYSTEM] Target AWS ECR repository:\u001b[0m\n",
      "ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh\n",
      "\u001b[96m[SYSTEM] AWS ECR create-repository response: \u001b[0m\n",
      "{'repository': {'repositoryArn': 'arn:aws:ecr:ap-northeast-2:086558720570:repository/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh', 'registryId': '086558720570', 'repositoryName': 'ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh', 'repositoryUri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh', 'createdAt': datetime.datetime(2024, 1, 20, 14, 37, 52, 407000, tzinfo=tzlocal()), 'imageTagMutability': 'MUTABLE', 'imageScanningConfiguration': {'scanOnPush': False}, 'encryptionConfiguration': {'encryptionType': 'AES256'}}, 'ResponseMetadata': {'RequestId': '50d29041-e424-4a8e-a039-293ae1394b92', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '50d29041-e424-4a8e-a039-293ae1394b92', 'date': 'Sat, 20 Jan 2024 05:37:52 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '601', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Upload Docker Container\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "Sending build context to Docker daemon  3.117MB\n",
      "Step 1/12 : FROM public.ecr.aws/docker/library/python:3.10-slim-bullseye\n",
      " ---> ee6be26d226b\n",
      "Step 2/12 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> c5214f1ac135\n",
      "Step 3/12 : RUN apt-get install -y apt-utils\n",
      " ---> Using cache\n",
      " ---> b4b5b8d367ba\n",
      "Step 4/12 : RUN apt-get install -y --no-install-recommends          build-essential          wget          ca-certificates          git          gcc     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> f61e2821ba8e\n",
      "Step 5/12 : ENV LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 729705be4177\n",
      "Step 6/12 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 47764350993e\n",
      "Step 7/12 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> ead025070b9a\n",
      "Step 8/12 : ENV SOLUTION_PIPELINE_MODE='inference'\n",
      " ---> Using cache\n",
      " ---> aa77d76f572d\n",
      "Step 9/12 : ENV PATH=\"/framework:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 53b6bdefdee1\n",
      "Step 10/12 : COPY /alo /framework\n",
      " ---> 92009ce0f4b8\n",
      "Step 11/12 : WORKDIR /framework\n",
      " ---> Running in a66afbb5f43f\n",
      "Removing intermediate container a66afbb5f43f\n",
      " ---> 13ccdb410063\n",
      "Step 12/12 : CMD [\"python\", \"main.py\"]\n",
      " ---> Running in eb8daf44a466\n",
      "Removing intermediate container eb8daf44a466\n",
      " ---> 7b5787b3e9d2\n",
      "[Warning] One or more build-args [ARCHITECTURE MODE USE_GPU] were not consumed\n",
      "Successfully built 7b5787b3e9d2\n",
      "Successfully tagged 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh:latest\n",
      "The push refers to repository [086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh]\n",
      "98a6e79457ef: Preparing\n",
      "52f6a5bb02a9: Preparing\n",
      "1ae895bce35d: Preparing\n",
      "d80559b265dd: Preparing\n",
      "9647f452a529: Preparing\n",
      "7972dfbb0bc8: Preparing\n",
      "29578fbbec63: Preparing\n",
      "cc056986b725: Preparing\n",
      "74c0af6e0227: Preparing\n",
      "29578fbbec63: Waiting\n",
      "cc056986b725: Waiting\n",
      "74c0af6e0227: Waiting\n",
      "7972dfbb0bc8: Waiting\n",
      "98a6e79457ef: Pushed\n",
      "1ae895bce35d: Pushed\n",
      "7972dfbb0bc8: Pushed\n",
      "9647f452a529: Pushed\n",
      "cc056986b725: Pushed\n",
      "d80559b265dd: Pushed\n",
      "29578fbbec63: Pushed\n",
      "74c0af6e0227: Pushed\n",
      "52f6a5bb02a9: Pushed\n",
      "latest: digest: sha256:1c70519d1bcddee45dbe1dd101ce262d366ccad8dd59d9b17106c6175c9151b5 size: 2215\n",
      "Removing login credentials for https://index.docker.io/v1/\n",
      "\u001b[92m[SYSTEM] Completes setting << container_uri >> in solution_metadata.yaml:\u001b[0m\n",
      "pipeline: -container_uri: 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh\n",
      "\u001b[94m\n",
      "#########################################\u001b[0m\n",
      "\u001b[94m#######    Register AI solution\u001b[0m\n",
      "\u001b[94m#########################################\n",
      "\u001b[0m\n",
      "\u001b[96m[SUCCESS] AI Solution 등록을 성공하였습니다. \u001b[0m\n",
      "[INFO] AI solution register response: \n",
      " {'id': 'c7bcc712-1666-449b-88e7-d4be992ab5a1', 'name': 'tcr-test-ssh', 'scope_ws': 'cism-ws', 'version': {'id': 'b2c2447e-1959-44e7-a2d7-0291a971afe9', 'version': 1, 'metadata_dict': {'version': 1.0, 'name': 'tcr-test-ssh', 'description': {'overview': 'Test TCR', 'title': 'tcr-test-ssh', 'input_data': '', 'output_data': '', 'user_parameters': '', 'algorithm': '', 'icon': 's3://s3-an2-hyunsoo-dev-aia/icons/ic_artificial_intelligence.svg'}, 'pipeline': [{'type': 'train', 'resource': {'default': 'standard'}, 'parameters': {'candidate_parameters': [{'step': 'input', 'args': [{'input_path': 'default_train', 'x_columns': ['input_x0', 'input_x1', 'input_x2', 'input_x3'], 'use_all_x': False, 'y_column': 'target', 'groupkey_columns': None, 'drop_columns': None, 'time_column': None, 'concat_dataframes': True, 'encoding': None}], 'ui_args': ['x_columns', 'y_column']}, {'step': 'preprocess', 'args': [{'mode': 'auto', 'custom': {}}]}, {'step': 'sampling', 'args': [{'sampling_type': 'none', 'sampling_method': 'random', 'label_sampling': False, 'ignore_label_class': None, 'negative_target_class': None, 'label_sampling_num_type': None, 'label_sampling_num': None, 'sampling_groupkey_columns': None, 'sampling_num_type': 'ratio', 'sampling_num': 0.8}]}, {'step': 'train', 'args': [{'model_type': 'classification', 'data_split_method': 'cross_validate', 'evaluation_metric': 'accuracy', 'model_list': ['lgb', 'rf', 'cb'], 'num_hpo': 3, 'param_range': {'rf': {'max_depth': 6, 'n_estimators': [300, 500]}, 'gbm': {'max_depth': [5, 7], 'n_estimators': [300, 500]}, 'ngb': {'col_sample': [0.6, 0.8], 'n_estimators': [100, 300]}, 'lgb': {'max_depth': [5, 9], 'n_estimators': [300, 500]}, 'cb': {'max_depth': [5, 9], 'n_estimators': [100, 500]}}, 'shap_ratio': 1.0}], 'ui_args': ['evaluation_metric']}], 'selected_user_parameters': [{'step': 'input', 'args': []}, {'step': 'preprocess', 'args': []}, {'step': 'sampling', 'args': []}, {'step': 'train', 'args': []}], 'user_parameters': [{'step': 'input', 'args': [{'name': 'x_columns', 'description': \"TCR 모델링에 사용될 x columns를 ','로 구분하여 기입합니다. ex) x_column1, x_column2\", 'type': 'string', 'default': '', 'range': [1, 1000000]}, {'name': 'y_column', 'description': 'TCR 모델링에 사용될 y column명을 기입합니다. ex) y_column', 'type': 'string', 'default': '', 'range': [1, 1000000]}]}, {'step': 'preprocess', 'args': []}, {'step': 'sampling', 'args': []}, {'step': 'train', 'args': [{'name': 'evaluation_metric', 'description': 'TCR 학습 시 best 모델 기준을 선정합니다.', 'type': 'single_selection', 'default': 'accuracy', 'selectable': ['accuracy', 'precision', 'recall', 'f1-score']}]}]}, 'dataset_uri': ['s3://s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/train/data/'], 'artifact_uri': 's3://s3-an2-hyunsoo-dev-cism//ai-solutions/tcr-test-ssh/v1/train/artifacts/', 'container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/train/tcr-test-ssh'}, {'type': 'inference', 'resource': {'default': 'standard'}, 'parameters': {'candidate_parameters': [{'step': 'input', 'args': [{'input_path': 'default_inference', 'x_columns': ['input_x0', 'input_x1', 'input_x2', 'input_x3'], 'use_all_x': False, 'y_column': None, 'groupkey_columns': None, 'drop_columns': None, 'time_column': None, 'concat_dataframes': True, 'encoding': None}], 'ui_args': ['x_columns']}, {'step': 'preprocess', 'args': [{'mode': 'auto', 'custom': {}}]}, {'step': 'inference', 'args': [{'model_type': 'classification', 'run_shapley': True}], 'ui_args': ['run_shapley']}], 'selected_user_parameters': [{'step': 'input', 'args': []}, {'step': 'preprocess', 'args': []}, {'step': 'inference', 'args': []}], 'user_parameters': [{'step': 'input', 'args': [{'name': 'x_columns', 'description': \"TCR 모델링에 사용될 x columns를 ','로 구분하여 기입합니다. ex) x_column1, x_column2\", 'type': 'string', 'default': None, 'range': [1, 1000000]}]}, {'step': 'preprocess', 'args': []}, {'step': 'inference', 'args': [{'name': 'run_shapley', 'description': 'inference시 shapley value 출력 여부를 결정합니다 (shapley value 출력: True)', 'type': 'single_selection', 'default': True, 'selectable': [True, False]}]}]}, 'dataset_uri': ['s3://s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/inference/data/'], 'artifact_uri': 's3://s3-an2-hyunsoo-dev-cism//ai-solutions/tcr-test-ssh/v1/inference/artifacts/', 'model_uri': 's3://s3-an2-hyunsoo-dev-cism/ai-solutions/tcr-test-ssh/v1/train/artifacts/', 'container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/cism/ai-solutions/tcr-test-ssh/inference/tcr-test-ssh'}], 'wrangler_code_uri': '', 'wrangler_dataset_uri': '', 'edgeconductor_interface': {'support_labeling': False, 'inference_result_datatype': 'table', 'train_datatype': 'table'}, 'edgeapp_interface': {'redis_server_uri': ''}}, 'created_at': '2024-01-20T05:38:21', 'updated_at': '2024-01-20T05:38:21'}, 'is_deleted': 0, 'created_at': '2024-01-20T05:38:21', 'updated_at': '2024-01-20T05:38:21'}\n",
      "\u001b[92m[SYSTEM] register 결과를 ./register_solution.json 에 저장합니다.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from IPython.display import SVG, display, HTML\n",
    "import os \n",
    "from solution_register import SolutionRegister\n",
    "\n",
    "try:\n",
    "    del sys.modules['solution_register'] \n",
    "except:\n",
    "    pass\n",
    "\n",
    "register = SolutionRegister(\n",
    "    infra_setup=infra_setup, \n",
    "    solution_info=solution_info)\n",
    "\n",
    "register.debugging = False  ## default: False\n",
    "register.skip_generation_docker = False  ## default: False\n",
    "register.run(username=username, password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 등록된 AI Solution 테스트 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\n",
      "######################################################\u001b[0m\n",
      "\u001b[94m#######    Initiate ALO operation mode\u001b[0m\n",
      "\u001b[94m########################################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SYSTEM] Solutoin 등록에 필요한 setup file 들을 load 합니다. \u001b[0m\n",
      "\u001b[92m[SYSTEM] infra_setup: \u001b[0m\n",
      "{'AIC_URI': 'https://web.aic-dev.lgebigdata.com/',\n",
      " 'BUILDAH_TAGS': ['Key=Company,Value=LGE',\n",
      "                  'Key=Owner,Value=IC360',\n",
      "                  'Key=HQ,Value=CDO',\n",
      "                  'Key=Division,Value=CDO',\n",
      "                  'Key=Infra Region,Value=KIC',\n",
      "                  'Key=Service Mode,Value=OP',\n",
      "                  'Key=Cost Type,Value=COMPUTING',\n",
      "                  'Key=Project,Value=CIS',\n",
      "                  'Key=Sub Project,Value=CISM',\n",
      "                  'Key=System,Value=AIDX'],\n",
      " 'BUILD_METHOD': 'docker',\n",
      " 'ECR_TAG': 'latest',\n",
      " 'LOGIN_MODE': 'static',\n",
      " 'REGION': 'ap-northeast-2',\n",
      " 'SOLUTION_TYPE': 'private',\n",
      " 'VERSION': 1.0,\n",
      " 'WORKSPACE_NAME': 'cism-ws'}\n",
      "\n",
      "API setup 파일이 존재 하지 않으므로, Default 파일을 load 합니다. (path: ./api_setup.yaml)\n",
      "\u001b[92m[SYSTEM] solution_info.: \u001b[0m\n",
      "{'contents_type': {'inference_result_datatype': 'table',\n",
      "                   'support_labeling': False,\n",
      "                   'train_datatype': 'table'},\n",
      " 'description': {'algorithm': '',\n",
      "                 'input_data': '',\n",
      "                 'output_data': '',\n",
      "                 'overview': 'Test TCR',\n",
      "                 'title': 'tcr-test-ssh',\n",
      "                 'user_parameters': ''},\n",
      " 'inference_arm': True,\n",
      " 'inference_gpu': True,\n",
      " 'name': 'tcr-test-ssh',\n",
      " 'pipeline_type': ['train', 'inference'],\n",
      " 'solution_update': True,\n",
      " 'train_gpu': True}\n",
      "\u001b[92m[SYSTEM] S3 key 파일을 로드 합니다. (file: /nas001/users/ruci.sung/aws.key)\u001b[0m\n",
      "\u001b[94m\n",
      "######################################################\u001b[0m\n",
      "\u001b[94m#######    Login to AI Conductor\u001b[0m\n",
      "\u001b[94m########################################################\n",
      "\u001b[0m\n",
      "해당 계정으로 접근 가능한 workspace list: ['cism-ws']\n",
      "\u001b[92m[SYSTEM] 접근 요청하신 workspace (cism-ws) 은 해당 계정으로 접근 가능합니다.\u001b[0m\n",
      "\u001b[94m\n",
      "######################################################\u001b[0m\n",
      "\u001b[94m#######    Get AI solution stream status\u001b[0m\n",
      "\u001b[94m########################################################\n",
      "\u001b[0m\n",
      "\u001b[92m[SYSTEM] Stream 실행 정보를 ./interface/.response_stream_run.json 에서 확인합니다.\u001b[0m\n",
      "\u001b[96m[SUCCESS] Stream Status 요청을 성공하였습니다. \u001b[0m\n",
      "[INFO] response: \n",
      " {'id': 'fc649a8f-2eb1-49f7-a6f9-2c0d2aee8ac3', 'name': 'tcr-test-ssh-20240120084007378', 'workspace_name': 'cism-ws', 'stream_id': 'df921f7c-b499-42f7-9b13-fdfbc7b654d3', 'train_pipeline_id': 'e883be2c-aa4a-444b-983d-6cac2c47da1a', 'status': 'Failed', 'train_dataset_uri': [], 'train_artifact_uri': 's3://s3-an2-hyunsoo-dev-cism/instances/tcr-test-ssh/df921f7c-b499-42f7-9b13-fdfbc7b654d3/train/artifacts/2024/01/20/084007.378/', 'model_version': '0', 'is_deleted': 0, 'created_at': '2024-01-20T08:40:07', 'updated_at': '2024-01-20T08:40:27'}\n",
      "\u001b[92m[SYSTEM] status 확인 결과를 ./interface/.response_stream_status.json 에 저장합니다.\u001b[0m\n",
      "Failed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del sys.modules['solution_register'] \n",
    "except:\n",
    "    pass\n",
    "\n",
    "from solution_register import SolutionRegister\n",
    "\n",
    "register2 = SolutionRegister(\n",
    "    infra_setup=infra_setup, \n",
    "    solution_info=solution_info)\n",
    "    \n",
    "register2.login(username, password)\n",
    "# register2.register_solution_instance()\n",
    "# register2.load_solution_instance_list()\n",
    "# register2.register_stream()\n",
    "# register2.request_run_stream()\n",
    "status = register2.get_stream_status()\n",
    "print(status)\n",
    "\n",
    "register2.download_artifacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 가상환경이 잘 connected 돼있는지 확인 \n",
    "!which python \n",
    "# 현재 작업경로 확인 \n",
    "!pwd\n",
    "\n",
    "# s3로부터 다운로드받은 train artifacts를 scripts 폴더 상위 경로의 main.py랑 같은 위치로 옮기고 추론 실행 \n",
    "import os\n",
    "os.makedirs(\"./.train_artifacts\",  exist_ok=True)\n",
    "\n",
    "!tar -xvf ./train_artifacts.tar.gz -C ./.train_artifacts/\n",
    "!cp -r .train_artifacts ../../\n",
    "!rm -rf ./.train_artifacts\n",
    "\n",
    "!python ../../main.py --mode inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr",
   "language": "python",
   "name": "tcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
