{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP-1**. Prepare for AI Solution Registration\n",
    "&#x1F600; **등록 할 AI Contents 의 experimental_plan.yaml 를 alo/config/ 에 준비해 둡니다.**\n",
    "\n",
    "&#x1F600; **가상 환경을 만들어 두고, ipykernel 을 제작해 둡니다.**     \n",
    "\n",
    "- ALO 의 main.py 파일이 존재하는 위치에서 아래 명령어들을 실행합니다.\n",
    "> conda create -n {name} python=3.10 \\\n",
    "> conda init bash \\ \n",
    "> conda activate {name} \\\n",
    "> python main.py \\\n",
    "> pip install ipykernel \\\n",
    "> pip install requests \\\n",
    "> python -m ipykernel install --user --name {name} --display-name [ipykernel-name]\n",
    "\n",
    "- 해당 jupyter notebook 에서 생성된 ipykernel 을 선택 합니다.     \n",
    "\n",
    "<div style=\"margin: 40px\">\n",
    "<img src=\"./image/ipykernel.png\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# REST API 요청을 위해 필요한 모듈 import \n",
    "import os\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP-2**. AI Solution 이름 선택     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-2-1**. AI Conductor 의 URI 입력\n",
    "로그인 요청 및 시스템 담당에게 사용 가능한 URI 를 확인 합니다. \n",
    "- 고객지수플랫폼 Development \n",
    "> URI: \"https://aic-kic.aidxlge.com/\"\n",
    "- 담당서버 테스트 환경       \n",
    "> URI = \"http://10.158.2.243:9999/\"\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 사용자 입력 가변부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#----------------------------------------#\n",
    "#              사용자 입력                #\n",
    "#----------------------------------------#\n",
    "# 시스템 URI\n",
    "URI = \"http://10.158.2.243:9999/\"\n",
    "# workspace 이름 \n",
    "WORKSPACE_NAME = \"magna-ws\" # \"cism-ws\"\n",
    "# 로그인 정보 \n",
    "LOGIN_ID = 'magna-dev'\n",
    "LOGIN_PW = 'magna-dev@com'\n",
    "# Scope: public / private  \n",
    "ONLY_PUBLIC = 0 # 0: public으로 등록된 solution을 가져옴 / 1: magna-ws으로 등록된 solution을 가져옴\n",
    "URI_SCOPE = 'public' #'private' #'public'\n",
    "# ECR에 올라갈 컨테이너 URI TAG \n",
    "ECR_TAG = 'latest'\n",
    "#----------------------------------------#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> REST API 주소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REST API Endpoints\n",
    "BASE_URI = 'api/v1/'\n",
    "# 0. 로그인\n",
    "LOGIN = BASE_URI + 'auth/static/login' # POST\n",
    "# 1. 시스템 정보 획득\n",
    "SYSTEM_INFO = BASE_URI + 'workspaces' # GET\n",
    "# 2. AI Solution 이름 설정 / 3. AI Solution 등록\n",
    "AI_SOLUTION = BASE_URI + 'solutions' # 이름 설정 시 GET, 등록 시 POST\n",
    "# 4. AI Solution Instance 등록\n",
    "SOLUTION_INSTANCE = BASE_URI + 'instances' # POST\n",
    "# 5. Stream 등록\n",
    "STREAMS = BASE_URI + 'streams' # POST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 시스템 로그인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 로그인 결과:  {'result': 'OK'}\n",
      ">> cookie:  {'access-token': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJtYWduYS1kZXYiLCJleHAiOjE3MDE0MjE1NDh9.Av9lHkIeMW1f775QjOrlcVo_7Qp_PguKgSD5ZVB8JRw'}\n"
     ]
    }
   ],
   "source": [
    "# 로그인\n",
    "login_data = json.dumps({\n",
    "  \"login_id\": LOGIN_ID,\n",
    "  \"login_pw\": LOGIN_PW\n",
    "})\n",
    "login_response = requests.post(URI + LOGIN, data = login_data)\n",
    "cookies = login_response.cookies.get_dict()\n",
    "access_token = cookies.get('access-token', None)\n",
    "aic_cookie = {\n",
    "  'access-token' : access_token \n",
    "}\n",
    "print('>> 로그인 결과: ', login_response.json())\n",
    "print('>> cookie: ', aic_cookie)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AI Solution 이름 설정 (사용자 입력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"font-size: 20px;\"> AI Solution 이름을 입력해 주세요! </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size: 14px;\"><< 'ws-test-1' >> 는 AI Solution 이름으로 사용 가능합니다.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI Solution List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>solution-hyunsoo-cism-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>solution-test-ws-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sol-ws-test0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solution-woosung-test-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>solution-hyunsoo-magna-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>solution-woosung-test-231201-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>solution-woosung-test-final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>solution-hyunsoo-public-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>solution-woosung-231201-v0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AI Solution List\n",
       "0          solution-hyunsoo-cism-1\n",
       "1               solution-test-ws-0\n",
       "2                     sol-ws-test0\n",
       "3          solution-woosung-test-0\n",
       "4         solution-hyunsoo-magna-1\n",
       "5  solution-woosung-test-231201-v2\n",
       "6      solution-woosung-test-final\n",
       "7        solution-hyunsoo-public-1\n",
       "8       solution-woosung-231201-v0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AI Solution 이름 설정\n",
    "from IPython.display import HTML, display\n",
    "import pandas as pd \n",
    "\n",
    "solution_data = {\n",
    "    \"workspace_name\": WORKSPACE_NAME, \n",
    "    \"only_public\": ONLY_PUBLIC \n",
    "}\n",
    "solution_name = requests.get(URI + AI_SOLUTION, params=solution_data, cookies=aic_cookie)\n",
    "solution_list = []\n",
    "\n",
    "for sol in solution_name.json()['solutions']:\n",
    "    solution_list.append(sol['name'])\n",
    "    \n",
    "## soltuion 이름 입력 받기 \n",
    "display(HTML('<p style=\"font-size: 20px;\"> AI Solution 이름을 입력해 주세요! </p>'))\n",
    "user_input = input(\"AI Solutiuon 이름: \")\n",
    "\n",
    "# 기존 solution 존재하면 에러 나게 하기 \n",
    "if user_input in solution_list: \n",
    "    txt = \"이미 입력한 이름이 AI Solution으로 존재합니다. 고유한 이름을 입력해주세요.\"\n",
    "    raise ValueError(HTML(f'<p style=\"font-size: 20px;\">{txt}</p>'))\n",
    "else:\n",
    "    name = user_input ## 이름을 반영 합니다. \n",
    "    txt = f\"<< '{user_input}' >> 는 AI Solution 이름으로 사용 가능합니다.\" \n",
    "    display(HTML(f'<p style=\"font-size: 14px;\">{txt}</p>'))\n",
    "\n",
    "print(\"\\n\")\n",
    "df = pd.DataFrame(solution_list, columns=[\"AI Solution List\"])\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEE-2-2**. AI Solution Name 을 AI Conductor 에 등록합니다. \n",
    ": 이름이 등록되면 본 노트북 과정이 끝날 때까지 변경이 어려 울 수 있습니다. \\\n",
    "   변경이 필요할 경우 (2-1) 를 다시 실행하여 주시기 바랍니다. \n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 기존에 workspace에 존재하는 solution 이름을 조회하여, 사용자가 입력하는 이름이 유효한지 (고유한지) 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: green; font-size: 14px;\">[INFO] S3_BUCUKET_URI:\n",
       "   '{'public': 's3-an2-hyunsoo-dev-aia', 'private': 's3-an2-hyunsoo-dev-magna'}' </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: green; font-size: 14px;\">[INFO] ECR_URI:\n",
       "   '{'public': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/public/', 'private': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/magna/'}'</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/public/\n",
      ">> bucket name:  s3-an2-hyunsoo-dev-aia\n",
      "\n",
      ">> solution metadata 작성을 시작합니다. 현재 버전 v1 입니다.\n"
     ]
    }
   ],
   "source": [
    "from sm_control_v0_7 import SMC \n",
    "###################\n",
    "pipeline = 'train'\n",
    "###################\n",
    "## workspaces list 확인 \n",
    "workspaces = requests.get(URI + SYSTEM_INFO, cookies=aic_cookie)\n",
    "## workspace_name 의 ECR, S3 주소를 확인 합니다. \n",
    "for ws in workspaces.json():\n",
    "    if WORKSPACE_NAME in ws['name']:\n",
    "        S3_BUCKET_NAME = ws['s3_bucket_name']\n",
    "        ECR_NAME = ws['ecr_base_path']\n",
    "        TAG = 'latest'        \n",
    "        \n",
    "txt = f\"[INFO] S3_BUCUKET_URI:\\n   '{S3_BUCKET_NAME}' \"\n",
    "def print_styled(text, color='black', size='14px'):\n",
    "    \"\"\"\n",
    "    Jupyter Notebook에서 스타일이 적용된 텍스트를 출력합니다.\n",
    "    :param text: 출력할 텍스트\n",
    "    :param color: 텍스트의 색상 (기본값: 검은색)\n",
    "    :param size: 텍스트의 크기 (기본값: 14px)\n",
    "    \"\"\"\n",
    "    display(HTML(f'<p style=\"color: {color}; font-size: {size};\">{text}</p>'))    \n",
    "print_styled(txt, 'green')\n",
    "txt = f\"[INFO] ECR_URI:\\n   '{ECR_NAME}'\"\n",
    "print_styled(txt, 'green')\n",
    "\n",
    "# solution metadata 를 setup 합니다.\n",
    "SM_path = \"./solution_meta_raw.yaml\"\n",
    "sm = SMC(workspaces, URI_SCOPE, ECR_TAG, name, pipeline)\n",
    "sm.set_yaml()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-3**. Train 용 Sample Data 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> access check:  True\n",
      ">> my region:  ap-northeast-2\n",
      ">> Upload bucket + s3 path:  s3-an2-hyunsoo-dev-aia ai-solutions/ws-test-1/v1/train/data\n",
      ">> [Success Uploading] S3 ai-solutions/ws-test-1/v1/train/data/default_train/iris.csv\n"
     ]
    }
   ],
   "source": [
    "# s3 접근확인\n",
    "sm.s3_access_check()\n",
    "# s3 데이터 업로드\n",
    "# 이전에 이미 존재하던 데이터는 지워집니다.\n",
    "sm.s3_upload(pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-4**. Train Docker Container 제작"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ALO 작업 폴더를 현재 노트북 경로로 가져옵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ws.jang/alo_2.1/alo_2.1.1/alo/main.py\n",
      "/home/ws.jang/alo_2.1/alo_2.1.1/alo/src\n",
      "/home/ws.jang/alo_2.1/alo_2.1.1/alo/config\n",
      "/home/ws.jang/alo_2.1/alo_2.1.1/alo/assets\n",
      "/home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib\n",
      ">> Success ALO setting.\n"
     ]
    }
   ],
   "source": [
    "# ALO 작업 폴더 가져오기 \n",
    "sm.set_alo()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> DOCKERFILE을 셋팅합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Success DOCKERFILE setting.\n"
     ]
    }
   ],
   "source": [
    "# DOCKERFILE setting\n",
    "sm.set_docker_contatiner()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AWS ECR에 docker 등록을 위한 repository를 생성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> region:  ap-northeast-2\n",
      ">> ecr url:  086558720570.dkr.ecr.ap-northeast-2.amazonaws.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ws.jang/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "\n",
      ">> ecr repo:  ecr-repo-an2-hyunsoo-dev/ai-solution/public/ws-test-1/train/ws-test-1\n",
      "command:  ['aws', 'ecr', 'create-repository', '--region', 'ap-northeast-2', '--repository-name', 'ecr-repo-an2-hyunsoo-dev/ai-solution/public/ws-test-1/train/ws-test-1', '--image-scanning-configuration', 'scanOnPush=true']\n",
      "명령어 실행 결과: {\n",
      "    \"repository\": {\n",
      "        \"repositoryArn\": \"arn:aws:ecr:ap-northeast-2:086558720570:repository/ecr-repo-an2-hyunsoo-dev/ai-solution/public/ws-test-1/train/ws-test-1\",\n",
      "        \"registryId\": \"086558720570\",\n",
      "        \"repositoryName\": \"ecr-repo-an2-hyunsoo-dev/ai-solution/public/ws-test-1/train/ws-test-1\",\n",
      "        \"repositoryUri\": \"086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/ws-test-1/train/ws-test-1\",\n",
      "        \"createdAt\": 1701414396.0,\n",
      "        \"imageTagMutability\": \"MUTABLE\",\n",
      "        \"imageScanningConfiguration\": {\n",
      "            \"scanOnPush\": true\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ECR 등록\n",
    "## docker login 실행 \n",
    "sm.set_aws_ecr(docker=True)\n",
    "\n",
    "## buildah login 실행 (docker in docker) \n",
    "# tags = [\n",
    "#     \"Key=Company,Value=LGE\",\n",
    "#     \"Key=Owner,Value=IC360\",\n",
    "#     \"Key=HQ,Value=CDO\",\n",
    "#     \"Key=Division,Value=CDO\",\n",
    "#     \"Key=Infra Region,Value=KIC\",\n",
    "#     \"Key=Service Mode,Value=DE\",\n",
    "#     \"Key=Cost Type,Value=COMPUTING\",\n",
    "#     \"Key=Project,Value=CIS\",\n",
    "#     \"Key=Sub Project,Value=CISM\",\n",
    "#     \"Key=System,Value=AIDX\"\n",
    "# ]\n",
    "# sm.set_aws_ecr(docker=False, tags=tags) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Docker Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  3.878MB\n",
      "Step 1/12 : FROM public.ecr.aws/docker/library/python:3.10-slim-bullseye\n",
      " ---> f4856e227921\n",
      "Step 2/12 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> a0ed300f475c\n",
      "Step 3/12 : RUN apt-get install -y apt-utils\n",
      " ---> Using cache\n",
      " ---> 0d48e764839f\n",
      "Step 4/12 : RUN apt-get install -y --no-install-recommends          build-essential          wget          ca-certificates          git          gcc     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 9fbe37653d86\n",
      "Step 5/12 : ENV LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 4618e9c77332\n",
      "Step 6/12 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 9fc9e6aad13f\n",
      "Step 7/12 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 25e2b3770ca8\n",
      "Step 8/12 : ENV SOLUTION_PIPELINE_MODE='train'\n",
      " ---> Using cache\n",
      " ---> 717f09671e82\n",
      "Step 9/12 : ENV PATH=\"/framework:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> ceb6ef277cb8\n",
      "Step 10/12 : COPY /alo /framework\n",
      " ---> 7731f367d3ea\n",
      "Step 11/12 : WORKDIR /framework\n",
      " ---> Running in 8b32816d76e4\n",
      "Removing intermediate container 8b32816d76e4\n",
      " ---> 886fabdb95de\n",
      "Step 12/12 : CMD [\"python\", \"main.py\"]\n",
      " ---> Running in 4c5a9d51a723\n",
      "Removing intermediate container 4c5a9d51a723\n",
      " ---> 9622ad2de9bd\n",
      "Successfully built 9622ad2de9bd\n",
      "Successfully tagged 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/ws-test-1/train/ws-test-1:latest\n"
     ]
    }
   ],
   "source": [
    "# docker build \n",
    "# [TODO] TAG 관련 실험 및 코드 수정 필요 (지금은 latest)\n",
    "sm.build_docker()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ECR에 docker image를 push 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/ws-test-1/train/ws-test-1]\n",
      "308ab4b8d221: Preparing\n",
      "d537c430cce3: Preparing\n",
      "c8c3e6e9c7c7: Preparing\n",
      "35f25cd63c2c: Preparing\n",
      "2f33dd8c934e: Preparing\n",
      "6b3d0b913afc: Preparing\n",
      "277bd6c0df20: Preparing\n",
      "12d601beac88: Preparing\n",
      "1b6fd3ad4ce6: Preparing\n",
      "6b3d0b913afc: Waiting\n",
      "1b6fd3ad4ce6: Waiting\n",
      "277bd6c0df20: Waiting\n",
      "308ab4b8d221: Pushed\n",
      "c8c3e6e9c7c7: Pushed\n",
      "6b3d0b913afc: Pushed\n",
      "2f33dd8c934e: Pushed\n",
      "35f25cd63c2c: Pushed\n",
      "12d601beac88: Pushed\n",
      "277bd6c0df20: Pushed\n",
      "1b6fd3ad4ce6: Pushed\n",
      "d537c430cce3: Pushed\n",
      "latest: digest: sha256:7cea3e61c3f828c8699fe4b238aa08a5bec9affebf81ba25e9a6431fff08e29b size: 2214\n",
      "Removing login credentials for https://index.docker.io/v1/\n"
     ]
    }
   ],
   "source": [
    "sm.docker_push()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> solution_metadata.yaml에 container uri를 넣어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "container uri is 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/ws-test-1/train/ws-test-1\n"
     ]
    }
   ],
   "source": [
    "sm.set_container_uri(pipeline) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-5**. Training 에 사용될 User Parameters 설정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> solution_metadata.yaml에 사용자 파라미터 및 artifacts 저장 경로를 넣어줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_parameters were stored\n",
      "s3://s3-an2-hyunsoo-dev-aia/artifact/ws-test-1/train/artifacts/ were stored\n"
     ]
    }
   ],
   "source": [
    "## user parameter 입력\n",
    "sm.set_cadidate_param(pipeline)\n",
    "## artifact 저장 경로 지정\n",
    "sm.set_artifacts_uri(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-6**. Training 에 사용될 Cloud resource 선택"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 컴퓨팅 자원을 선택합니다. (default: standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloud resource was standard\n"
     ]
    }
   ],
   "source": [
    "# 컴퓨팅 리소스 선택 \n",
    "sm.set_resource(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-7**. Inference 용 Sample Data 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Upload bucket + s3 path:  s3-an2-hyunsoo-dev-aia solution/sol-ws-test0/inference/data\n",
      ">> [Success Uploading] S3 solution/sol-ws-test0/inference/data/default_inference/iris.csv\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "pipeline = \"inference\"\n",
    "###################\n",
    "# s3 데이터 업로드\n",
    "# 이전에 있던 데이터는 지워집니다\n",
    "sm.s3_upload(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-8**. Inference 용 Docker Container 제작"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> DOCKERFILE을 셋팅합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Success DOCKERFILE setting.\n"
     ]
    }
   ],
   "source": [
    "# DOCKERFILE setting\n",
    "sm.set_docker_contatiner()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AWS ECR에 docker 등록을 위한 repository를 생성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> region:  ap-northeast-2\n",
      ">> ecr url:  086558720570.dkr.ecr.ap-northeast-2.amazonaws.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ws.jang/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "\n",
      ">> ecr repo:  ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/inference/sol-ws-test0\n",
      "command:  ['aws', 'ecr', 'create-repository', '--region', 'ap-northeast-2', '--repository-name', 'ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/inference/sol-ws-test0', '--image-scanning-configuration', 'scanOnPush=true']\n",
      "명령어 실행 결과: {\n",
      "    \"repository\": {\n",
      "        \"repositoryArn\": \"arn:aws:ecr:ap-northeast-2:086558720570:repository/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/inference/sol-ws-test0\",\n",
      "        \"registryId\": \"086558720570\",\n",
      "        \"repositoryName\": \"ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/inference/sol-ws-test0\",\n",
      "        \"repositoryUri\": \"086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/inference/sol-ws-test0\",\n",
      "        \"createdAt\": 1701410431.0,\n",
      "        \"imageTagMutability\": \"MUTABLE\",\n",
      "        \"imageScanningConfiguration\": {\n",
      "            \"scanOnPush\": true\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ECR 등록\n",
    "## docker login 실행 \n",
    "sm.set_aws_ecr(docker=True)\n",
    "\n",
    "## buildah login 실행 (docker in docker) \n",
    "# tags = [\n",
    "#     \"Key=Company,Value=LGE\",\n",
    "#     \"Key=Owner,Value=IC360\",\n",
    "#     \"Key=HQ,Value=CDO\",\n",
    "#     \"Key=Division,Value=CDO\",\n",
    "#     \"Key=Infra Region,Value=KIC\",\n",
    "#     \"Key=Service Mode,Value=DE\",\n",
    "#     \"Key=Cost Type,Value=COMPUTING\",\n",
    "#     \"Key=Project,Value=CIS\",\n",
    "#     \"Key=Sub Project,Value=CISM\",\n",
    "#     \"Key=System,Value=AIDX\"\n",
    "# ]\n",
    "# sm.set_aws_ecr(docker=False, tags=tags) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Build docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon    2.2MB\n",
      "Step 1/12 : FROM public.ecr.aws/docker/library/python:3.10-slim-bullseye\n",
      " ---> f4856e227921\n",
      "Step 2/12 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> a0ed300f475c\n",
      "Step 3/12 : RUN apt-get install -y apt-utils\n",
      " ---> Using cache\n",
      " ---> 0d48e764839f\n",
      "Step 4/12 : RUN apt-get install -y --no-install-recommends          build-essential          wget          ca-certificates          git          gcc     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 9fbe37653d86\n",
      "Step 5/12 : ENV LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 4618e9c77332\n",
      "Step 6/12 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 9fc9e6aad13f\n",
      "Step 7/12 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 25e2b3770ca8\n",
      "Step 8/12 : ENV SOLUTION_PIPELINE_MODE='inference'\n",
      " ---> Using cache\n",
      " ---> 697a6e734a5b\n",
      "Step 9/12 : ENV PATH=\"/framework:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 6b36771d5ea1\n",
      "Step 10/12 : COPY /alo /framework\n",
      " ---> b2f890ebf7b5\n",
      "Step 11/12 : WORKDIR /framework\n",
      " ---> Running in 5d62bf515e93\n",
      "Removing intermediate container 5d62bf515e93\n",
      " ---> 06d60175fc85\n",
      "Step 12/12 : CMD [\"python\", \"main.py\"]\n",
      " ---> Running in 15f96b7ae105\n",
      "Removing intermediate container 15f96b7ae105\n",
      " ---> baa8a990d54f\n",
      "Successfully built baa8a990d54f\n",
      "Successfully tagged 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/inference/sol-ws-test0:latest\n"
     ]
    }
   ],
   "source": [
    "# docker build \n",
    "sm.build_docker()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AWS ECR에 docker 이미지를 push 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/inference/sol-ws-test0]\n",
      "e3a6974e8a21: Preparing\n",
      "d537c430cce3: Preparing\n",
      "c8c3e6e9c7c7: Preparing\n",
      "35f25cd63c2c: Preparing\n",
      "2f33dd8c934e: Preparing\n",
      "6b3d0b913afc: Preparing\n",
      "277bd6c0df20: Preparing\n",
      "12d601beac88: Preparing\n",
      "1b6fd3ad4ce6: Preparing\n",
      "6b3d0b913afc: Waiting\n",
      "277bd6c0df20: Waiting\n",
      "12d601beac88: Waiting\n",
      "1b6fd3ad4ce6: Waiting\n",
      "e3a6974e8a21: Pushed\n",
      "c8c3e6e9c7c7: Pushed\n",
      "6b3d0b913afc: Pushed\n",
      "35f25cd63c2c: Pushed\n",
      "12d601beac88: Pushed\n",
      "2f33dd8c934e: Pushed\n",
      "277bd6c0df20: Pushed\n",
      "1b6fd3ad4ce6: Pushed\n",
      "d537c430cce3: Pushed\n",
      "latest: digest: sha256:a9956c21224e0e861bc6a75d3010847b82873b2f641be70172c2e1170b19096d size: 2214\n",
      "Removing login credentials for https://index.docker.io/v1/\n"
     ]
    }
   ],
   "source": [
    "sm.docker_push()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> solution_metadata.yaml에 container uri를 넣어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "container uri is 086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/inference/sol-ws-test0\n"
     ]
    }
   ],
   "source": [
    "sm.set_container_uri(pipeline) # uri도 그냥 입력되게 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-9**. Inference 용 User Parameters 제작"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> solution_metadata.yaml에 사용자 파라미터, artifacts 경로, model 경로 등을 넣어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_parameters were stored\n",
      "s3://s3-an2-hyunsoo-dev-aia/artifact/sol-ws-test0/inference/artifacts/ were stored\n",
      "s3://s3-an2-hyunsoo-dev-aia/artifact/sol-ws-test0/inference/artifacts/ were stored\n"
     ]
    }
   ],
   "source": [
    "sm.set_cadidate_param(pipeline)\n",
    "sm.set_artifacts_uri(pipeline)\n",
    "sm.set_model_uri(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-10**. Inference 용 Resource 선택"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 컴퓨팅 자원을 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloud resource was standard\n"
     ]
    }
   ],
   "source": [
    "sm.set_resource(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-11**. Description 추가"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> solution_metadata.yaml에 description을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution metadata description이 작성되었습니다\n"
     ]
    }
   ],
   "source": [
    "sm.set_sm_description(name, \"AI Advisor Test\", f\"without bucket url\", f\"without bucket url\", \"params\", \"alo\", \"s3://icon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP-12**. AI Solution 등록 !!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AI Solution 등록을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '2412f92f-4f81-435e-8c5e-d8ae1e37cd98',\n",
       " 'name': 'sol-ws-test0',\n",
       " 'scope_ws': 'public',\n",
       " 'version': {'id': 'fdc53fe2-029b-4905-a374-66f79647b5e1',\n",
       "  'version': 1,\n",
       "  'train_container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/train/sol-ws-test0',\n",
       "  'train_container_tag': 'latest',\n",
       "  'inference_container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/inference/sol-ws-test0',\n",
       "  'inference_container_tag': 'latest',\n",
       "  'metadata_dict': {'version': 1,\n",
       "   'name': 'sol-ws-test0',\n",
       "   'description': {'title': 'sol-ws-test0',\n",
       "    'overview': 'AI Advisor Test',\n",
       "    'input_data': 's3-an2-hyunsoo-dev-aiawithout bucket url',\n",
       "    'output_data': 's3-an2-hyunsoo-dev-aiawithout bucket url',\n",
       "    'user_parameters': 'params',\n",
       "    'algorithm': 'alo',\n",
       "    'icon': 's3://icon'},\n",
       "   'pipeline': [{'type': 'train',\n",
       "     'dataset_uri': ['s3://s3-an2-hyunsoo-dev-aia/ai-solutions/sol-ws-test0/v1/train/data/'],\n",
       "     'container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/train/sol-ws-test0',\n",
       "     'parameters': {'candidate_parameters': [{'args': [{'concat_dataframes': True,\n",
       "          'drop_columns': None,\n",
       "          'encoding': None,\n",
       "          'groupkey_columns': None,\n",
       "          'input_path': 'default_train',\n",
       "          'time_column': None,\n",
       "          'use_all_x': False,\n",
       "          'x_columns': ['input_x0', 'input_x1', 'input_x2', 'input_x3'],\n",
       "          'y_column': 'target'}],\n",
       "        'step': 'input'},\n",
       "       {'args': [{'custom': {}, 'mode': 'auto'}], 'step': 'preprocess'},\n",
       "       {'args': [{'ignore_label_class': None,\n",
       "          'label_sampling': False,\n",
       "          'label_sampling_num': None,\n",
       "          'label_sampling_num_type': None,\n",
       "          'negative_target_class': None,\n",
       "          'sampling_groupkey_columns': None,\n",
       "          'sampling_method': 'random',\n",
       "          'sampling_num': 0.8,\n",
       "          'sampling_num_type': 'ratio',\n",
       "          'sampling_type': 'none'}],\n",
       "        'step': 'sampling'},\n",
       "       {'args': [{'data_split_method': 'cross_validate',\n",
       "          'evaluation_metric': 'accuracy',\n",
       "          'model_list': ['lgb', 'rf', 'cb'],\n",
       "          'model_type': 'classification',\n",
       "          'num_hpo': 3,\n",
       "          'param_range': {'cb': {'max_depth': [5, 9],\n",
       "            'n_estimators': [100, 500]},\n",
       "           'gbm': {'max_depth': [5, 7], 'n_estimators': [300, 500]},\n",
       "           'lgb': {'max_depth': [5, 9], 'n_estimators': [300, 500]},\n",
       "           'ngb': {'col_sample': [0.6, 0.8], 'n_estimators': [100, 300]},\n",
       "           'rf': {'max_depth': 6, 'n_estimators': [300, 500]}},\n",
       "          'shap_ratio': 1.0}],\n",
       "        'step': 'train'}],\n",
       "      'user_parameters': [{'step': 'input', 'args': []},\n",
       "       {'step': 'preprocess', 'args': []},\n",
       "       {'step': 'sampling', 'args': []},\n",
       "       {'step': 'train', 'args': []}],\n",
       "      'selected_user_parameters': [{'step': 'input', 'args': []},\n",
       "       {'step': 'preprocess', 'args': []},\n",
       "       {'step': 'sampling', 'args': []},\n",
       "       {'step': 'train', 'args': []}]},\n",
       "     'artifact_uri': 's3://s3-an2-hyunsoo-dev-aia/artifact/sol-ws-test0/train/artifacts/',\n",
       "     'resource': {'default': 'standard'}},\n",
       "    {'type': 'inference',\n",
       "     'artifact_uri': 's3://s3-an2-hyunsoo-dev-aia/artifact/sol-ws-test0/inference/artifacts/',\n",
       "     'dataset_uri': ['s3://s3-an2-hyunsoo-dev-aia/solution/sol-ws-test0/inference/data/'],\n",
       "     'container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/inference/sol-ws-test0',\n",
       "     'parameters': {'candidate_parameters': [{'args': [{'concat_dataframes': True,\n",
       "          'drop_columns': None,\n",
       "          'encoding': None,\n",
       "          'groupkey_columns': None,\n",
       "          'input_path': 'default_inference',\n",
       "          'time_column': None,\n",
       "          'use_all_x': False,\n",
       "          'x_columns': ['input_x0', 'input_x1', 'input_x2', 'input_x3'],\n",
       "          'y_column': None}],\n",
       "        'step': 'input'},\n",
       "       {'args': [{'custom': {}, 'mode': 'auto'}], 'step': 'preprocess'},\n",
       "       {'args': [{'model_type': 'classification', 'run_shapley': True}],\n",
       "        'step': 'inference'}],\n",
       "      'user_parameters': [{'step': 'input', 'args': []},\n",
       "       {'step': 'preprocess', 'args': []},\n",
       "       {'step': 'inference', 'args': []}],\n",
       "      'selected_user_parameters': [{'step': 'input', 'args': []},\n",
       "       {'step': 'preprocess', 'args': []},\n",
       "       {'step': 'inference', 'args': []}]},\n",
       "     'model_uri': 's3://s3-an2-hyunsoo-dev-aia/artifact/sol-ws-test0/inference/artifacts/',\n",
       "     'resource': {'default': 'standard'}}],\n",
       "   'wrangler_code_uri': '',\n",
       "   'wrangler_dataset_uri': '',\n",
       "   'edgeconductor_interface': {'support_labeling': True,\n",
       "    'inference_result_datatype': 'image',\n",
       "    'train_datatype': 'table'},\n",
       "   'edgeapp_interface': {'redis_server_uri': ''}},\n",
       "  'created_at': '2023-12-01 06:01:14'},\n",
       " 'is_deleted': 0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [임시] 변경 예정\n",
    "sm.set_wrangler()\n",
    "sm.set_edge()\n",
    "\n",
    "# 등록을 위한 형태 변경\n",
    "data = {\n",
    "  \"scope_ws\": URI_SCOPE,\n",
    "  \"metadata_json\": sm.sm_yaml\n",
    "}\n",
    "data =json.dumps(data)\n",
    "solution_params = {\n",
    "    \"workspace_name\": WORKSPACE_NAME\n",
    "}\n",
    "\n",
    "# AI 솔루션 등록\n",
    "post_response = requests.post(URI + AI_SOLUTION, params=solution_params, data=data, cookies=aic_cookie)\n",
    "post_response_json = post_response.json()\n",
    "post_response_json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Solution instance 등록을 위한 interface 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sol-ws-test0',\n",
       " 'solution_version_id': 'fdc53fe2-029b-4905-a374-66f79647b5e1',\n",
       " 'workspace_name': 'magna-ws'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_id = post_response_json['version']['id']\n",
    "save_json = {\"server_uri\" : URI,\n",
    "    \"name\" : name,\n",
    "    \"version_id\": solution_id,\n",
    "    \"workspace_name\": WORKSPACE_NAME}\n",
    "\n",
    "import shutil\n",
    "interface_dir = './interface'\n",
    "try:\n",
    "    # 폴더가 이미 존재하는 경우 삭제합니다.\n",
    "    if os.path.exists(interface_dir):\n",
    "        shutil.rmtree(interface_dir)\n",
    "    # 새로운 폴더를 생성합니다.\n",
    "    os.mkdir(interface_dir)\n",
    "except Exception as e:\n",
    "    print(f\"폴더 생성 중 오류 발생: {e}\")\n",
    "\n",
    "with open(interface_dir + \"/ai_soluition_certification.json\", 'w') as outfile:\n",
    "    json.dump(save_json, outfile)\n",
    "\n",
    "with open(\"./interface/ai_soluition_certification.json\", 'r') as outfile:\n",
    "    interface = json.load(outfile)\n",
    "    \n",
    "params = {\"name\":interface['name'],\n",
    "\"solution_version_id\":interface['version_id'],\n",
    "\"workspace_name\":interface['workspace_name']\n",
    "}\n",
    "params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Solution instance 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '29a34bd6-1927-4682-8b3d-e5847873a94b',\n",
       " 'name': 'sol-ws-test0',\n",
       " 'workspace_id': 'a0da0a72-3ce4-43e4-b510-b875896dcb35',\n",
       " 'workspace_name': 'magna-ws',\n",
       " 'solution_version_id': 'fdc53fe2-029b-4905-a374-66f79647b5e1',\n",
       " 'solution_version': 1,\n",
       " 'metadata_dict': {'version': 1,\n",
       "  'name': 'sol-ws-test0',\n",
       "  'description': {'title': 'sol-ws-test0',\n",
       "   'overview': 'AI Advisor Test',\n",
       "   'input_data': 's3-an2-hyunsoo-dev-aiawithout bucket url',\n",
       "   'output_data': 's3-an2-hyunsoo-dev-aiawithout bucket url',\n",
       "   'user_parameters': 'params',\n",
       "   'algorithm': 'alo',\n",
       "   'icon': 's3://icon'},\n",
       "  'pipeline': [{'type': 'train',\n",
       "    'dataset_uri': ['s3://s3-an2-hyunsoo-dev-aia/ai-solutions/sol-ws-test0/v1/train/data/'],\n",
       "    'container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/train/sol-ws-test0',\n",
       "    'parameters': {'candidate_parameters': [{'args': [{'concat_dataframes': True,\n",
       "         'drop_columns': None,\n",
       "         'encoding': None,\n",
       "         'groupkey_columns': None,\n",
       "         'input_path': 'default_train',\n",
       "         'time_column': None,\n",
       "         'use_all_x': False,\n",
       "         'x_columns': ['input_x0', 'input_x1', 'input_x2', 'input_x3'],\n",
       "         'y_column': 'target'}],\n",
       "       'step': 'input'},\n",
       "      {'args': [{'custom': {}, 'mode': 'auto'}], 'step': 'preprocess'},\n",
       "      {'args': [{'ignore_label_class': None,\n",
       "         'label_sampling': False,\n",
       "         'label_sampling_num': None,\n",
       "         'label_sampling_num_type': None,\n",
       "         'negative_target_class': None,\n",
       "         'sampling_groupkey_columns': None,\n",
       "         'sampling_method': 'random',\n",
       "         'sampling_num': 0.8,\n",
       "         'sampling_num_type': 'ratio',\n",
       "         'sampling_type': 'none'}],\n",
       "       'step': 'sampling'},\n",
       "      {'args': [{'data_split_method': 'cross_validate',\n",
       "         'evaluation_metric': 'accuracy',\n",
       "         'model_list': ['lgb', 'rf', 'cb'],\n",
       "         'model_type': 'classification',\n",
       "         'num_hpo': 3,\n",
       "         'param_range': {'cb': {'max_depth': [5, 9],\n",
       "           'n_estimators': [100, 500]},\n",
       "          'gbm': {'max_depth': [5, 7], 'n_estimators': [300, 500]},\n",
       "          'lgb': {'max_depth': [5, 9], 'n_estimators': [300, 500]},\n",
       "          'ngb': {'col_sample': [0.6, 0.8], 'n_estimators': [100, 300]},\n",
       "          'rf': {'max_depth': 6, 'n_estimators': [300, 500]}},\n",
       "         'shap_ratio': 1.0}],\n",
       "       'step': 'train'}],\n",
       "     'user_parameters': [{'step': 'input', 'args': []},\n",
       "      {'step': 'preprocess', 'args': []},\n",
       "      {'step': 'sampling', 'args': []},\n",
       "      {'step': 'train', 'args': []}],\n",
       "     'selected_user_parameters': [{'step': 'input', 'args': []},\n",
       "      {'step': 'preprocess', 'args': []},\n",
       "      {'step': 'sampling', 'args': []},\n",
       "      {'step': 'train', 'args': []}]},\n",
       "    'artifact_uri': 's3://s3-an2-hyunsoo-dev-aia/artifact/sol-ws-test0/train/artifacts/',\n",
       "    'resource': {'default': 'standard'}},\n",
       "   {'type': 'inference',\n",
       "    'artifact_uri': 's3://s3-an2-hyunsoo-dev-aia/artifact/sol-ws-test0/inference/artifacts/',\n",
       "    'dataset_uri': ['s3://s3-an2-hyunsoo-dev-aia/solution/sol-ws-test0/inference/data/'],\n",
       "    'container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/inference/sol-ws-test0',\n",
       "    'parameters': {'candidate_parameters': [{'args': [{'concat_dataframes': True,\n",
       "         'drop_columns': None,\n",
       "         'encoding': None,\n",
       "         'groupkey_columns': None,\n",
       "         'input_path': 'default_inference',\n",
       "         'time_column': None,\n",
       "         'use_all_x': False,\n",
       "         'x_columns': ['input_x0', 'input_x1', 'input_x2', 'input_x3'],\n",
       "         'y_column': None}],\n",
       "       'step': 'input'},\n",
       "      {'args': [{'custom': {}, 'mode': 'auto'}], 'step': 'preprocess'},\n",
       "      {'args': [{'model_type': 'classification', 'run_shapley': True}],\n",
       "       'step': 'inference'}],\n",
       "     'user_parameters': [{'step': 'input', 'args': []},\n",
       "      {'step': 'preprocess', 'args': []},\n",
       "      {'step': 'inference', 'args': []}],\n",
       "     'selected_user_parameters': [{'step': 'input', 'args': []},\n",
       "      {'step': 'preprocess', 'args': []},\n",
       "      {'step': 'inference', 'args': []}]},\n",
       "    'model_uri': 's3://s3-an2-hyunsoo-dev-aia/artifact/sol-ws-test0/inference/artifacts/',\n",
       "    'resource': {'default': 'standard'}}],\n",
       "  'wrangler_code_uri': '',\n",
       "  'wrangler_dataset_uri': '',\n",
       "  'edgeconductor_interface': {'support_labeling': True,\n",
       "   'inference_result_datatype': 'image',\n",
       "   'train_datatype': 'table'},\n",
       "  'edgeapp_interface': {'redis_server_uri': ''}},\n",
       " 'train_container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/train/sol-ws-test0',\n",
       " 'train_container_tag': 'latest',\n",
       " 'inference_container_uri': '086558720570.dkr.ecr.ap-northeast-2.amazonaws.com/ecr-repo-an2-hyunsoo-dev/ai-solution/public/sol-ws-test0/inference/sol-ws-test0',\n",
       " 'inference_container_tag': 'latest',\n",
       " 'is_deleted': 0,\n",
       " 'created_at': '2023-12-01 06:01:25'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution instance 등록\n",
    "solution_instance = requests.post(interface['server_uri'] + SOLUTION_INSTANCE, params=params, cookies=aic_cookie)\n",
    "solution_instance.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Stream 등록 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'f7c3e9b2-769d-4101-aa5f-d91b7252697a',\n",
       " 'name': 'sol-ws-test0',\n",
       " 'instance_id': '29a34bd6-1927-4682-8b3d-e5847873a94b',\n",
       " 'train_dataset_uri': 's3://s3-an2-hyunsoo-dev-magna/instances/sol-ws-test0/sol-ws-test0/train/data/',\n",
       " 'workspace_name': 'magna-ws',\n",
       " 'is_deleted': 0,\n",
       " 'created_at': '2023-12-01 06:01:27'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stream 등록 \n",
    "solution_instance_json = solution_instance.json()\n",
    "instance_params = {\n",
    "    \"name\": solution_instance_json['name'],\n",
    "    \"instance_id\": solution_instance_json['id'],\n",
    "    \"workspace_name\": solution_instance_json['workspace_name']\n",
    "}\n",
    "stream = requests.post(interface['server_uri'] + STREAMS, params=instance_params, cookies=aic_cookie)\n",
    "stream.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> pipeline run 요청 (train, inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ac581afa-7f9d-4470-aba4-31c905578b4c',\n",
       " 'name': 'sol-ws-test0-20231201060151',\n",
       " 'workspace_name': 'magna-ws',\n",
       " 'stream_id': 'f7c3e9b2-769d-4101-aa5f-d91b7252697a',\n",
       " 'train_pipeline_id': '32778b6d-bb11-45e8-980e-68252fd726df',\n",
       " 'status': 'running',\n",
       " 'train_dataset_uri': ['s3://s3-an2-hyunsoo-dev-aia/ai-solutions/sol-ws-test0/v1/train/data/'],\n",
       " 'train_artifact_uri': 's3://s3-an2-hyunsoo-dev-magna/instances/sol-ws-test0/f7c3e9b2-769d-4101-aa5f-d91b7252697a/train/artifacts/2023/12/01/060151.390/',\n",
       " 'model_version': '0',\n",
       " 'is_deleted': 0,\n",
       " 'created_at': '2023-12-01 06:01:51',\n",
       " 'updated_at': '2023-12-01 06:01:51'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train pipeline 요청\n",
    "# solution_metadata.yaml을 읽어서 metadata_json에 넣기\n",
    "# [?] config path? \n",
    "import yaml\n",
    "# solution_metadata.yaml 읽어오기 \n",
    "# YAML 파일 경로\n",
    "yaml_file_path = './solution_metadata.yaml'\n",
    "# YAML 파일을 읽어서 parsing\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    yaml_data = yaml.safe_load(file)\n",
    "data = {\n",
    "  \"metadata_json\": yaml_data,\n",
    "  \"config_path\": \"\"\n",
    "}\n",
    "data =json.dumps(data)\n",
    "\n",
    "# stream 등록 \n",
    "stream_json = stream.json()\n",
    "stream_id = stream_json['id']\n",
    "workspace_name = stream_json['workspace_name']\n",
    "stream_params = {\n",
    "  \"stream_id\": stream_id,\n",
    "  \"workspace_name\": stream_json['workspace_name']\n",
    "}\n",
    "\n",
    "stream_history = requests.post(interface['server_uri'] + f\"{STREAMS}/{stream_id}/start\", params=stream_params, data=data, cookies=aic_cookie)\n",
    "stream_history.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> pipeline status 조회 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Succeeded'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [?] 계속 running 상태여서 artifacts 안생기는 듯 \n",
    "# Train pipeline 확인\n",
    "stream_history_json = stream_history.json()\n",
    "stream_history_parmas = {\n",
    "    \"stream_history_id\": stream_history_json ['id'],\n",
    "    \"workspace_name\": stream_history_json['workspace_name']\n",
    "}\n",
    "\n",
    "info = requests.get(interface['server_uri'] + f\"{STREAMS}/{stream_history_json['id']}/info\", params=stream_history_parmas, cookies=aic_cookie)\n",
    "info.json()['status']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 학습 완료된 artifacts download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: model.tar.gz\n",
      "Downloaded: train_artifacts.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "def split_s3_path(s3_path):\n",
    "    # 's3://'를 제거하고 '/'를 기준으로 첫 부분을 분리하여 bucket과 나머지 경로를 얻습니다.\n",
    "    path_parts = s3_path.replace('s3://', '').split('/', 1)\n",
    "    bucket = path_parts[0]\n",
    "    rest_of_the_path = path_parts[1]\n",
    "    return bucket, rest_of_the_path\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3_bucket = split_s3_path(stream_history_json['train_artifact_uri'])[0]\n",
    "s3_prefix = split_s3_path(stream_history_json['train_artifact_uri'])[1]\n",
    "\n",
    "# S3 버킷에서 파일 목록 가져오기\n",
    "objects = s3.list_objects(Bucket=s3_bucket, Prefix=s3_prefix)\n",
    "\n",
    "# 파일 다운로드\n",
    "for obj in objects.get('Contents', []):\n",
    "    key = obj['Key']\n",
    "    filename = key.split('/')[-1]  # 파일 이름 추출\n",
    "    s3.download_file(s3_bucket, key, filename)\n",
    "    print(f'Downloaded: {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".train_artifacts/log/process.log\n",
      ".train_artifacts/log/pipeline.log\n",
      ".train_artifacts/output/train/result_train_with_shapley.csv\n",
      ".train_artifacts/models/preprocess/train_pipeline.pkl\n",
      ".train_artifacts/models/preprocess/train_config.json\n",
      ".train_artifacts/models/train/params.json\n",
      ".train_artifacts/models/train/model_selection.json\n",
      ".train_artifacts/models/train/best_model_top0.pkl\n",
      ".train_artifacts/models/train/best_model_top1.pkl\n",
      ".train_artifacts/models/train/best_model_top2.pkl\n",
      ".train_artifacts/models/train/summary_plot.png\n",
      ".train_artifacts/models/train/output.csv\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf ./train_artifacts.tar.gz\n",
    "!cp -r .train_artifacts/ ../../ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alolib already exists in local path.\n",
      "패키지 설치 성공\n",
      "Requirement already satisfied: gitpython==3.1.37 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from -r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 1)) (3.1.37)\n",
      "Requirement already satisfied: pyyaml==6.0.1 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from -r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: pytz==2021.3 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from -r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 3)) (2021.3)\n",
      "Requirement already satisfied: boto3==1.20.0 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from -r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 4)) (1.20.0)\n",
      "Requirement already satisfied: botocore==1.23.0 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from -r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 5)) (1.23.0)\n",
      "Requirement already satisfied: psutil==5.9.5 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from -r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 6)) (5.9.5)\n",
      "Requirement already satisfied: requests==2.31.0 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from -r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 7)) (2.31.0)\n",
      "Requirement already satisfied: redis==5.0.1 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from -r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 8)) (5.0.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from gitpython==3.1.37->-r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 1)) (4.0.11)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from boto3==1.20.0->-r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from boto3==1.20.0->-r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 4)) (0.5.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from botocore==1.23.0->-r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from botocore==1.23.0->-r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 5)) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from requests==2.31.0->-r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 7)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from requests==2.31.0->-r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 7)) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from requests==2.31.0->-r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 7)) (2023.11.17)\n",
      "Requirement already satisfied: async-timeout>=4.0.2 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from redis==5.0.1->-r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 8)) (4.0.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython==3.1.37->-r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 1)) (5.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ws.jang/miniforge3/envs/aic_test/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.23.0->-r /home/ws.jang/alo_2.1/alo_2.1.1/alo/alolib/requirements.txt (line 5)) (1.16.0)\n",
      "\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,524]: Process start-time: 231201_150752\n",
      "[\u001b[1;32mINFO\u001b[0m][META][2023-12-01 15:07:52,524]: ALO version = develop\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,525]: ==================== Start ALO preset ==================== \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,526]: Successfully loaded << experimental_plan.yaml >> from: \n",
      " /home/ws.jang/alo_2.1/alo_2.1.1/alo/config/experimental_plan.yaml\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,549]: Success versioning up experimental_plan.yaml : 2.0 --> 2.1 (version ref. : compare yaml version)\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,549]: ==================== Finish ALO preset ==================== \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,550]: Successfully emptied << /home/ws.jang/alo_2.1/alo_2.1.1/alo/.inference_artifacts/output >> \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,551]: Successfully emptied << /home/ws.jang/alo_2.1/alo_2.1.1/alo/.inference_artifacts/score >> \n",
      "[\u001b[33;21mWARNING\u001b[0m][PROCESS][2023-12-01 15:07:52,552]: You did not write any << s3_private_key_file >> in the config yaml file. When you wanna get data from s3 storage, \n",
      "                                 you have to write the s3_private_key_file path or set << AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY >> in your os environment. \n",
      "\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,553]: Skip loading external data. All the data in the external load data path already exist in << /home/ws.jang/alo_2.1/alo_2.1.1/alo/input/ >> equally. \n",
      " : << external_base_dirs >>\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,553]: Start setting-up << input >> asset @ << assets >> directory.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,554]: << input >> asset had already been created at 2023-11-30 09:31:34.755786\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,555]: Start setting-up << preprocess >> asset @ << assets >> directory.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,556]: Now << local >> asset_source_code mode: <preprocess> asset exists.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,556]: Start setting-up << inference >> asset @ << assets >> directory.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,557]: << inference >> asset had already been created at 2023-11-30 09:31:48.471694\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,558]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,559]: >>> Ignored installing << numpy==1.25.2 >>. Another version would be installed in the previous step.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,559]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,560]: >>> Ignored installing << scikit-learn >>. Another version would be installed in the previous step.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,561]: ======================================== Start dependency installation : << input >> \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,562]: Start checking existence & installing package - pandas==1.5.3 | Progress: ( 1 / 11 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,563]: [OK] << pandas==1.5.3 >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,564]: ======================================== Start dependency installation : << preprocess >> \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,565]: Start checking existence & installing package - numpy==1.25.2 | Progress: ( 2 / 11 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,566]: [OK] << numpy==1.25.2 >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,566]: Start checking existence & installing package - scikit-learn | Progress: ( 3 / 11 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,567]: [OK] << scikit-learn >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,568]: ======================================== Start dependency installation : << inference >> \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,569]: Start checking existence & installing package - matplotlib | Progress: ( 4 / 11 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,569]: [OK] << matplotlib >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,570]: Start checking existence & installing package - seaborn | Progress: ( 5 / 11 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,571]: [OK] << seaborn >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,572]: Start checking existence & installing package - shap | Progress: ( 6 / 11 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,572]: [OK] << shap >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,573]: Start checking existence & installing package - lightgbm | Progress: ( 7 / 11 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,574]: [OK] << lightgbm >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,575]: Start checking existence & installing package - catboost | Progress: ( 8 / 11 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,575]: [OK] << catboost >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,576]: Start checking existence & installing package - ngboost | Progress: ( 9 / 11 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,577]: [OK] << ngboost >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,578]: Start checking existence & installing package - numba==0.58.0 | Progress: ( 10 / 11 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,579]: [OK] << numba==0.58.0 >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,579]: Start checking existence & installing package - missingno | Progress: ( 11 / 11 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,580]: [OK] << missingno >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,581]: ======================================== Start dependency installation : << force-reinstall >> \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,582]: ======================================== Finish dependency installation \n",
      "\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,582]: ==================== Start pipeline: inference_pipeline / step: input\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:52,836][inference_pipeline][input]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET START ===========================================================\n",
      "- time (UTC)        : 2023-12-01 06:07:52\n",
      "- current step      : input\n",
      "- asset branch.     : tabular_dev\n",
      "- alolib ver.       : 2.1.2\n",
      "- alo ver.          : develop\n",
      "- load envs. keys   : dict_keys(['project_home', 'solution_metadata_version', 'artifacts', 'alo_version', 'interface_mode', 'proc_start_time', 'save_train_artifacts_path', 'save_inference_artifacts_path', 'pipeline', 'step', 'num_step', 'asset_branch', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path'])\n",
      "- load args. keys   : dict_keys(['concat_dataframes', 'drop_columns', 'encoding', 'groupkey_columns', 'input_path', 'time_column', 'use_all_x', 'x_columns', 'y_column'])\n",
      "- load config. keys : dict_keys(['meta'])\n",
      "- load data keys    : dict_keys([])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:52,837][inference_pipeline][input]: >> Load path : ['/home/ws.jang/alo_2.1/alo_2.1.1/alo/input/inference/default_inference/']\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:52,841][inference_pipeline][input]: >> The file for batch data has been loaded. (File name: /home/ws.jang/alo_2.1/alo_2.1.1/alo/input/inference/default_inference/iris.csv)\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:52,842][inference_pipeline][input]: ==================== Success loading dataframe ====================\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:52,842][inference_pipeline][input]: >> Drop columns from the input dataframe when set << auto >> mode or specified in the << drop_columns >> in config yaml. (dropped colums:[])\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:52,843][inference_pipeline][input]: >> Start processing ignore columns & drop columns: ['/home/ws.jang/alo_2.1/alo_2.1.1/alo/input/inference/default_inference/iris.csv']\n",
      "Saved : /home/ws.jang/alo_2.1/alo_2.1.1/alo/.asset_interface/inference_pipeline/input_data.pkl\n",
      "Saved : /home/ws.jang/alo_2.1/alo_2.1.1/alo/.asset_interface/inference_pipeline/input_config.pkl\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:52,844][inference_pipeline][input]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET FINISH ===========================================================\n",
      "- time (UTC)        : 2023-12-01 06:07:52\n",
      "- current step      : input\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,845]: ==================== Finish pipeline: inference_pipeline / step: input\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:52,846]: ==================== Start pipeline: inference_pipeline / step: preprocess\n",
      "Loaded : /home/ws.jang/alo_2.1/alo_2.1.1/alo/.asset_interface/inference_pipeline/input_config.pkl\n",
      "Loaded : /home/ws.jang/alo_2.1/alo_2.1.1/alo/.asset_interface/inference_pipeline/input_data.pkl\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:53,281][inference_pipeline][preprocess]: Successfully got model path for saving or loading your AI model: \n",
      " /home/ws.jang/alo_2.1/alo_2.1.1/alo/.train_artifacts/models/preprocess/\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:53,282][inference_pipeline][preprocess]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET START ===========================================================\n",
      "- time (UTC)        : 2023-12-01 06:07:53\n",
      "- current step      : preprocess\n",
      "- asset branch.     : prep_v1.0.0\n",
      "- alolib ver.       : 2.1.2\n",
      "- alo ver.          : develop\n",
      "- load envs. keys   : dict_keys(['project_home', 'solution_metadata_version', 'artifacts', 'alo_version', 'interface_mode', 'proc_start_time', 'save_train_artifacts_path', 'save_inference_artifacts_path', 'pipeline', 'step', 'num_step', 'asset_branch', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['custom', 'mode'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:53,285][inference_pipeline][preprocess]: category_columns: []\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:53,286][inference_pipeline][preprocess]: numeric_columns: ['prep_input_x3', 'prep_input_x1', 'prep_input_x2', 'prep_input_x0']\n",
      "[Inference pipeline] Dataframe shape before preprocessing (3, 4)\n",
      "[Inference pipeline] Dataframe shape after preprocessing (3, 4)\n",
      "Saved : /home/ws.jang/alo_2.1/alo_2.1.1/alo/.asset_interface/inference_pipeline/preprocess_data.pkl\n",
      "Saved : /home/ws.jang/alo_2.1/alo_2.1.1/alo/.asset_interface/inference_pipeline/preprocess_config.pkl\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:53,295][inference_pipeline][preprocess]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET FINISH ===========================================================\n",
      "- time (UTC)        : 2023-12-01 06:07:53\n",
      "- current step      : preprocess\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:53,295]: ==================== Finish pipeline: inference_pipeline / step: preprocess\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:53,296]: ==================== Start pipeline: inference_pipeline / step: inference\n",
      "font: ['sans-serif']\n",
      "Loaded : /home/ws.jang/alo_2.1/alo_2.1.1/alo/.asset_interface/inference_pipeline/preprocess_config.pkl\n",
      "Loaded : /home/ws.jang/alo_2.1/alo_2.1.1/alo/.asset_interface/inference_pipeline/preprocess_data.pkl\n",
      "\n",
      " ################################### inference_init (sec):  0.0003490447998046875 ################################### \n",
      "\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:54,162][inference_pipeline][inference]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET START ===========================================================\n",
      "- time (UTC)        : 2023-12-01 06:07:54\n",
      "- current step      : inference\n",
      "- asset branch.     : tcr_v1.1.4\n",
      "- alolib ver.       : 2.1.2\n",
      "- alo ver.          : develop\n",
      "- load envs. keys   : dict_keys(['project_home', 'solution_metadata_version', 'artifacts', 'alo_version', 'interface_mode', 'proc_start_time', 'save_train_artifacts_path', 'save_inference_artifacts_path', 'pipeline', 'step', 'num_step', 'asset_branch', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['model_type', 'run_shapley'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'preprocess'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:54,163][inference_pipeline][inference]: Successfully got model path for saving or loading your AI model: \n",
      " /home/ws.jang/alo_2.1/alo_2.1.1/alo/.train_artifacts/models/train/\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:54,164][inference_pipeline][inference]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/ws.jang/alo_2.1/alo_2.1.1/alo/.inference_artifacts/output/inference/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \n",
      "해당 column 은 Training 과정에 사용되지 않습니다. (column_name: ['Unnamed: 0', 'target'])\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:54,166][inference_pipeline][inference]: Successfully got model path for saving or loading your AI model: \n",
      " /home/ws.jang/alo_2.1/alo_2.1.1/alo/.train_artifacts/models/train/\n",
      "[INFO] XAI 분석 시, 활용할 모델을 로드합니다.\n",
      "모델을 Load 완료 하였습니다. (모델 위치: /home/ws.jang/alo_2.1/alo_2.1.1/alo/.train_artifacts/models/train/best_model_top0.pkl)\n",
      "[INFO] SHAP 기반 XAI 분석을 진행합니다.\n",
      "[INFO] Summary_plot for Inference data 를 저장했습니다. (1/2)\n",
      "[\u001b[33;21mWARNING\u001b[0m][ASSET][2023-12-01 15:07:54,633][inference_pipeline][inference]: Please enter the << external_path - save_inference_artifacts_path >> in the experimental_plan.yaml.\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:54,634][inference_pipeline][inference]: Successfully saved inference summary yaml. \n",
      " >> /home/ws.jang/alo_2.1/alo_2.1.1/alo/.inference_artifacts/score/inference_summary.yaml\n",
      "Saved : /home/ws.jang/alo_2.1/alo_2.1.1/alo/.asset_interface/inference_pipeline/inference_data.pkl\n",
      "Saved : /home/ws.jang/alo_2.1/alo_2.1.1/alo/.asset_interface/inference_pipeline/inference_config.pkl\n",
      "\n",
      " ################################### inference_user_run (sec):  0.47287702560424805 ################################### \n",
      "\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2023-12-01 15:07:54,637][inference_pipeline][inference]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET FINISH ===========================================================\n",
      "- time (UTC)        : 2023-12-01 06:07:54\n",
      "- current step      : inference\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:54,638]: ==================== Finish pipeline: inference_pipeline / step: inference\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:54,639]: None of external path is written in your experimental_plan.yaml. Skip saving artifacts into external path. \n",
      "\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:54,642]: Successfully completes << .history >> backup (experimental_plan.yaml & artifacts)\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2023-12-01 15:07:54,643]: Process finish-time: 2023-12-01 15:07:54\n"
     ]
    }
   ],
   "source": [
    "!python ../../main.py --mode 'inference'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aic_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
