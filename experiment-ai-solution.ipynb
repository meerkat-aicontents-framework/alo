{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model 제작을 위한 실험 프로세스 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 실험이 가능한가? \n",
    "- 학습 실험 과정 \n",
    "    - 데이터를 변경하면서 모델 성능 확인 \n",
    "    - Step 의 코드를 업데이트 하면서 학습 결과 확인\n",
    "    - Step 의 파라미터를 변경하면서 모델 성능 확인\n",
    "    - 특정 Step 만 집중적으로 재학습 \n",
    "</br></br>\n",
    " \n",
    "- 추론 실험 과정    \n",
    "    - 이전 학습 실험의 모델로 실험 가능  \n",
    "    - 고정된 모델로 데이터를 변경하면서 추론 결과 확인\n",
    "    - 고정된 모델로 파라미터를 변경하면서 추론 결과 확인     \n",
    "\n",
    "</br>\n",
    "\n",
    "**추론 결과가 좋은 모델을 찾는 것을 목표로 한다. !!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step0. 사전 준비물: \n",
    "\n",
    "##### 준비물1: \n",
    "```bash\n",
    "    conda activate {ENV-NAME}           ## python main.py 실행 용 가상환경\n",
    "    pip install ipykernel        \n",
    "    python -m ipykernel install --user --name {ENV-NAME} --display-name {IPYKERNEL-NAME}\n",
    "```\n",
    "\n",
    "##### 준비물2: \n",
    "Asset 에 self.asset.save_summary() (ALO API) 를 사용하여 학습 및 추론 결과를 저장합니다.    \n",
    "- train/inference_pipeline 에서 선언되는 경우 에 따라 train/inference history 에 따로 저장\n",
    "\n",
    "===========  \n",
    "```python \n",
    "# {solution_name}/assets/output/asset_output.py\n",
    "summary = {}\n",
    "summary['result'] = # model.predict() # 'OK'                                            ## Mandatory\n",
    "summary['score'] = # model.predict_proba() # 0.98                                       ## Mandatory\n",
    "summary['note'] = # Score는 모델의 추론 예측 결과에 대한 확률 값을 나타냅니다.            ## Mandatory\n",
    "summary['probability'] = # model.predict_proba() # {'OK': 0.65, 'NG1':0.25, 'NG2':0.1}  ## Optional\n",
    "\n",
    "self.asset.save_summary(result=summary['result'], score=summary['score'], note=summary['note'], probability=summary['probability'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## history table 을 시각적 표현을 위해 \n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:30,204]: alolib already exists in local path.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:31,370]: Success installing alolib requirements.txt\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:31,374]: Requirement already satisfied: pyyaml==6.0.1 in /home/sehyun.song/miniforge3/envs/tcr/lib/python3.10/site-packages (from -r /home/sehyun.song/Project/alo/dev-240228/alolib/requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: pytz==2021.3 in /home/sehyun.song/miniforge3/envs/tcr/lib/python3.10/site-packages (from -r /home/sehyun.song/Project/alo/dev-240228/alolib/requirements.txt (line 2)) (2021.3)\n",
      "Requirement already satisfied: psutil==5.9.5 in /home/sehyun.song/miniforge3/envs/tcr/lib/python3.10/site-packages (from -r /home/sehyun.song/Project/alo/dev-240228/alolib/requirements.txt (line 3)) (5.9.5)\n",
      "Requirement already satisfied: requests==2.31.0 in /home/sehyun.song/miniforge3/envs/tcr/lib/python3.10/site-packages (from -r /home/sehyun.song/Project/alo/dev-240228/alolib/requirements.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sehyun.song/miniforge3/envs/tcr/lib/python3.10/site-packages (from requests==2.31.0->-r /home/sehyun.song/Project/alo/dev-240228/alolib/requirements.txt (line 4)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sehyun.song/miniforge3/envs/tcr/lib/python3.10/site-packages (from requests==2.31.0->-r /home/sehyun.song/Project/alo/dev-240228/alolib/requirements.txt (line 4)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sehyun.song/miniforge3/envs/tcr/lib/python3.10/site-packages (from requests==2.31.0->-r /home/sehyun.song/Project/alo/dev-240228/alolib/requirements.txt (line 4)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sehyun.song/miniforge3/envs/tcr/lib/python3.10/site-packages (from requests==2.31.0->-r /home/sehyun.song/Project/alo/dev-240228/alolib/requirements.txt (line 4)) (2024.2.2)\n",
      "\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:31,377]: Successfully loaded experimental plan yaml: \n",
      " /home/sehyun.song/Project/alo/dev-240228/solution/experimental_plan.yaml\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:31,380]: Successfully loaded << experimental_plan.yaml >> from: \n",
      " /home/sehyun.song/Project/alo/dev-240228/solution/experimental_plan.yaml\n",
      "[\u001b[1;32mINFO\u001b[0m][META][2024-03-09 16:21:31,398]: Loaded solution_metadata: \n",
      "None\n",
      "\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:31,401]: Process start-time: 240309_162131\n",
      "[\u001b[1;32mINFO\u001b[0m][META][2024-03-09 16:21:31,403]: ALO version = develop\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:31,405]: ==================== Start ALO preset ==================== \n"
     ]
    }
   ],
   "source": [
    "from src.alo import ALO\n",
    "import os \n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "alo = ALO()\n",
    "train_pipeline = alo.pipeline(pipes='train_pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. 학습 과정을 실행\n",
    "- setup() : step 별 code 를 git repository 에서 clone 하고, python package 를 설치 합니다. \n",
    "- load() : external_data 를 ALO 환경으로 load 합니다. \n",
    "- run() : step 을 pipeline 순서대로 실행 합니다. \n",
    "- save() : 학습 및 추론 결과를 *_artifact 에 저장 합니다. 실험 내용을 history 에 backup 합니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history 폴더에 아래와 같은 내용들이 저장 됩니다. \n",
    "\n",
    "\n",
    "```bash\n",
    "├── history \n",
    "     ├── train\n",
    "     │   ├── {UTC}-{random}-{contents_name}\n",
    "     │        ├── experimental_plan.yaml\n",
    "     │        ├── register_source    ## train docker container 준비물\n",
    "     │            ├── assets\n",
    "     │            ├── solution\n",
    "     │            ├── src\n",
    "     │            ├── alolib\n",
    "     │        ├── models\n",
    "     │        ├── score\n",
    "     │        ├── report\n",
    "     │        ├── output\n",
    "     │        ├── log\n",
    "     │            ├── experimental_history.json  ## 학습 데이터, 코드, 파라미터 변경 사항 기록\n",
    "     │\n",
    "     ├── inference\n",
    "     │   ├── {UTC}-{random}-{contents_name}\n",
    "     │        ├── experimental_plan.yaml\n",
    "     │        ├── register_source    ## inference docker container 준비물\n",
    "     │            ├── assets\n",
    "     │            ├── solution\n",
    "     │            ├── src\n",
    "     │            ├── alolib\n",
    "     │        ├── score\n",
    "     │        ├── extra_output\n",
    "     │        ├── output\n",
    "     │        ├── log\n",
    "     │            ├── experimental_history.json  ## 추론 데이터, 코드, 파라미터 변경 사항 기록\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,924]: Successfully emptied << /home/sehyun.song/Project/alo/dev-240228/train_artifacts/score >> \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,935]: Successfully emptied << /home/sehyun.song/Project/alo/dev-240228/train_artifacts/models >> \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,937]: Successfully emptied << /home/sehyun.song/Project/alo/dev-240228/train_artifacts/output >> \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,940]: Successfully emptied << /home/sehyun.song/Project/alo/dev-240228/train_artifacts/report >> \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,942]: Start setting-up << input >> asset @ << assets >> directory.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,945]: << input >> asset had already been created at 2024-03-06 23:43:57.387463\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,947]: Start setting-up << train >> asset @ << assets >> directory.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,949]: << train >> asset had already been created at 2024-03-06 23:43:57.535467\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,952]: ======================================== Start dependency installation : << input >> \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,954]: Start checking existence & installing package - pandas==1.5.3 | Progress: ( 1 / 2 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,957]: [OK] << pandas==1.5.3 >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,959]: ======================================== Start dependency installation : << train >> \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,961]: Start checking existence & installing package - scikit-learn | Progress: ( 2 / 2 total packages ) \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,964]: [OK] << scikit-learn >> already exists\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,966]: ======================================== Start dependency installation : << force-reinstall >> \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,968]: ======================================== Finish dependency installation \n",
      "\n",
      "[\u001b[33;21mWARNING\u001b[0m][PROCESS][2024-03-09 16:21:54,971]: You did not write any << aws_key_profile >> in the config yaml file. When you wanna get data from s3 storage, \n",
      "                                     you have to write the aws_key_profile or set << AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY >> in your os environment. \n",
      "\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,974]: Successfuly removed << /home/sehyun.song/Project/alo/dev-240228/input/train/ >> before loading external data.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,976]: << ./solution/sample_data/train_data/ >> may be relative path. The reference folder of relative path is << /home/sehyun.song/Project/alo/dev-240228/ >>. \n",
      " If this is not appropriate relative path, Loading external data process would raise error.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,979]: Successfully done loading external data: \n",
      " ./solution/sample_data/train_data/ --> /home/sehyun.song/Project/alo/dev-240228/input/train/\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,981]: Successfuly finish loading << ./solution/sample_data/train_data/ >> into << /home/sehyun.song/Project/alo/dev-240228/input/ >>\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,984]: ==================== Start pipeline: train_pipeline / step: input\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:21:54,987][train_pipeline][input]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET START ===========================================================\n",
      "- time (UTC)        : 2024-03-09 07:21:54\n",
      "- current step      : input\n",
      "- asset branch.     : release_1.0\n",
      "- alolib ver.       : develop\n",
      "- alo ver.          : develop\n",
      "- load envs. keys   : dict_keys(['project_home', 'solution_metadata_version', 'artifacts', 'alo_version', 'interface_mode', 'proc_start_time', 'save_train_artifacts_path', 'save_inference_artifacts_path', 'pipeline', 'step', 'num_step', 'asset_branch', 'log_file_path', 'load_data', 'load_config', 'save_data', 'save_config', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['input_data_folder', 'x_columns', 'y_column'])\n",
      "- load config. keys : dict_keys(['meta', 'x_columns', 'y_column', 'model_path'])\n",
      "- load data keys    : dict_keys(['dataframe0'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:21:54,994][train_pipeline][input]: Loaded dataframe0\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:21:54,996][train_pipeline][input]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET FINISH ===========================================================\n",
      "- time (UTC)        : 2024-03-09 07:21:54\n",
      "- current step      : input\n",
      "- save config. keys : dict_keys(['meta', 'x_columns', 'y_column', 'model_path'])\n",
      "- save data keys    : dict_keys(['dataframe0'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:54,998]: ==================== Finish pipeline: train_pipeline / step: input\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,001]: ==================== Start pipeline: train_pipeline / step: train\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:21:55,004][train_pipeline][train]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET START ===========================================================\n",
      "- time (UTC)        : 2024-03-09 07:21:55\n",
      "- current step      : train\n",
      "- asset branch.     : release_1.0\n",
      "- alolib ver.       : develop\n",
      "- alo ver.          : develop\n",
      "- load envs. keys   : dict_keys(['project_home', 'solution_metadata_version', 'artifacts', 'alo_version', 'interface_mode', 'proc_start_time', 'save_train_artifacts_path', 'save_inference_artifacts_path', 'pipeline', 'step', 'num_step', 'asset_branch', 'log_file_path', 'load_data', 'load_config', 'save_data', 'save_config', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['n_estimators'])\n",
      "- load config. keys : dict_keys(['meta', 'x_columns', 'y_column', 'model_path'])\n",
      "- load data keys    : dict_keys(['dataframe0'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder '/home/sehyun.song/Project/alo/dev-240228/.package_list/train_pipeline/' has been removed.\n",
      "Folder '/home/sehyun.song/Project/alo/dev-240228/.package_list/train_pipeline/' has been created.\n",
      "SSH2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:21:55,176][train_pipeline][train]: Successfully got model path for saving or loading your AI model: \n",
      " /home/sehyun.song/Project/alo/dev-240228/train_artifacts/models/train/\n",
      "[\u001b[33;21mWARNING\u001b[0m][ASSET][2024-03-09 16:21:55,183][train_pipeline][train]: Please enter the << external_path - save_train_artifacts_path >> in the experimental_plan.yaml.\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:21:55,186][train_pipeline][train]: Successfully saved inference summary yaml. \n",
      " >> /home/sehyun.song/Project/alo/dev-240228/train_artifacts/score/train_summary.yaml\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:21:55,188][train_pipeline][train]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET FINISH ===========================================================\n",
      "- time (UTC)        : 2024-03-09 07:21:55\n",
      "- current step      : train\n",
      "- save config. keys : dict_keys(['meta', 'x_columns', 'y_column', 'model_path'])\n",
      "- save data keys    : dict_keys(['dataframe0'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,190]: ==================== Finish pipeline: train_pipeline / step: train\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,195]: None of external path is written in your experimental_plan.yaml. Skip saving artifacts into external path. \n",
      "\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,197]: Process finish-time: 2024-03-09 16:21:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,618]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/main.py \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-13050773-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,626]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/src \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-13050773-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,658]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/assets \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-13050773-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,679]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/solution \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-13050773-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,689]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/alolib \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-13050773-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,753]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/.git \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-13050773-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,756]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/requirements.txt \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-13050773-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,758]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/solution_requirements.txt \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-13050773-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:21:55,762]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/.package_list \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-13050773-demo-titanic/register_source/ \" \n"
     ]
    }
   ],
   "source": [
    "train_pipeline.setup()\n",
    "train_pipeline.load()\n",
    "train_pipeline.run()\n",
    "train_pipeline.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실험 결과를 확인 합니다.    \n",
    "- \"data_id\"    : 실험에 사용된 데이터가 일부라도 변경될 경우 ID 변경. 동일 데이터로 실험 결과 비교 목적     \n",
    "- \"code_id\"    : step 코드가 일부라도 변경됨을 감지(간단 프린트 문 추가 만으로도 ID 변경). 동일 코드로 실험 결과 비교에 집중    \n",
    "- \"param_id\"   : 파라미터가 추가 되거나 값이 변경될 경우 ID 변경     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>score</th>\n",
       "      <th>result</th>\n",
       "      <th>note</th>\n",
       "      <th>probability</th>\n",
       "      <th>version</th>\n",
       "      <th>data_id</th>\n",
       "      <th>code_id</th>\n",
       "      <th>param_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240309T072131Z-13050773-demo-titanic</td>\n",
       "      <td>2024-03-09 07:21:31</td>\n",
       "      <td>2024-03-09 16:21:55</td>\n",
       "      <td>0.20</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-09 07:21:55)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>7732711228ca</td>\n",
       "      <td>8a3cb8f9217c</td>\n",
       "      <td>80885fb84940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240309T072131Z-53505915-demo-titanic</td>\n",
       "      <td>2024-03-09 07:21:31</td>\n",
       "      <td>2024-03-09 16:21:53</td>\n",
       "      <td>0.85</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-09 07:21:53)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>7732711228ca</td>\n",
       "      <td>8a3cb8f9217c</td>\n",
       "      <td>80885fb84940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240309T072131Z-92229745-demo-titanic</td>\n",
       "      <td>2024-03-09 07:21:31</td>\n",
       "      <td>2024-03-09 16:21:51</td>\n",
       "      <td>0.55</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-09 07:21:51)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>7732711228ca</td>\n",
       "      <td>8a3cb8f9217c</td>\n",
       "      <td>80885fb84940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240309T072131Z-34778465-demo-titanic</td>\n",
       "      <td>2024-03-09 07:21:31</td>\n",
       "      <td>2024-03-09 16:21:35</td>\n",
       "      <td>0.58</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-09 07:21:35)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>7732711228ca</td>\n",
       "      <td>8a3cb8f9217c</td>\n",
       "      <td>80885fb84940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id           start_time  \\\n",
       "0  20240309T072131Z-13050773-demo-titanic  2024-03-09 07:21:31   \n",
       "1  20240309T072131Z-53505915-demo-titanic  2024-03-09 07:21:31   \n",
       "2  20240309T072131Z-92229745-demo-titanic  2024-03-09 07:21:31   \n",
       "3  20240309T072131Z-34778465-demo-titanic  2024-03-09 07:21:31   \n",
       "\n",
       "              end_time  score                        result  \\\n",
       "0  2024-03-09 16:21:55   0.20  precision: 0.796594261196031   \n",
       "1  2024-03-09 16:21:53   0.85  precision: 0.796594261196031   \n",
       "2  2024-03-09 16:21:51   0.55  precision: 0.796594261196031   \n",
       "3  2024-03-09 16:21:35   0.58  precision: 0.796594261196031   \n",
       "\n",
       "                                            note probability version  \\\n",
       "0  Test Titanic-demo (date: 2024-03-09 07:21:55)          {}           \n",
       "1  Test Titanic-demo (date: 2024-03-09 07:21:53)          {}           \n",
       "2  Test Titanic-demo (date: 2024-03-09 07:21:51)          {}           \n",
       "3  Test Titanic-demo (date: 2024-03-09 07:21:35)          {}           \n",
       "\n",
       "        data_id       code_id      param_id  \n",
       "0  7732711228ca  8a3cb8f9217c  80885fb84940  \n",
       "1  7732711228ca  8a3cb8f9217c  80885fb84940  \n",
       "2  7732711228ca  8a3cb8f9217c  80885fb84940  \n",
       "3  7732711228ca  8a3cb8f9217c  80885fb84940  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_list = train_pipeline.history( )\n",
    "display(pd.DataFrame(table_list).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. 데이터 변경하여 실험하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[33;21mWARNING\u001b[0m][PROCESS][2024-03-09 16:23:18,101]: You did not write any << aws_key_profile >> in the config yaml file. When you wanna get data from s3 storage, \n",
      "                                     you have to write the aws_key_profile or set << AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY >> in your os environment. \n",
      "\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,105]: Successfuly removed << /home/sehyun.song/Project/alo/dev-240228/input/train/ >> before loading external data.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,107]: << ./solution/sample_data2/train_data/ >> may be relative path. The reference folder of relative path is << /home/sehyun.song/Project/alo/dev-240228/ >>. \n",
      " If this is not appropriate relative path, Loading external data process would raise error.\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,110]: Successfully done loading external data: \n",
      " ./solution/sample_data2/train_data/ --> /home/sehyun.song/Project/alo/dev-240228/input/train/\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,113]: Successfuly finish loading << ./solution/sample_data2/train_data/ >> into << /home/sehyun.song/Project/alo/dev-240228/input/ >>\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,115]: ==================== Start pipeline: train_pipeline / step: input\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:23:18,118][train_pipeline][input]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET START ===========================================================\n",
      "- time (UTC)        : 2024-03-09 07:23:18\n",
      "- current step      : input\n",
      "- asset branch.     : release_1.0\n",
      "- alolib ver.       : develop\n",
      "- alo ver.          : develop\n",
      "- load envs. keys   : dict_keys(['project_home', 'solution_metadata_version', 'artifacts', 'alo_version', 'interface_mode', 'proc_start_time', 'save_train_artifacts_path', 'save_inference_artifacts_path', 'pipeline', 'step', 'num_step', 'asset_branch', 'log_file_path', 'load_data', 'load_config', 'save_data', 'save_config', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['input_data_folder', 'x_columns', 'y_column'])\n",
      "- load config. keys : dict_keys(['meta', 'x_columns', 'y_column', 'model_path'])\n",
      "- load data keys    : dict_keys(['dataframe0'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:23:18,125][train_pipeline][input]: Loaded dataframe0\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:23:18,127][train_pipeline][input]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET FINISH ===========================================================\n",
      "- time (UTC)        : 2024-03-09 07:23:18\n",
      "- current step      : input\n",
      "- save config. keys : dict_keys(['meta', 'x_columns', 'y_column', 'model_path'])\n",
      "- save data keys    : dict_keys(['dataframe0'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,130]: ==================== Finish pipeline: train_pipeline / step: input\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,132]: ==================== Start pipeline: train_pipeline / step: train\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:23:18,135][train_pipeline][train]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET START ===========================================================\n",
      "- time (UTC)        : 2024-03-09 07:23:18\n",
      "- current step      : train\n",
      "- asset branch.     : release_1.0\n",
      "- alolib ver.       : develop\n",
      "- alo ver.          : develop\n",
      "- load envs. keys   : dict_keys(['project_home', 'solution_metadata_version', 'artifacts', 'alo_version', 'interface_mode', 'proc_start_time', 'save_train_artifacts_path', 'save_inference_artifacts_path', 'pipeline', 'step', 'num_step', 'asset_branch', 'log_file_path', 'load_data', 'load_config', 'save_data', 'save_config', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['n_estimators'])\n",
      "- load config. keys : dict_keys(['meta', 'x_columns', 'y_column', 'model_path'])\n",
      "- load data keys    : dict_keys(['dataframe0'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:23:18,315][train_pipeline][train]: Successfully got model path for saving or loading your AI model: \n",
      " /home/sehyun.song/Project/alo/dev-240228/train_artifacts/models/train/\n",
      "[\u001b[33;21mWARNING\u001b[0m][ASSET][2024-03-09 16:23:18,324][train_pipeline][train]: Please enter the << external_path - save_train_artifacts_path >> in the experimental_plan.yaml.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSH2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:23:18,328][train_pipeline][train]: Successfully saved inference summary yaml. \n",
      " >> /home/sehyun.song/Project/alo/dev-240228/train_artifacts/score/train_summary.yaml\n",
      "[\u001b[1;32mINFO\u001b[0m][ASSET][2024-03-09 16:23:18,330][train_pipeline][train]: \u001b[36m\n",
      "\n",
      "=========================================================== ASSET FINISH ===========================================================\n",
      "- time (UTC)        : 2024-03-09 07:23:18\n",
      "- current step      : train\n",
      "- save config. keys : dict_keys(['meta', 'x_columns', 'y_column', 'model_path'])\n",
      "- save data keys    : dict_keys(['dataframe0'])\n",
      "====================================================================================================================================\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,332]: ==================== Finish pipeline: train_pipeline / step: train\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,337]: None of external path is written in your experimental_plan.yaml. Skip saving artifacts into external path. \n",
      "\n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,339]: Process finish-time: 2024-03-09 16:23:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,789]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/main.py \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-27087406-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,796]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/src \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-27087406-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,829]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/assets \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-27087406-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,849]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/solution \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-27087406-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,860]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/alolib \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-27087406-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,923]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/.git \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-27087406-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,925]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/requirements.txt \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-27087406-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,928]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/solution_requirements.txt \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-27087406-demo-titanic/register_source/ \" \n",
      "[\u001b[1;32mINFO\u001b[0m][PROCESS][2024-03-09 16:23:18,931]: [INFO] copy from \" /home/sehyun.song/Project/alo/dev-240228/.package_list \"  -->  \" /home/sehyun.song/Project/alo/dev-240228/history/train/20240309T072131Z-27087406-demo-titanic/register_source/ \" \n"
     ]
    }
   ],
   "source": [
    "new_data = './solution/sample_data2/train_data/'  ## 실험에 필요한 데이터로 변경 !!\n",
    "\n",
    "train_pipeline.load(data_path=new_data)\n",
    "train_pipeline.run()\n",
    "train_pipeline.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>score</th>\n",
       "      <th>result</th>\n",
       "      <th>note</th>\n",
       "      <th>probability</th>\n",
       "      <th>version</th>\n",
       "      <th>data_id</th>\n",
       "      <th>code_id</th>\n",
       "      <th>param_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240309T072131Z-27087406-demo-titanic</td>\n",
       "      <td>2024-03-09 07:21:31</td>\n",
       "      <td>2024-03-09 16:23:18</td>\n",
       "      <td>0.99</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-09 07:23:18)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>e72889ca48a6</td>\n",
       "      <td>8a3cb8f9217c</td>\n",
       "      <td>80885fb84940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240309T072131Z-03916014-demo-titanic</td>\n",
       "      <td>2024-03-09 07:21:31</td>\n",
       "      <td>2024-03-09 16:22:44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-09 07:22:44)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>e72889ca48a6</td>\n",
       "      <td>8a3cb8f9217c</td>\n",
       "      <td>80885fb84940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240309T072131Z-13050773-demo-titanic</td>\n",
       "      <td>2024-03-09 07:21:31</td>\n",
       "      <td>2024-03-09 16:21:55</td>\n",
       "      <td>0.20</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-09 07:21:55)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>7732711228ca</td>\n",
       "      <td>8a3cb8f9217c</td>\n",
       "      <td>80885fb84940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240309T072131Z-53505915-demo-titanic</td>\n",
       "      <td>2024-03-09 07:21:31</td>\n",
       "      <td>2024-03-09 16:21:53</td>\n",
       "      <td>0.85</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-09 07:21:53)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>7732711228ca</td>\n",
       "      <td>8a3cb8f9217c</td>\n",
       "      <td>80885fb84940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240309T072131Z-92229745-demo-titanic</td>\n",
       "      <td>2024-03-09 07:21:31</td>\n",
       "      <td>2024-03-09 16:21:51</td>\n",
       "      <td>0.55</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-09 07:21:51)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>7732711228ca</td>\n",
       "      <td>8a3cb8f9217c</td>\n",
       "      <td>80885fb84940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20240309T072131Z-34778465-demo-titanic</td>\n",
       "      <td>2024-03-09 07:21:31</td>\n",
       "      <td>2024-03-09 16:21:35</td>\n",
       "      <td>0.58</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-09 07:21:35)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>7732711228ca</td>\n",
       "      <td>8a3cb8f9217c</td>\n",
       "      <td>80885fb84940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20240309T065929Z-03426922-demo-titanic</td>\n",
       "      <td>2024-03-09 06:59:29</td>\n",
       "      <td>2024-03-09 15:59:33</td>\n",
       "      <td>0.64</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-09 06:59:33)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>0000000017c20530</td>\n",
       "      <td>8a3cb8f9217c</td>\n",
       "      <td>80885fb84940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20240309T031352Z-04407409-demo-titanic</td>\n",
       "      <td>2024-03-09 03:13:52</td>\n",
       "      <td>2024-03-09 12:16:20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-09 03:16:20)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>9484828294349639189</td>\n",
       "      <td>16505050446478898296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20240308T180553Z-88428745-demo-titanic</td>\n",
       "      <td>2024-03-08 18:05:53</td>\n",
       "      <td>2024-03-09 03:20:40</td>\n",
       "      <td>0.98</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-08 18:20:40)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>398591280</td>\n",
       "      <td>9484828294349639189</td>\n",
       "      <td>3860141117657530653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20240308T131729Z-91458146-demo-titanic</td>\n",
       "      <td>2024-03-08 13:17:29</td>\n",
       "      <td>2024-03-08 22:17:31</td>\n",
       "      <td>0.35</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-08 13:17:31)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>398591280</td>\n",
       "      <td>9484828294349639189</td>\n",
       "      <td>3860141117657530653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20240308T131326Z-17088408-demo-titanic</td>\n",
       "      <td>2024-03-08 13:13:26</td>\n",
       "      <td>2024-03-08 22:13:28</td>\n",
       "      <td>0.88</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-08 13:13:28)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>398591280</td>\n",
       "      <td>9484828294349639189</td>\n",
       "      <td>3860141117657530653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20240308T131009Z-23249777-demo-titanic</td>\n",
       "      <td>2024-03-08 13:10:09</td>\n",
       "      <td>2024-03-08 22:10:10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-08 13:10:10)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>398591280</td>\n",
       "      <td>9484828294349639189</td>\n",
       "      <td>3860141117657530653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20240308T123551Z-71004875-demo-titanic</td>\n",
       "      <td>2024-03-08 12:35:51</td>\n",
       "      <td>2024-03-08 21:35:52</td>\n",
       "      <td>0.41</td>\n",
       "      <td>precision: 0.796594261196031</td>\n",
       "      <td>Test Titanic-demo (date: 2024-03-08 12:35:52)</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>398591280</td>\n",
       "      <td>9484828294349639189</td>\n",
       "      <td>3860141117657530653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id           start_time  \\\n",
       "0   20240309T072131Z-27087406-demo-titanic  2024-03-09 07:21:31   \n",
       "1   20240309T072131Z-03916014-demo-titanic  2024-03-09 07:21:31   \n",
       "2   20240309T072131Z-13050773-demo-titanic  2024-03-09 07:21:31   \n",
       "3   20240309T072131Z-53505915-demo-titanic  2024-03-09 07:21:31   \n",
       "4   20240309T072131Z-92229745-demo-titanic  2024-03-09 07:21:31   \n",
       "5   20240309T072131Z-34778465-demo-titanic  2024-03-09 07:21:31   \n",
       "6   20240309T065929Z-03426922-demo-titanic  2024-03-09 06:59:29   \n",
       "7   20240309T031352Z-04407409-demo-titanic  2024-03-09 03:13:52   \n",
       "8   20240308T180553Z-88428745-demo-titanic  2024-03-08 18:05:53   \n",
       "9   20240308T131729Z-91458146-demo-titanic  2024-03-08 13:17:29   \n",
       "10  20240308T131326Z-17088408-demo-titanic  2024-03-08 13:13:26   \n",
       "11  20240308T131009Z-23249777-demo-titanic  2024-03-08 13:10:09   \n",
       "12  20240308T123551Z-71004875-demo-titanic  2024-03-08 12:35:51   \n",
       "\n",
       "               end_time  score                        result  \\\n",
       "0   2024-03-09 16:23:18   0.99  precision: 0.796594261196031   \n",
       "1   2024-03-09 16:22:44   0.56  precision: 0.796594261196031   \n",
       "2   2024-03-09 16:21:55   0.20  precision: 0.796594261196031   \n",
       "3   2024-03-09 16:21:53   0.85  precision: 0.796594261196031   \n",
       "4   2024-03-09 16:21:51   0.55  precision: 0.796594261196031   \n",
       "5   2024-03-09 16:21:35   0.58  precision: 0.796594261196031   \n",
       "6   2024-03-09 15:59:33   0.64  precision: 0.796594261196031   \n",
       "7   2024-03-09 12:16:20   0.25  precision: 0.796594261196031   \n",
       "8   2024-03-09 03:20:40   0.98  precision: 0.796594261196031   \n",
       "9   2024-03-08 22:17:31   0.35  precision: 0.796594261196031   \n",
       "10  2024-03-08 22:13:28   0.88  precision: 0.796594261196031   \n",
       "11  2024-03-08 22:10:10   0.37  precision: 0.796594261196031   \n",
       "12  2024-03-08 21:35:52   0.41  precision: 0.796594261196031   \n",
       "\n",
       "                                             note probability version  \\\n",
       "0   Test Titanic-demo (date: 2024-03-09 07:23:18)          {}           \n",
       "1   Test Titanic-demo (date: 2024-03-09 07:22:44)          {}           \n",
       "2   Test Titanic-demo (date: 2024-03-09 07:21:55)          {}           \n",
       "3   Test Titanic-demo (date: 2024-03-09 07:21:53)          {}           \n",
       "4   Test Titanic-demo (date: 2024-03-09 07:21:51)          {}           \n",
       "5   Test Titanic-demo (date: 2024-03-09 07:21:35)          {}           \n",
       "6   Test Titanic-demo (date: 2024-03-09 06:59:33)          {}           \n",
       "7   Test Titanic-demo (date: 2024-03-09 03:16:20)          {}           \n",
       "8   Test Titanic-demo (date: 2024-03-08 18:20:40)          {}           \n",
       "9   Test Titanic-demo (date: 2024-03-08 13:17:31)          {}           \n",
       "10  Test Titanic-demo (date: 2024-03-08 13:13:28)          {}           \n",
       "11  Test Titanic-demo (date: 2024-03-08 13:10:10)          {}           \n",
       "12  Test Titanic-demo (date: 2024-03-08 12:35:52)          {}           \n",
       "\n",
       "             data_id              code_id              param_id  \n",
       "0       e72889ca48a6         8a3cb8f9217c          80885fb84940  \n",
       "1       e72889ca48a6         8a3cb8f9217c          80885fb84940  \n",
       "2       7732711228ca         8a3cb8f9217c          80885fb84940  \n",
       "3       7732711228ca         8a3cb8f9217c          80885fb84940  \n",
       "4       7732711228ca         8a3cb8f9217c          80885fb84940  \n",
       "5       7732711228ca         8a3cb8f9217c          80885fb84940  \n",
       "6   0000000017c20530         8a3cb8f9217c          80885fb84940  \n",
       "7               None  9484828294349639189  16505050446478898296  \n",
       "8          398591280  9484828294349639189   3860141117657530653  \n",
       "9          398591280  9484828294349639189   3860141117657530653  \n",
       "10         398591280  9484828294349639189   3860141117657530653  \n",
       "11         398591280  9484828294349639189   3860141117657530653  \n",
       "12         398591280  9484828294349639189   3860141117657530653  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_list = train_pipeline.history()\n",
    "display(pd.DataFrame(table_list).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. 코드 변경하여 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline.run()\n",
    "train_pipeline.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = train_pipeline.history()\n",
    "display(pd.DataFrame(table_list).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. 파라미터 변경하여 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline.get_parameter('train')['n_estimators'] = 150\n",
    "train_pipeline.get_parameter('train')\n",
    "train_pipeline.run()\n",
    "train_pipeline.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4-2: 파라미터 변경 & 특정 Step 만 반복 실행하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in [100, 110, 120, 130]:\n",
    "    train_pipeline.get_parameter('train')['n_estimators'] = value\n",
    "    train_pipeline.run(steps = ['train'])\n",
    "    train_pipeline.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = train_pipeline.history()\n",
    "display(pd.DataFrame(table_list).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: 추론 결과를 확인 (데이터, 코드, 파라미터 변경 가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = '20240308T131729Z-91458146-demo-titanic'\n",
    "train_id = ''\n",
    "inference_pipeline = alo.pipeline(pipes='inference_pipeline', train_id=train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline.load()\n",
    "inference_pipeline.system_envs['inference_history']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline.setup()\n",
    "inference_pipeline.load()\n",
    "inference_pipeline.run()\n",
    "inference_pipeline.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = inference_pipeline.history()\n",
    "display(pd.DataFrame(table_list).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 결과 등록 (train_id, inference_id 입력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "username = input('Username: ')\n",
    "password = getpass.getpass('Password: ')\n",
    "\n",
    "print(\"Your ID : \", username)\n",
    "print(\"Your PW : \", password.replace(password, '*' * len(password)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infra_setup = \"./setting/example_infra_config/infra_config.localtest.yaml\"\n",
    "solution_info ={\n",
    "    'inference_only': False, # True, False\n",
    "    'solution_update': False,\n",
    "    'solution_name': 'titanic-exp-test1',\n",
    "    'solution_type': 'private',\n",
    "    'contents_type': {\n",
    "            'support_labeling': False,\n",
    "            'inference_result_datatype': 'table', # 'image'\n",
    "            'train_datatype': 'table', # 'image'\n",
    "            'labeling_column_name': ''\n",
    "    },\n",
    "    'train_gpu': False, ## cpu, gpu\n",
    "    'inference_gpu': False,\n",
    "    \"inference_arm\": False,  # amd, arm  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history table 에서 ID 를 확인하고, 입력하여 솔루션을 등록 한다. \n",
    "- 학습 실험 과 추론 실험 을 혼합하여 솔루션 등록이 가능 \n",
    "- train_id, inference_id 가 None 인 경우, 마지막 실험 결과를 등록 \n",
    "    - history 의 experimental_plan.yaml 를 참조하여 1회 실행하고, 이를 솔루션 등록 함 \n",
    "    - history 가 오염 될 수 있음을 고려 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register = alo.register(\n",
    "    infra_setup=infra_setup,\n",
    "    solution_info=solution_info,\n",
    "    train_id='',   ## history 에서 확인 한 Train ID 입력 하세요.!!\n",
    "    inference_id='',  ## history 에서 확인 한 Inference ID 를 입력 하세요 !!\n",
    ")\n",
    "\n",
    "register.login(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register.debugging = True  ## default: False (skip 항목: docker 생성, solution 등록)\n",
    "register.run(username=username, password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register.run_train(\n",
    "    status_period = 10, ## 몇 초 간격으로 학습 상태를 체크할 것인지 설정\n",
    "    delete_instance = False,   ## 학습 테스트에 사용한 solution instance & stream 을 삭제할 것인지 설정 \n",
    "    delete_solution= False,  ## solution 을 삭제할 것인지 설정\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr",
   "language": "python",
   "name": "tcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
