{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model 제작을 위한 실험 프로세스 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 실험이 가능한가? \n",
    "- 학습 실험 과정 \n",
    "    - 데이터를 변경하면서 모델 성능 확인 \n",
    "    - Step 의 코드를 업데이트 하면서 학습 결과 확인\n",
    "    - Step 의 파라미터를 변경하면서 모델 성능 확인\n",
    "    - 특정 Step 만 집중적으로 재학습 \n",
    "</br></br>\n",
    " \n",
    "- 추론 실험 과정    \n",
    "    - 이전 학습 실험의 모델로 실험 가능  \n",
    "    - 고정된 모델로 데이터를 변경하면서 추론 결과 확인\n",
    "    - 고정된 모델로 파라미터를 변경하면서 추론 결과 확인     \n",
    "\n",
    "</br>\n",
    "\n",
    "**추론 결과가 좋은 모델을 찾는 것을 목표로 한다. !!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step0. 사전 준비물: \n",
    "\n",
    "Asset 에 self.asset.save_summary() (ALO API) 를 사용하여 학습 및 추론 결과를 저장합니다.    \n",
    "train_pipeline 에서 선언 할 경우 train model 결과로 수집되고, inference_pipelne 에서 사용하면 inference summary 결과로 수집됩니다. \n",
    "\n",
    "아래는 output step 에서 save_summary() 를 사용한 예제 입니다. \n",
    "</br></br>\n",
    "```python \n",
    "# {solution_name}/assets/output/asset_output.py\n",
    "summary = {}\n",
    "summary['result'] = # model.predict() # 'OK'                                            ## Mandatory\n",
    "summary['score'] = # model.predict_proba() # 0.98                                       ## Mandatory\n",
    "summary['note'] = # Score는 모델의 추론 예측 결과에 대한 확률 값을 나타냅니다.            ## Mandatory\n",
    "summary['probability'] = # model.predict_proba() # {'OK': 0.65, 'NG1':0.25, 'NG2':0.1}  ## Optional\n",
    "\n",
    "self.asset.save_summary(result=summary['result'], score=summary['score'], note=summary['note'], probability=summary['probability'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.alo import ALO\n",
    "import os \n",
    "from pprint import pprint\n",
    "\n",
    "alo = ALO()\n",
    "train_pipeline = alo.pipeline(pipes='train_pipeline')\n",
    "inference_pipeline = alo.pipeline(pipes='inference_pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1. 학습 과정을 실행\n",
    "- setup() : step 별 code 를 git repository 에서 clone 하고, python package 를 설치 합니다. \n",
    "- load() : external_data 를 ALO 환경으로 load 합니다. \n",
    "- run() : step 을 pipeline 순서대로 실행 합니다. \n",
    "- save() : 학습 및 추론 결과를 *_artifact 에 저장 합니다. 실험 내용을 history 에 backup 합니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history 폴더에 아래와 같은 내용들이 저장 됩니다. \n",
    "\n",
    "\n",
    "```bash\n",
    "├── history \n",
    "     ├── train\n",
    "     │   ├── {UTC}-{random}-{contents_name}\n",
    "     │        ├── experimental_plan.yaml\n",
    "     │        ├── register_source    ## train docker container 준비물\n",
    "     │            ├── assets\n",
    "     │            ├── solution\n",
    "     │            ├── src\n",
    "     │            ├── alolib\n",
    "     │        ├── models\n",
    "     │        ├── score\n",
    "     │        ├── report\n",
    "     │        ├── output\n",
    "     │        ├── log\n",
    "     │            ├── experimental_history.json  ## 학습 데이터, 코드, 파라미터 변경 사항 기록\n",
    "     │\n",
    "     ├── inference\n",
    "     │   ├── {UTC}-{random}-{contents_name}\n",
    "     │        ├── experimental_plan.yaml\n",
    "     │        ├── register_source    ## inference docker container 준비물\n",
    "     │            ├── assets\n",
    "     │            ├── solution\n",
    "     │            ├── src\n",
    "     │            ├── alolib\n",
    "     │        ├── score\n",
    "     │        ├── extra_output\n",
    "     │        ├── output\n",
    "     │        ├── log\n",
    "     │            ├── experimental_history.json  ## 추론 데이터, 코드, 파라미터 변경 사항 기록\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline.setup()\n",
    "train_pipeline.load()\n",
    "train_pipeline.run()\n",
    "train_pipeline.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실험 결과를 확인 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_pipeline.history()\n",
    "display(df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2. 데이터 변경하여 실험하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = './solution/sample_data2/train_data/'  ## 실험에 필요한 데이터로 변경 !!\n",
    "\n",
    "train_pipeline.load(data_path=new_data)\n",
    "train_pipeline.run()\n",
    "train_pipeline.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_pipeline.history()\n",
    "display(df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3. 코드 변경하여 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline.run()\n",
    "train_pipeline.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_pipeline.history()\n",
    "display(df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4. 파라미터 변경하여 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline.get_parameter('train')['n_estimators'] = 150\n",
    "train_pipeline.get_parameter('train')\n",
    "train_pipeline.run()\n",
    "train_pipeline.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험방법3-2: 파라미터 변경 & 특정 Step 만 반복 실행하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in [100, 110, 120, 130]:\n",
    "    train_pipeline.get_parameter('train')['n_estimators'] = value\n",
    "    train_pipeline.run(steps = ['train'])\n",
    "    train_pipeline.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_pipeline.history()\n",
    "display(df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline.setup()\n",
    "inference_pipeline.load()\n",
    "inference_pipeline.run()\n",
    "inference_pipeline.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 결과 등록 (train_id, inference_id 입력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "username = input('Username: ')\n",
    "password = getpass.getpass('Password: ')\n",
    "\n",
    "print(\"Your ID : \", username)\n",
    "print(\"Your PW : \", password.replace(password, '*' * len(password)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infra_setup = \"./setting/example_infra_config/infra_config.localtest.yaml\"\n",
    "solution_info ={\n",
    "    'inference_only': False, # True, False\n",
    "    'solution_update': False,\n",
    "    'solution_name': 'titanic-exp-test1',\n",
    "    'solution_type': 'private',\n",
    "    'contents_type': {\n",
    "            'support_labeling': False,\n",
    "            'inference_result_datatype': 'table', # 'image'\n",
    "            'train_datatype': 'table', # 'image'\n",
    "            'labeling_column_name': ''\n",
    "    },\n",
    "    'train_gpu': False, ## cpu, gpu\n",
    "    'inference_gpu': False,\n",
    "    \"inference_arm\": False,  # amd, arm  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history table 에서 ID 를 확인하고, 입력하여 솔루션을 등록 한다. \n",
    "- 학습 실험 과 추론 실험 을 혼합하여 솔루션 등록이 가능 \n",
    "- train_id, inference_id 가 None 인 경우, 마지막 실험 결과를 등록 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register = alo.register(\n",
    "    infra_setup=infra_setup,\n",
    "    solution_info=solution_info,\n",
    "    train_id='',   ## history 에서 확인 한 Train ID 입력 하세요.!!\n",
    "    inference_id='',  ## history 에서 확인 한 Inference ID 를 입력 하세요 !!\n",
    ")\n",
    "\n",
    "register.login(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register.debugging = True  ## default: False (skip 항목: docker 생성, solution 등록)\n",
    "register.run(username=username, password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register.run_train(\n",
    "    status_period = 10, ## 몇 초 간격으로 학습 상태를 체크할 것인지 설정\n",
    "    delete_instance = False,   ## 학습 테스트에 사용한 solution instance & stream 을 삭제할 것인지 설정 \n",
    "    delete_solution= False,  ## solution 을 삭제할 것인지 설정\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr",
   "language": "python",
   "name": "tcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
